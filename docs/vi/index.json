[
{
	"uri": "https://phuong721.github.io/learning-aws/vi/",
	"title": "Báo cáo thực tập",
	"tags": [],
	"description": "",
	"content": "Báo cáo thực tập Thông tin sinh viên: Họ và tên: Đỗ Đoàn Duy Phương\nSố điện thoại: 0983394370\nEmail: phuongdddse180235@fpt.edu.vn\nTrường: Đại học FPT TP.HCM\nNgành: An toàn thông tin\nLớp: AWS082025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 08/09/2025 đến ngày 30/12/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/4-eventparticipated/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “AWS Mastery #2 – CloudFormation \u0026amp; CDK Workshop” Mục Đích Của Sự Kiện Workshop “AWS Mastery #2 – CloudFormation \u0026amp; CDK” được tổ chức nhằm giúp người tham dự:\nNắm bắt tư duy Infrastructure as Code (IaC) – phương pháp quản lý hệ thống hạ tầng bằng mã nguồn. Hiểu rõ cách AWS triển khai, tự động hóa và vận hành tài nguyên thông qua CloudFormation và CDK. Cung cấp góc nhìn tổng quan và thực tiễn về Docker, container orchestration, và các dịch vụ như ECS, EKS, App Runner. Trau dồi tư duy DevOps, khả năng kiểm soát thay đổi, tái sử dụng hạ tầng, và triển khai nhanh chóng. Trực tiếp quan sát các demo giúp củng cố khả năng triển khai hạ tầng thực tế. Sự kiện phù hợp với lập trình viên, DevOps engineer, cloud engineer hoặc bất kỳ ai đang muốn tiếp cận tự động hóa trên AWS.\nDanh Sách Diễn Giả Bao Huynh Thinh Nguyen – AWS Community Builder Vi Tran – AWS Community Builder Các diễn giả đều có nhiều kinh nghiệm triển khai hệ thống AWS thực tế, nên phần trình bày rất thực tiễn, dễ theo kịp và chứa nhiều kinh nghiệm áp dụng ngay.\nNội Dung Nổi Bật 1. Tư duy Infrastructure as Code (IaC) Workshop bắt đầu với việc chỉ ra lý do vì sao ClickOps (click chuột thủ công trên console) gây ra hạn chế:\nDễ bị lỗi do thao tác người dùng. Khó tái tạo môi trường giữa các team. Không kiểm soát được các thay đổi ngoài quy trình. Khó audit, khó rollback và khó mở rộng. IaC được giới thiệu như một bước chuyển đổi tất yếu trong DevOps:\nAutomation: Hạ tầng được tạo và quản lý hoàn toàn tự động. Reproducibility: Môi trường được build ra giống 100%. Scalability: Mở rộng nhanh chóng bằng code. Collaboration: Mọi thay đổi được version-control (Git), dễ phối hợp nhóm. 2. AWS CloudFormation – Công cụ IaC “native” của AWS CloudFormation là gì? CloudFormation cho phép mô tả toàn bộ hạ tầng bằng YAML hoặc JSON và AWS sẽ tự động tạo mọi thứ.\nCác khái niệm quan trọng được trình bày:\nCloudFormation Template Anatomy Parameters:\nCho phép template tái sử dụng bằng cách truyền tham số. Ví dụ: AMI ID, instance type, VPC ID. Mappings:\nChứa các giá trị phụ thuộc vùng, ví dụ AMI khác nhau giữa us-east-1 và ap-southeast-1. Conditions:\nTạo tài nguyên theo điều kiện (ví dụ chỉ tạo EC2 nếu environment = production). Resources:\nPhần quan trọng nhất của template. Mô tả full tài nguyên S3, EC2, IAM, VPC,\u0026hellip; Outputs:\nXuất giá trị ra ngoài, dùng để cross-stack reference hoặc chia sẻ cho team. Drift Detection Tính năng cho phép phát hiện khi một tài nguyên bị thay đổi trực tiếp trên console. Giúp giữ hạ tầng “khớp” với template đã định nghĩa. Diễn giả trình bày minh hoạ trực quan giúp tôi dễ hiểu về sự khác biệt giữa “state từ template” và “state ngoài đời thực”.\n3. AWS CDK – Viết hạ tầng bằng ngôn ngữ lập trình CDK được giới thiệu như phiên bản nâng cấp của CloudFormation:\nDùng ngôn ngữ lập trình như TypeScript, Python, Java, Go. Code CDK sẽ được dịch thành CloudFormation template thông qua cdk synth. Dễ tái sử dụng, dễ tạo abstraction, dễ maintain. Các khái niệm cốt lõi: Constructs L1: mapping 1:1 CloudFormation (chi tiết nhất). L2: API thân thiện hơn, có default best practice. L3: solution patterns triển khai trọn gói (như website hosting, pipeline). Stack \u0026amp; App Stack = 1 CloudFormation stack. App có thể gồm nhiều stack. CDK CLI Một số lệnh quan trọng:\ncdk init – tạo project. cdk bootstrap – chuẩn bị môi trường lần đầu. cdk synth – generate CloudFormation template. cdk deploy – triển khai. cdk destroy – xóa. cdk diff – so sánh thay đổi. cdk drift – kiểm tra drift. CDK giúp người làm DevOps và developer tự động hóa dễ dàng hơn rất nhiều so với viết YAML thủ công.\n4. Docker \u0026amp; Container Services trên AWS Phần này rất quan trọng vì container gần như là tiêu chuẩn hiện nay.\nDocker Fundamentals Container nhẹ, khởi động nhanh hơn VM. Dockerfile: mô tả cách build image. Image: blueprint tạo container. Amazon ECR Registry chứa images. Hỗ trợ scanning, immutable tags và IAM authorization. 5. Orchestration: ECS, EKS và App Runner Amazon ECS Dịch vụ orchestration “simple \u0026amp; native”. 2 kiểu chạy: EC2 launch type (tự quản lý server) Fargate launch type (serverless) Thành phần: Cluster – Task Definition – Service Amazon EKS Managed Kubernetes. Dùng cho workloads cần multi-cloud hoặc cần đầy đủ sức mạnh Kubernetes. App Runner Dịch vụ đơn giản nhất để chạy web app/container. Tự build → deploy → scale. Thích hợp cho team nhỏ hoặc prototype. Những Gì Học Được 1. Tư duy quản trị hạ tầng hiện đại IaC không chỉ là công cụ, mà còn là triết lý quản lý hạ tầng chuẩn hoá, giảm rủi ro vận hành. Drift detection là công cụ hữu ích để đảm bảo sự ổn định. 2. Kiến thức chuyên sâu về IaC Hiểu chi tiết các component của CloudFormation template giúp tôi có thể đọc – viết template tốt hơn. Học được cách viết CDK với construct L2/L3 nhanh và “clean” hơn nhiều so với YAML. 3. Kiến trúc container hiện đại Khả năng phân biệt rõ khi nào dùng ECS, khi nào dùng Fargate, khi nào dùng EKS. Biết cách đánh giá workloads dựa trên chi phí – hiệu suất – yêu cầu vận hành. 4. Kinh nghiệm thực tế trong DevOps cdk diff cực kỳ hữu ích trước khi deploy production. IaC giúp các team rất dễ review code trước khi bản thân hạ tầng được tạo ra. Ứng Dụng Vào Công Việc Bắt đầu chuyển hạ tầng nhỏ sang IaC bằng CloudFormation hoặc CDK. Viết template cho S3 bucket, IAM role, hoặc VPC cơ bản để thực hành. Triển khai ứng dụng mẫu bằng ECS Fargate để hiểu end-to-end pipeline. Tự xây dựng demo CDK áp dụng constructs ở cả L1–L3. Đề xuất áp dụng container registry ECR cho pipeline CI/CD của team. Tạo tài liệu nội bộ hướng dẫn cách dùng cdk diff để kiểm soát thay đổi. Trải Nghiệm Trong Event Buổi workshop có không khí chuyên nghiệp nhưng rất gần gũi, diễn giả nhiệt tình trả lời câu hỏi. Demo trực tiếp CDK và ECS giúp tôi hiểu rõ bản chất “as code” của toàn bộ hệ thống AWS. Tôi đặc biệt thích phần so sánh ECS vs EKS vì giúp tôi định hình khi nào sử dụng orchestration đơn giản hoặc Kubernetes. Kết nối với những người tham gia khác giúp tôi học thêm nhiều kinh nghiệm trong nghề DevOps. Một số hình ảnh trong sự kiện Sau sự kiện, tôi cảm thấy mình tự tin hơn rất nhiều trong việc tiếp cận AWS Infrastructure as Code và container orchestration, đồng thời có định hướng rõ ràng để áp dụng chúng vào công việc thực tế.\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/1-worklog/1.9-week9/",
	"title": "Worklog Tuần 9",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 9: Thu thập yêu cầu và bắt đầu xây dựng nội dung cho Proposal và Proposal Template của dự án BDSS. Viết các phần mở đầu: Executive Summary, Problem Statement, Solution Overview. Xác định kiến trúc AWS để đưa vào cả hai tài liệu. Hoàn thiện bản nháp đầu tiên cho Proposal và phần khung (structure) của Proposal Template. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Nhận yêu cầu từ mentor về nội dung cần có trong Proposal \u0026amp; Proposal Template - Xác định outline chung cho cả hai tài liệu 03/11/2025 03/11/2025 proposal.docx Proposal Template.docx 3 - Viết Executive Summary cho Proposal - Chuẩn bị phần mở đầu tương ứng trong Proposal Template 04/11/2025 04/11/2025 proposal.docx 4 - Viết Problem Statement: mô tả vấn đề tại các cơ sở y tế \u0026amp; nhu cầu kết nối người hiến máu - Điều chỉnh nội dung để phù hợp khi đưa vào Proposal Template 05/11/2025 05/11/2025 Tài liệu nhóm 5 - Viết Proposed Solution cho Proposal - Đồng thời hoàn thiện phần Solution Overview trong Proposal Template 06/11/2025 06/11/2025 proposal.docx 6 - Mô tả Solution Architecture theo 4 layer - Rà soát cách trình bày kiến trúc trong Proposal Template để khớp layout chuẩn 07/11/2025 07/11/2025 AWS Docs 7 - Viết phần Technical Implementation và lộ trình triển khai - Đồng thời điền các mục tương ứng trong Proposal Template (Activities, Deliverables, Scope…) 08/11/2025 08/11/2025 Proposal Template.docx CN - Hoàn thiện bản nháp đầu cho cả Proposal và Proposal Template - Gửi mentor review và ghi nhận feedback - Cập nhật Worklog tuần 9 09/11/2025 09/11/2025 Slack/Meeting Kết quả đạt được tuần 9: Hoàn thành bản nháp đầu tiên của Proposal và phần skeleton của Proposal Template, gồm các mục:\nExecutive Summary Problem Statement Proposed Cloud Solution Solution Architecture (4 lớp) Technical Implementation (draft) Xây dựng được cấu trúc hoàn chỉnh cho Proposal Template, sẵn sàng điền nội dung chi tiết ở tuần sau.\nHiểu rõ hơn yêu cầu từ mentor và cách trình bày nội dung theo hai định dạng khác nhau:\nProposal: mô tả chi tiết Proposal Template: mô hình chuẩn AWS Xác định rõ kiến trúc AWS sử dụng trong cả hai tài liệu:\nRoute 53, CloudFront API Gateway – EC2 RDS MySQL Cognito Authorization CI/CD Pipeline Monitoring \u0026amp; Security Layer Tạo nền tảng nội dung quan trọng để tuần tới tiếp tục hoàn thiện:\nTechnical Plan, Budget Estimate, Risk Assessment và hoàn chỉnh Proposal Template.\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/1-worklog/1.8-week8/",
	"title": "Worklog Tuần 8",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 8: Nắm được yêu cầu kiến trúc cần xây dựng cho dự án. Thành thạo cách sử dụng draw.io để dựng sơ đồ hệ thống. Hiểu rõ mối quan hệ giữa các service AWS trong kiến trúc: Networking, Compute, Database, CI/CD, Monitoring. Hoàn thiện bản Network Architecture Diagram và gửi mentor review. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Thu thập yêu cầu kiến trúc từ mentor - Xác định phạm vi kiến trúc cần vẽ (VPC, subnet, routing, frontend, backend, database, CI/CD…) 27/10/2025 27/10/2025 Nội bộ FCJ 3 - Bắt đầu dựng sơ đồ kiến trúc mạng trên draw.io - Tạo VPC, public/private subnet, Internet Gateway - Thêm Route 53, CloudFront, S3 FE 28/10/2025 28/10/2025 AWS Docs 4 - Thêm API Gateway, EC2, Security Group - Thiết kế RDS trong private subnet - Vẽ luồng xử lý FE → CloudFront → API → EC2 → RDS 29/10/2025 29/10/2025 AWS Architecture Icons 5 - Tích hợp CI/CD pipeline (CodePipeline, CodeBuild, CloudFormation) - Thêm Cognito/Auth và hoàn thiện Security Layer 30/10/2025 30/10/2025 aws.amazon.com 6 - Tối ưu bố cục sơ đồ, chỉnh màu + border - Đánh số thứ tự luồng xử lý - Xuất bản sơ đồ và gửi mentor nhận xét 31/10/2025 31/10/2025 Nội bộ FCJ 7 - Nhận feedback từ mentor: cập nhật subnet, luồng xử lý API, lớp bảo mật - Chỉnh sửa lại sơ đồ theo góp ý 01/11/2025 01/11/2025 Trao đổi trực tiếp CN - Tổng hợp bài học rút ra trong khi xây dựng kiến trúc - Hoàn thiện Worklog tuần 02/11/2025 02/11/2025 Kết quả đạt được tuần 9: Hoàn thành sơ đồ AWS Network Architecture Diagram đầy đủ thành phần:\nRoute 53, CloudFront, S3 bucket frontend. API Gateway → EC2 backend. NAT Gateway + Internet Gateway. RDS trong private subnet. CI/CD: CodePipeline, CodeBuild, CloudFormation. Monitoring \u0026amp; Security: CloudWatch, CloudTrail, IAM, Secrets Manager, SNS. Hiểu rõ cách các thành phần kết nối trong mô hình:\nLuồng request của user đến FE/BE. Cách tách biệt public/private subnet. Cơ chế NAT để EC2 truy cập internet an toàn. Luồng API Gateway → EC2 → RDS. Nắm được cách chuẩn hoá sơ đồ kỹ thuật theo chuẩn AWS:\nSử dụng đúng icon, nhóm dịch vụ, phân layer rõ ràng. Đánh dấu số thứ tự các bước xử lý. Hoàn thiện bản diagram để đưa vào báo cáo và gửi cho mentor đánh giá.\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/1-worklog/1.7-week7/",
	"title": "Worklog Tuần 7",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 7: Triển khai và quản lý dữ liệu trên S3, DynamoDB, Redshift. Tạo pipeline dữ liệu với Kinesis, Glue, DataBrew, EMR. Phân tích dữ liệu bằng Athena, Kinesis Data Analytics và trực quan hóa bằng QuickSight. Xây dựng ứng dụng serverless và dashboard tương tác. Làm quen với CloudShell, AWS SDK và Cloud9 cho thao tác lập trình và xử lý dữ liệu. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tạo S3 Bucket, Delivery Stream, dữ liệu mẫu, Glue Crawler, kiểm tra dữ liệu, session setup, phân tích với Athena, trực quan hóa QuickSight, dọn dẹp tài nguyên (Module 07-Lab35-3.1 đến 7) 20/10/2025 20/10/2025 https://000035.awsstudygroup.com/ 3 - Làm quen DynamoDB, khám phá console, backup dữ liệu, dọn dẹp, áp dụng Advanced Design Patterns, triển khai global serverless app, event-driven architecture (Module 07-Lab39-1 đến 8) 21/10/2025 21/10/2025 https://000039.awsstudygroup.com/ 4 - Chuẩn bị, xây dựng cơ sở dữ liệu, quản lý dữ liệu trong bảng, chi phí, tagging, sử dụng và truy vấn dữ liệu, dọn dẹp tài nguyên (Module 07-Lab40-2.1 đến 4) 22/10/2025 22/10/2025 https://000040.awsstudygroup.com/ 5 - Làm quen với CloudShell, console, SDK; tạo Cloud9 instance, tải và upload dataset lên S3; setup DataBrew, data profiling, clean \u0026amp; transform data (Module 07-Lab60 \u0026amp; 07-Lab70) 23/10/2025 23/10/2025 https://000060.awsstudygroup.com/ 6 - Chuẩn bị pipeline, ingest \u0026amp; store dữ liệu, catalog data, transform data với Glue (interactive \u0026amp; GUI), DataBrew, EMR; phân tích dữ liệu với Athena \u0026amp; Kinesis Data Analytics; visualize với QuickSight; serve với Lambda; warehouse trên Redshift (Module 07-Lab72-2 đến 13) 24/10/2025 24/10/2025 https://000070.awsstudygroup.com/ 7 - Xây dựng dashboard, cải thiện dashboard, tạo interactive dashboard (Module 07-Lab73-3 đến 5) 25/10/2025 25/10/2025 https://000072.awsstudygroup.com/ CN - Tổng hợp, kiểm tra kết quả, dọn dẹp tài nguyên, tự đánh giá tuần và chuẩn bị nội dung tuần tiếp theo 26/10/2025 26/10/2025 https://000073.awsstudygroup.com/ Kết quả đạt được tuần 7: Quản lý và xử lý dữ liệu:\nTriển khai dữ liệu trên S3, DynamoDB, Redshift. Tạo pipeline dữ liệu với Kinesis, Glue, DataBrew và EMR. Phân tích \u0026amp; trực quan hóa:\nPhân tích dữ liệu bằng Athena và Kinesis Data Analytics. Trực quan hóa dữ liệu và xây dựng dashboard tương tác với QuickSight. Ứng dụng serverless:\nTriển khai ứng dụng serverless trên DynamoDB và Lambda. Xây dựng event-driven architecture cho global serverless app. Công cụ lập trình \u0026amp; thao tác dữ liệu:\nSử dụng CloudShell, AWS SDK và Cloud9 để thao tác và xử lý dữ liệu. Quản lý tài nguyên:\nDọn dẹp toàn bộ tài nguyên đã triển khai để tránh chi phí phát sinh. Tự đánh giá:\nNắm vững quản lý dữ liệu, pipeline, phân tích \u0026amp; trực quan hóa, serverless application. Chuẩn bị tốt cho tuần tiếp theo với các nội dung nâng cao về bảo mật, tagging và quản lý chi phí. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/1-worklog/1.6-week6/",
	"title": "Worklog Tuần 6",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 6: Thực hành triển khai VPC, EC2, RDS và các cấu hình bảo mật. Triển khai ứng dụng và thực hiện backup/restore. Quản lý kết nối EC2 qua RDP và Fleet Manager. Thực hiện cấu hình SQL Server và Oracle database. Thực hiện chuyển đổi schema từ MSSQL/Oracle sang Aurora MySQL. Thực hành Serverless Migration, kiểm tra logs và troubleshoot các kịch bản test. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tạo VPC (Module 06-Lab05-2.1) - Tạo EC2 Security Group (Module 06-Lab05-2.2) - Tạo RDS Security Group (Module 06-Lab05-2.3) - Tạo DB Subnet Group (Module 06-Lab05-2.4) - Triển khai EC2 instance (Module 06-Lab05-3) - Triển khai RDS database instance (Module 06-Lab05-4) - Deploy ứng dụng (Module 06-Lab05-5) - Backup \u0026amp; Restore (Module 06-Lab05-6) - Dọn dẹp tài nguyên (Module 06-Lab05-7) 13/10/2025 13/10/2025 https://000006.awsstudygroup.com/ 3 - Kết nối EC2 bằng RDP Client (Module 06-Lab43-01) - Kết nối EC2 bằng Fleet Manager (Module 06-Lab43-02) - Cấu hình SQL Server Source DB (Module 06-Lab43-03) 14/10/2025 14/10/2025 https://000043.awsstudygroup.com/ 4 - Kết nối và cấu hình Oracle Source DB (Module 06-Lab43-04 \u0026amp; 05) - Drop Constraint (Module 06-Lab43-06) - MSSQL → Aurora MySQL target config (Module 06-Lab43-07) - Tạo project migration (Module 06-Lab43-08) 15/10/2025 15/10/2025 https://000043.awsstudygroup.com/ 5 - Chuyển đổi schema MSSQL/Oracle sang Aurora MySQL (Module 06-Lab43-09 \u0026amp; 10) - Tạo Migration Task và Endpoints (Module 06-Lab43-11) - Kiểm tra dữ liệu trên S3 (Module 06-Lab43-12) 16/10/2025 16/10/2025 https://000043.awsstudygroup.com/ 6 - Tạo Serverless Migration (Module 06-Lab43-13) - Tạo Event Notification (Module 06-Lab43-14) - Kiểm tra logs (Module 06-Lab43-15) - Troubleshoot Mem Pressure \u0026amp; Table Errors (Module 06-Lab43-16 \u0026amp; 17) 17/10/2025 17/10/2025 https://000043.awsstudygroup.com/ 7 - Tổng hợp kết quả, kiểm tra và dọn dẹp toàn bộ tài nguyên thực hành 18/10/2025 18/10/2025 N/A CN - Tự đánh giá tuần, chuẩn bị kiến thức cho tuần tiếp theo 19/10/2025 19/10/2025 N/A Kết quả đạt được tuần 6: Triển khai mạng \u0026amp; cơ sở dữ liệu:\nTạo và cấu hình VPC, EC2 Security Group, RDS Security Group, DB Subnet Group. Triển khai EC2 \u0026amp; RDS instance thành công, deploy ứng dụng và thực hiện backup/restore. Quản lý kết nối EC2:\nKết nối EC2 bằng RDP Client và Fleet Manager, quản lý Source DB SQL Server \u0026amp; Oracle. Chuyển đổi dữ liệu \u0026amp; Migration:\nThực hiện schema conversion từ MSSQL/Oracle sang Aurora MySQL. Tạo Migration Task, Endpoints, kiểm tra dữ liệu trên S3. Serverless Migration \u0026amp; Troubleshooting:\nTạo Serverless Migration, cấu hình Event Notification, kiểm tra logs. Xử lý các kịch bản test Mem Pressure và Table Errors thành công. Quản lý tài nguyên:\nDọn dẹp toàn bộ tài nguyên đã triển khai để tránh phát sinh chi phí ngoài ý muốn. Tự đánh giá:\nNắm vững triển khai VPC, EC2, RDS, backup/restore, kết nối database và Serverless Migration. Hiểu quy trình chuyển đổi dữ liệu và kiểm soát logs. Chuẩn bị tốt cho tuần tiếp theo với các nội dung nâng cao về bảo mật và tối ưu hạ tầng. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/1-worklog/1.5-week5/",
	"title": "Worklog Tuần 5",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 5: Thực hành AWS Security Hub và đánh giá bảo mật. Quản lý VPC, EC2 và Lambda với Web-hooks và Tagging. Quản lý IAM Users, Policies, Roles và Switch Roles nâng cao. Thực hành kiểm soát quyền hạn người dùng IAM và giới hạn truy cập. Quản lý CloudTrail, Athena và dữ liệu S3 được mã hóa. Triển khai và quản lý EC2, S3 và IAM Role/Key. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Bật AWS Security Hub (Module 05-Lab18-02) - Đánh giá score theo tiêu chí (Module 05-Lab18-03) - Dọn dẹp tài nguyên Security Hub (Module 05-Lab18-04) 06/10/2025 06/10/2025 https://000018.awsstudygroup.com/ 3 - Tạo VPC, Security Group, EC2 (Module 05-Lab22-2.1 đến 2.3) - Cấu hình Incoming Web-hooks Slack (Module 05-Lab22-2.4) - Tạo Tag Instance (Module 05-Lab22-3) - Tạo Role cho Lambda (Module 05-Lab22-4) - Stop/Start function, kiểm tra kết quả (Module 05-Lab22-5.1 đến 6) - Dọn dẹp tài nguyên (Module 05-Lab22-7) 07/10/2025 07/10/2025 https://000022.awsstudygroup.com/ 4 - Quản lý Tag trên EC2 và AWS Resources (Module 05-Lab27-2.1.1 đến 2.2) - Tạo Resource Group (Module 05-Lab27-3) - Dọn dẹp tài nguyên (Module 05-Lab27-4) 08/10/2025 08/10/2025 https://000027.awsstudygroup.com/ 5 - Tạo IAM Users, Policies, Roles (Module 05-Lab28-2.1 đến 4) - Switch Roles \u0026amp; kiểm tra truy cập EC2 ở nhiều Region (Module 05-Lab28-5.1 đến 5.2.5) - Dọn dẹp tài nguyên (Module 05-Lab28-6) 09/10/2025 09/10/2025 https://000028.awsstudygroup.com/ 6 - Tạo IAM Limited User \u0026amp; Restriction Policy, test hạn chế quyền (Module 05-Lab30-3 đến 5) - Dọn dẹp tài nguyên (Module 05-Lab30-6) 10/10/2025 10/10/2025 https://000030.awsstudygroup.com/ 7 - Tạo Policy, Role, Group, User, KMS, Bucket S3, upload dữ liệu, CloudTrail, Athena, test mã hóa dữ liệu (Module 05-Lab33-2.1 đến 6) - Dọn dẹp tài nguyên (Module 05-Lab33-7) 11/10/2025 11/10/2025 https://000033.awsstudygroup.com/ CN - Quản lý IAM Group, User, Admin Role, Switch Role, hạn chế theo IP \u0026amp; thời gian (Module 05-Lab44) - Tạo EC2, S3, IAM Role, Access Key và dọn dẹp tài nguyên (Module 05-Lab48) 12/10/2025 12/10/2025 https://000044.awsstudygroup.com/ https://000048.awsstudygroup.com/ Kết quả đạt được tuần 5: AWS Security Hub:\nBật Security Hub, đánh giá score theo tiêu chí, dọn dẹp tài nguyên. VPC, EC2 \u0026amp; Lambda:\nTạo VPC, Security Group, EC2, Lambda functions với stop/start, Incoming Web-hooks Slack. Sử dụng Tags để quản lý resource, tạo Resource Group, kiểm tra kết quả. IAM Management:\nTạo Users, Policies, Roles, Switch Roles nâng cao. Triển khai IAM Limited User với hạn chế quyền và giới hạn truy cập theo IP/Time. Quản lý nhiều Region với EC2 console, kiểm tra Tag \u0026amp; Policy. CloudTrail, Athena \u0026amp; S3:\nTạo Bucket, upload dữ liệu, bật CloudTrail, truy xuất dữ liệu bằng Athena, test mã hóa dữ liệu. Quản lý tài nguyên:\nDọn dẹp toàn bộ tài nguyên đã triển khai sau khi thực hành để tránh phát sinh chi phí. Tự đánh giá:\nNắm vững thực hành Security Hub, VPC, EC2, Lambda, Tag, IAM, CloudTrail \u0026amp; Athena. Hiểu và triển khai các hạn chế truy cập nâng cao cho IAM Users. Sẵn sàng cho tuần tiếp theo với các nội dung tối ưu bảo mật và chi phí. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/1-worklog/1.4-week4/",
	"title": "Worklog Tuần 4",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 4: Thực hành AWS Backup nâng cao và thiết lập thông báo. Triển khai và quản lý máy ảo từ On-Premises lên AWS bằng AMI. Thực hành S3, Storage Gateway và File Shares nâng cao. Triển khai Multi-AZ file system với SSD và HDD, giám sát hiệu suất và quản lý người dùng. Quản lý website tĩnh S3, CloudFront, versioning, replication và dọn dẹp tài nguyên. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tạo S3 Bucket (Module 04-Lab13-02.1) - Triển khai hạ tầng Backup (Module 04-Lab13-02.2) - Tạo Backup Plan (Module 04-Lab13-03) - Thiết lập thông báo (Module 04-Lab13-04) 29/09/2025 29/09/2025 https://000013.awsstudygroup.com/, https://000014.awsstudygroup.com/ 3 - Thử nghiệm khôi phục dữ liệu (Module 04-Lab13-05) - Dọn dẹp tài nguyên Backup (Module 04-Lab13-06) 30/09/2025 30/09/2025 https://000013.awsstudygroup.com/, https://000014.awsstudygroup.com/ 4 - Làm việc với VMWare Workstation (Module 04-Lab14-01) - Export VM từ On-Premises (Module 04-Lab14-02.1) - Upload VM lên AWS (Module 04-Lab14-02.2) - Import VM vào AWS (Module 04-Lab14-02.3) - Triển khai Instance từ AMI (Module 04-Lab14-02.4) 01/10/2025 01/10/2025 https://000024.awsstudygroup.com/, https://000025.awsstudygroup.com/ 5 - Quản lý S3 Bucket ACL (Module 04-Lab14-03.1) - Export VM từ Instance (Module 04-Lab14-03.2) - Dọn dẹp tài nguyên VM \u0026amp; AWS (Module 04-Lab14-05) 02/10/2025 02/10/2025 https://000024.awsstudygroup.com/, https://000025.awsstudygroup.com/ 6 - Tạo Storage Gateway (Module 04-Lab24-2.1) - Tạo File Shares (Module 04-Lab24-2.2) - Mount File Shares trên máy On-Premises (Module 04-Lab24-2.3) - Dọn dẹp tài nguyên (Module 04-Lab24-3) 03/10/2025 03/10/2025 https://000024.awsstudygroup.com/ 7 - Tạo SSD \u0026amp; HDD Multi-AZ File System (Module 04-Lab25-2.2 \u0026amp; 2.3) - Tạo file shares, test \u0026amp; monitor performance (Module 04-Lab25-3, 4, 5) - Enable deduplication, shadow copies, quản lý user \u0026amp; quotas, scale throughput \u0026amp; storage (Module 04-Lab25-6 đến 12) 04/10/2025 04/10/2025 https://000024.awsstudygroup.com/ CN - Dọn dẹp môi trường Multi-AZ (Module 04-Lab25-13) - Tạo S3 Bucket, load dữ liệu, website tĩnh, CloudFront, versioning \u0026amp; replication, test \u0026amp; cleanup (Module 04-Lab57-2.1 đến 11) 05/10/2025 05/10/2025 https://000057.awsstudygroup.com/ Kết quả đạt được tuần 4: AWS Backup nâng cao:\nTriển khai Backup Plan, thiết lập thông báo, test restore dữ liệu thành công. Dọn dẹp tài nguyên backup. Máy ảo \u0026amp; AMI:\nExport VM từ On-Premises, upload \u0026amp; import vào AWS. Triển khai Instance từ AMI và quản lý S3 Bucket ACL. Dọn dẹp VM \u0026amp; tài nguyên sau thử nghiệm. Storage Gateway \u0026amp; Multi-AZ File System:\nTạo Storage Gateway, File Shares, mount trên máy On-Premises. Triển khai SSD \u0026amp; HDD Multi-AZ File System, tạo file shares, test \u0026amp; monitor performance. Quản lý user, enable deduplication, shadow copies, quotas, scale throughput \u0026amp; storage. S3 \u0026amp; CloudFront:\nTạo S3 Bucket, load dữ liệu, triển khai website tĩnh, cấu hình CloudFront. Sử dụng versioning, replication multi-region, test \u0026amp; dọn dẹp tài nguyên. Tự đánh giá:\nNắm vững triển khai Backup nâng cao, Storage Gateway, Multi-AZ File System, quản lý VM \u0026amp; website tĩnh. Thực hành dọn dẹp tài nguyên đúng cách, tránh phát sinh chi phí. Sẵn sàng cho tuần tiếp theo với các bài học về bảo mật, IAM \u0026amp; tối ưu chi phí. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/1-worklog/1.3-week3/",
	"title": "Worklog Tuần 3",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 3: Thực hành triển khai AWS Backup và đảm bảo phục hồi dữ liệu. Triển khai S3, Storage Gateway, quản lý dữ liệu và file shares. Thiết lập và quản lý website tĩnh trên S3 cùng với CloudFront. Tìm hiểu các tính năng nâng cao của S3: versioning, replication, quản lý quyền truy cập. Dọn dẹp tài nguyên sau khi thử nghiệm để tránh phát sinh chi phí. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Deploy AWS Backup to the system - Introduction (Module 03-Lab13-01) - Triển khai hạ tầng Backup (Module 03-Lab13-02.2) - Tạo Backup Plan (Module 03-Lab13-03) 22/09/2025 22/09/2025 https://000013.awsstudygroup.com/ 3 - Thử nghiệm khôi phục dữ liệu (Module 03-Lab13-05) - Dọn dẹp tài nguyên Backup (Module 03-Lab13-06) 23/09/2025 23/09/2025 https://000013.awsstudygroup.com/ 4 - Tạo S3 Bucket \u0026amp; EC2 cho Storage Gateway (Module 03-Lab24-01.1 \u0026amp; 01.2) - Tạo Storage Gateway và File Shares (Module 03-Lab24-02.1 \u0026amp; 02.2) 24/09/2025 24/09/2025 https://000024.awsstudygroup.com/ 5 - Tạo S3 Bucket, load dữ liệu, enable static website (Module 03-Lab57-02.1, 02.2 \u0026amp; 03) - Cấu hình quyền truy cập công khai và test website (Module 03-Lab57-04, 05, 06) 25/09/2025 25/09/2025 https://000057.awsstudygroup.com/ 6 - Block all public access, cấu hình CloudFront \u0026amp; test (Module 03-Lab57-07.1 đến 07.3) - Sử dụng bucket versioning, di chuyển đối tượng, replication multi-region (Module 03-Lab57-08, 09, 10) 26/09/2025 26/09/2025 https://000057.awsstudygroup.com/ 7 - Dọn dẹp tài nguyên S3 \u0026amp; CloudFront (Module 03-Lab57-11) 27/09/2025 27/09/2025 https://000057.awsstudygroup.com/ CN - Tổng kết tuần 3, đánh giá kết quả, ghi nhận kinh nghiệm triển khai Backup, Storage Gateway và S3/CloudFront 28/09/2025 28/09/2025 N/A Kết quả đạt được tuần 3: AWS Backup:\nTriển khai Backup Plan và thử nghiệm khôi phục dữ liệu thành công. Dọn dẹp tài nguyên backup sau khi kiểm tra. Storage Gateway \u0026amp; S3:\nTạo S3 Bucket và EC2 cho Storage Gateway. Thiết lập Storage Gateway và file shares, load dữ liệu thành công. Website tĩnh \u0026amp; CloudFront:\nTriển khai website tĩnh trên S3, cấu hình public access, và kiểm tra hiển thị. Cấu hình CloudFront để phân phối nội dung, kiểm tra hoạt động. Sử dụng versioning, di chuyển đối tượng và replication multi-region. Tự đánh giá:\nNắm vững các bước triển khai AWS Backup, Storage Gateway, S3 và CloudFront. Thực hành test restore, versioning, replication và dọn dẹp tài nguyên. Sẵn sàng cho tuần tiếp theo với các bài tập AWS nâng cao về bảo mật và tối ưu chi phí. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/1-worklog/1.2-week2/",
	"title": "Worklog Tuần 2",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 2: Học và thực hành thiết lập mạng AWS bằng VPC, Subnet, Route Table, Internet Gateway, NAT Gateway và các cơ chế bảo mật. Cấu hình EC2 instances trong các subnet và kiểm tra kết nối. Thiết lập Hybrid DNS với Route 53 Resolver. Tìm hiểu và triển khai VPC Peering và AWS Transit Gateway. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Giới thiệu Amazon VPC và AWS VPN Site-to-Site (Module 02-Lab03-01) - Subnets (Module 02-Lab03-01.1) - Route Table (Module 02-Lab03-01.2) - Internet Gateway (IGW) (Module 02-Lab03-01.3) - NAT Gateway (Module 02-Lab03-01.4) 15/09/2025 15/09/2025 https://000003.awsstudygroup.com/ 3 - Cấu hình Security Group (Module 02-Lab03-02.1) - Network ACLs (Module 02-Lab03-02.2) - VPC Resource Map (Module 02-Lab03-02.3) 16/09/2025 16/09/2025 https://000003.awsstudygroup.com/ 4 - Tạo VPC (Module 02-Lab03-03.1) - Tạo Subnet (Module 02-Lab03-03.2) - Tạo Internet Gateway (Module 02-Lab03-03.3) - Tạo Route Table cho Outbound Internet Routing qua IGW (Module 02-Lab03-03.4) - Tạo Security Groups (Module 02-Lab03-03.5) 17/09/2025 17/09/2025 https://000010.awsstudygroup.com/ 5 - Tạo EC2 Instances trong Subnets (Module 02-Lab03-04.1) - Kiểm tra kết nối (Module 02-Lab03-04.2) - Tạo NAT Gateway (Module 02-Lab03-04.3) - EC2 Instance Connect Endpoint (Module 02-Lab03-04.5) 18/09/2025 18/09/2025 https://000010.awsstudygroup.com/ 6 - Thiết lập Hybrid DNS với Route 53 Resolver (Module 02-Lab10-01) - Tạo Key Pair (Module 02-Lab10-02.1) - Khởi tạo CloudFormation Template (Module 02-Lab10-02.2) - Cấu hình Security Group (Module 02-Lab10-02.3) - Kết nối đến RDGW (Module 02-Lab10-03) 19/09/2025 19/09/2025 https://000019.awsstudygroup.com/ 7 - Thiết lập DNS: Route 53 Outbound Endpoint (Module 02-Lab10-05.1) - Tạo Resolver Rules (Module 02-Lab10-05.2) - Tạo Inbound Endpoints (Module 02-Lab10-05.3) - Kiểm tra kết quả (Module 02-Lab10-05.4) - Dọn dẹp tài nguyên (Module 02-Lab10-06) 20/09/2025 20/09/2025 https://000019.awsstudygroup.com/ CN - VPC Peering setup: Giới thiệu (Module 02-Lab19-01) - Khởi tạo CloudFormation Templates (Module 02-Lab19-02.1) - Tạo Security Group (Module 02-Lab19-02.2) - Tạo EC2 instance (Module 02-Lab19-02.3) - Cập nhật Network ACLs (Module 02-Lab19-03) - Tạo peering connection (Module 02-Lab19-04) - Cấu hình Route Tables (Module 02-Lab19-05) - Bật Cross-Peer DNS (Module 02-Lab19-06) - Dọn dẹp tài nguyên (Module 02-Lab19-07) - AWS Transit Gateway setup: Giới thiệu (Module 02-Lab20-01) - Các bước chuẩn bị (Module 02-Lab20-02) - Tạo Transit Gateway (Module 02-Lab20-03) - Tạo TGW Attachments (Module 02-Lab20-04) - Tạo TGW Route Tables (Module 02-Lab20-05) - Thêm TGW Routes vào VPC Route Tables (Module 02-Lab20-06) - Dọn dẹp tài nguyên (Module 02-Lab20-07) 21/09/2025 21/09/2025 https://000020.awsstudygroup.com/ Kết quả đạt được tuần 2: Mạng AWS:\nTạo và cấu hình VPC, Subnet, Route Table, Internet Gateway, NAT Gateway, Security Groups. Triển khai EC2 instances trong các subnet và kiểm tra kết nối thành công. Cấu hình EC2 Instance Connect Endpoint để truy cập dễ dàng hơn. Hybrid DNS:\nTạo Key Pairs và khởi tạo CloudFormation Templates. Cấu hình Security Groups và kết nối đến RDGW. Tạo Route 53 Outbound/Inbound Endpoints, thiết lập Resolver Rules và kiểm tra kết quả. Dọn dẹp tài nguyên DNS sau khi kiểm tra. VPC Peering \u0026amp; Transit Gateway:\nThiết lập VPC Peering, cấu hình Route Tables và bật Cross-Peer DNS. Tạo AWS Transit Gateway, attachments, route tables, thêm routes vào VPC route tables. Dọn dẹp các tài nguyên để tránh phát sinh chi phí không mong muốn. Tự đánh giá:\nCó kinh nghiệm thực hành với mạng AWS, Hybrid DNS, VPC Peering và Transit Gateway. Triển khai, kiểm tra và dọn dẹp tài nguyên thành công. Sẵn sàng cho các tuần tiếp theo với kiến thức nâng cao hơn. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/3-blogstranslated/3.4-blog4/",
	"title": "Blog 4",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/3-blogstranslated/3.5-blog5/",
	"title": "Blog 5",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/3-blogstranslated/3.6-blog6/",
	"title": "Blog 6",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/1-worklog/",
	"title": "Nhật ký công việc",
	"tags": [],
	"description": "",
	"content": "Tổng quan: Phần này giới thiệu worklog, tóm tắt các tuần hoàn thành, các công việc đã thực hiện và kết quả đạt được.\nTôi đã hoàn thành chương trình thực tập trong vòng 12 tuần, tập trung vào việc học và thực hành các dịch vụ AWS cơ bản, quản lý dữ liệu, bảo mật, ứng dụng serverless, phân tích và trực quan hóa dữ liệu. Dưới đây là tóm tắt công việc từng tuần:\nTuần 1: Làm quen với AWS, tạo tài khoản Free Tier, thiết lập bảo mật, quản lý IAM và tạo Budget cơ bản\nTuần 2: Thiết lập VPC, subnet, Internet Gateway, NAT Gateway, Security Group, EC2 instance, VPN site-to-site, Route53 hybrid DNS, VPC peering và Transit Gateway\nTuần 3: Triển khai AWS Backup, tạo kế hoạch backup, thử nghiệm restore; S3 Bucket, Storage Gateway, triển khai website tĩnh với S3 \u0026amp; CloudFront, versioning, replication\nTuần 4: Tạo S3 bucket, triển khai hạ tầng, backup plan \u0026amp; notifications, test restore; Virtual Machine import/export, Storage Gateway, file system Multi-AZ, test hiệu năng, website S3 nâng cao\nTuần 5: Bảo mật với Security Hub, quản lý VPC, EC2 \u0026amp; Lambda với Tagging; IAM Users, Policies, Roles, KMS; CloudTrail \u0026amp; Athena; kiểm soát quyền hạn; dọn dẹp tài nguyên\nTuần 6: Tạo VPC, EC2 \u0026amp; RDS Security Group, triển khai RDS database, deploy ứng dụng, backup/restore; kết nối EC2 qua RDP \u0026amp; Fleet Manager; cấu hình SQL Server \u0026amp; Oracle; tạo Migration Task; troubleshoot\nTuần 7: Quản lý dữ liệu trên S3, DynamoDB, Redshift; pipeline dữ liệu với Kinesis, Glue, DataBrew, EMR; phân tích dữ liệu bằng Athena \u0026amp; Kinesis Data Analytics; trực quan hóa với QuickSight; ứng dụng serverless và dashboard tương tác; sử dụng CloudShell, SDK, Cloud9\nTuần 8: Xây dựng kiến trúc AWS cho dự án; thu thập yêu cầu, dựng Network Architecture Diagram, thiết kế VPC, subnet, routing, EC2, RDS, API Gateway, CloudFront, CI/CD và hoàn thiện sơ đồ theo feedback mentor\nTuần 9: Xây dựng bản nháp Proposal BDSS; viết Executive Summary, Problem Statement, Solution Overview; phân tích kiến trúc BDSS; tổng hợp nội dung từ proposal nhóm và chuẩn hóa theo template\nTuần 10: Xây dựng workshop dựa trên Proposal \u0026amp; Proposal Template; viết Introduction, Background, Objectives; xây dựng Architecture, Data Flow, CI/CD, Security; tổng hợp Cost \u0026amp; Risk để hoàn thiện Workshop Draft\nTuần 11: Tổng hợp nội dung từ 2 proposal; chuẩn hóa Executive Summary, Problem, Solution Architecture; xây dựng outline slide; chuẩn hóa toàn bộ nội dung sang tiếng Anh để chuẩn bị báo cáo cuối kỳ\nTuần 12: Trình bày dự án trước mentor; ghi nhận phản hồi về kiến trúc, CI/CD, cost, security; chỉnh sửa slide và tài liệu; tổng hợp action items để chuẩn bị cho báo cáo cuối kỳ\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/5-workshop/5.4-s3-onprem/5.4.1-prepare/",
	"title": "Chuẩn bị tài nguyên",
	"tags": [],
	"description": "",
	"content": "Để chuẩn bị cho phần này của workshop, bạn sẽ cần phải:\nTriển khai CloudFormation stack Sửa đổi bảng định tuyến VPC. Các thành phần này hoạt động cùng nhau để mô phỏng DNS forwarding và name resolution.\nTriển khai CloudFormation stack Mẫu CloudFormation sẽ tạo các dịch vụ bổ sung để hỗ trợ mô phỏng môi trường truyền thống:\nMột Route 53 Private Hosted Zone lưu trữ các bản ghi Bí danh (Alias records) cho điểm cuối PrivateLink S3 Một Route 53 Inbound Resolver endpoint cho phép \u0026ldquo;VPC Cloud\u0026rdquo; giải quyết các yêu cầu resolve DNS gửi đến Private Hosted Zone Một Route 53 Outbound Resolver endpoint cho phép \u0026ldquo;VPC On-prem\u0026rdquo; chuyển tiếp các yêu cầu DNS cho S3 sang \u0026ldquo;VPC Cloud\u0026rdquo; Click link sau để mở AWS CloudFormation console. Mẫu yêu cầu sẽ được tải sẵn vào menu. Chấp nhận tất cả mặc định và nhấp vào Tạo stack. Có thể mất vài phút để triển khai stack hoàn tất. Bạn có thể tiếp tục với bước tiếp theo mà không cần đợi quá trình triển khai kết thúc.\nCập nhật bảng định tuyến private on-premise Workshop này sử dụng StrongSwan VPN chạy trên EC2 instance để mô phỏng khả năng kết nối giữa trung tâm dữ liệu truyền thống và môi trường cloud AWS. Hầu hết các thành phần bắt buộc đều được cung cấp trước khi bạn bắt đầu. Để hoàn tất cấu hình VPN, bạn sẽ sửa đổi bảng định tuyến \u0026ldquo;VPC on-prem\u0026rdquo; để hướng lưu lượng đến cloud đi qua StrongSwan VPN instance.\nMở Amazon EC2 console Chọn instance tên infra-vpngw-test. Từ Details tab, copy Instance ID và paste vào text editor của bạn để sử dụng ở những bước tiếp theo Đi đến VPC menu bằng cách gõ \u0026ldquo;VPC\u0026rdquo; vào Search box Click vào Route Tables, chọn RT Private On-prem route table, chọn Routes tab, và click Edit Routes. Click Add route. Destination: CIDR block của Cloud VPC Target: ID của infra-vpngw-test instance (bạn đã lưu lại ở bước trên) Click Save changes "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/5-workshop/5.1-workshop-overview/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Giới thiệu về VPC Endpoint Điểm cuối VPC (endpoint) là thiết bị ảo. Chúng là các thành phần VPC có thể mở rộng theo chiều ngang, dự phòng và có tính sẵn sàng cao. Chúng cho phép giao tiếp giữa tài nguyên điện toán của bạn và dịch vụ AWS mà không gây ra rủi ro về tính sẵn sàng. Tài nguyên điện toán đang chạy trong VPC có thể truy cập Amazon S3 bằng cách sử dụng điểm cuối Gateway. Interface Endpoint PrivateLink có thể được sử dụng bởi tài nguyên chạy trong VPC hoặc tại TTDL. Tổng quan về workshop Trong workshop này, bạn sẽ sử dụng hai VPC.\n\u0026ldquo;VPC Cloud\u0026rdquo; dành cho các tài nguyên cloud như Gateway endpoint và EC2 instance để kiểm tra. \u0026ldquo;VPC On-Prem\u0026rdquo; mô phỏng môi trường truyền thống như nhà máy hoặc trung tâm dữ liệu của công ty. Một EC2 Instance chạy phần mềm StrongSwan VPN đã được triển khai trong \u0026ldquo;VPC On-prem\u0026rdquo; và được cấu hình tự động để thiết lập đường hầm VPN Site-to-Site với AWS Transit Gateway. VPN này mô phỏng kết nối từ một vị trí tại TTDL (on-prem) với AWS cloud. Để giảm thiểu chi phí, chỉ một phiên bản VPN được cung cấp để hỗ trợ workshop này. Khi lập kế hoạch kết nối VPN cho production workloads của bạn, AWS khuyên bạn nên sử dụng nhiều thiết bị VPN để có tính sẵn sàng cao. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/5-workshop/5.3-s3-vpc/5.3.1-create-gwe/",
	"title": "Tạo một Gateway Endpoint",
	"tags": [],
	"description": "",
	"content": " Mở Amazon VPC console Trong thanh điều hướng, chọn Endpoints, click Create Endpoint: Bạn sẽ thấy 6 điểm cuối VPC hiện có hỗ trợ AWS Systems Manager (SSM). Các điểm cuối này được Mẫu CloudFormation triển khai tự động cho workshop này.\nTrong Create endpoint console: Đặt tên cho endpoint: s3-gwe Trong service category, chọn aws services Trong Services, gõ \u0026ldquo;s3\u0026rdquo; trong hộp tìm kiếm và chọn dịch vụ với loại gateway Đối với VPC, chọn VPC Cloud từ drop-down menu. Đối với Route tables, chọn bảng định tuyến mà đã liên kết với 2 subnets (lưu ý: đây không phải là bảng định tuyến chính cho VPC mà là bảng định tuyến thứ hai do CloudFormation tạo). Đối với Policy, để tùy chọn mặc định là Full access để cho phép toàn quyền truy cập vào dịch vụ. Bạn sẽ triển khai VPC endpoint policy trong phần sau để chứng minh việc hạn chế quyền truy cập vào S3 bucket dựa trên các policies. Không thêm tag vào VPC endpoint. Click Create endpoint, click x sau khi nhận được thông báo tạo thành công. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/1-worklog/1.1-week1/",
	"title": "Worklog Tuần 1",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 1: Khởi tạo và quản lý tài khoản AWS cơ bản. Làm quen với các cơ chế bảo mật, quản lý người dùng, ngân sách và hỗ trợ trên AWS. Thực hành thao tác trên AWS Console và AWS CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tạo AWS Free Tier account (Module 01-Lab01-01) - Thiết lập Virtual MFA (Module 01-Lab01-02) 08/09/2025 08/09/2025 https://000001.awsstudygroup.com/ 3 - Tạo nhóm quản trị (Admin Group) và user Admin (Module 01-Lab01-03) - Cấu hình Account Authentication Support (Module 01-Lab01-04) 09/09/2025 09/09/2025 https://000007.awsstudygroup.com/ 4 - Tạo Budget bằng template (Module 01-Lab07-01) - Tạo Cost Budget (Module 01-Lab07-02) 10/09/2025 10/09/2025 https://000009.awsstudygroup.com/ 5 - Tạo Usage Budget (Module 01-Lab07-03) - Tạo Reservation Instance (RI) Budget (Module 01-Lab07-04) 11/09/2025 11/09/2025 https://000009.awsstudygroup.com/ 6 - Tạo Savings Plans Budget (Module 01-Lab07-05) - Clean Up Budgets (Module 01-Lab07-06) 12/09/2025 12/09/2025 https://000009.awsstudygroup.com/ 7 - Tìm hiểu gói hỗ trợ AWS (Module 01-Lab09-01) - Các loại yêu cầu hỗ trợ (Module 01-Lab09-02) - Thay đổi gói hỗ trợ (Module 01-Lab09-03) - Quản lý yêu cầu hỗ trợ (Module 01-Lab09-04) 13/09/2025 13/09/2025 https://000007.awsstudygroup.com/ CN - Ôn tập, tổng hợp và hoàn thiện các thiết lập, clean up các tài nguyên thử nghiệm 14/09/2025 14/09/2025 - Kết quả đạt được tuần 1: Khởi động tài khoản AWS:\nTạo thành công AWS Free Tier account. Thiết lập MFA cho root account để bảo mật. Tạo Admin Group và Admin User để quản lý thay vì dùng root. Hoàn tất cấu hình Account Authentication Support. Quản lý ngân sách:\nTạo Budget bằng template, Cost Budget, Usage Budget, RI Budget, Savings Plans Budget. Thực hành Clean Up các Budget đã tạo để tránh chi phí phát sinh. Hỗ trợ và xử lý sự cố:\nHiểu và biết cách sử dụng các gói hỗ trợ AWS. Thực hành tạo, quản lý và thay đổi các yêu cầu hỗ trợ trên AWS Console. Tự đánh giá:\nNắm được quy trình khởi tạo tài khoản, bảo mật, quản lý người dùng và nhóm. Thực hành quản lý ngân sách AWS cơ bản và các gói hỗ trợ. Sẵn sàng tiếp tục sang các tuần sau với nội dung chuyên sâu hơn về dịch vụ AWS. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/3-blogstranslated/3.1-blog1/",
	"title": "Tăng tốc Chiến lược Đám mây của bạn với Kết nối Trực tiếp AWS được Lưu trữ 25 Gbps của Megaport",
	"tags": [],
	"description": "",
	"content": "Khi các doanh nghiệp di chuyển khối lượng công việc quan trọng lên đám mây, hiệu suất mạng đã trở thành yêu cầu kinh doanh cơ bản. Dịch vụ web của Amazon (AWS) Direct Connect cung cấp kết nối mạng chuyên dụng giữa các trung tâm dữ liệu tại chỗ và AWS. Điều này bỏ qua internet công cộng để mang lại hiệu suất mạng ổn định và đáng tin cậy hơn với độ trễ thấp hơn. Sự giới thiệu của 25 Gbps hosted connections lấp đầy khoảng cách giữa các tùy chọn 10 Gbps (thường không đủ) và 100 Gbps (thường là quá mức), cho phép các tổ chức điều chỉnh kích thước kết nối phù hợp mà không ảnh hưởng đến hiệu suất. Megaport, một nhà cung cấp Mạng lưới dưới dạng Dịch vụ (NaaS) hàng đầu và AWS Marketplace Đối tác của chúng tôi là một trong những đơn vị đầu tiên cung cấp kết nối 25 Gbps này trên nhiều Địa điểm Kết nối Trực tiếp Edge thông qua Mạng lưới Định nghĩa Phần mềm Toàn cầu, trải dài hàng trăm trung tâm dữ liệu trên toàn thế giới. Để biết thông tin mới nhất, vui lòng tham khảo Magaport public network footprint page.\nSử dụng nền tảng tự phục vụ của Megaport, các tổ chức có thể cung cấp, mở rộng quy mô và quản lý kết nối AWS hiệu suất cao chỉ trong vài phút thay vì hàng tuần hoặc hàng tháng. Trong bài viết này, chúng tôi sẽ mô tả cách sự kết hợp mạnh mẽ giữa các dịch vụ AWS và Megaport cho phép các kiến ​​trúc sư đám mây và lãnh đạo CNTT xây dựng các mạng lai thế hệ tiếp theo hỗ trợ các ứng dụng dữ liệu chuyên sâu, tăng cường bảo mật và tối ưu hóa chi phí — đồng thời vẫn duy trì tính linh hoạt để thích ứng với nhu cầu kinh doanh thay đổi.\nĐiều kiện tiên quyết Chúng tôi giả định rằng bạn đã quen thuộc với các cấu trúc mạng cốt lõi trên AWS, đặc biệt là Direct Connect. Mặc dù chúng tôi không đi sâu vào định nghĩa, nhưng chúng tôi sẽ nêu bật vai trò của nó trong việc hỗ trợ các kiến ​​trúc kết nối lai liên quan đến các kết nối được lưu trữ trên Direct Connect. Nếu bạn chưa quen với những khái niệm này, chúng tôi khuyên bạn nên xem lại tài liệu Direct Connect để biết thêm chi tiết choosing between Direct Connect dedicated and hosted connections.\nĐối với kiến ​​thức nền tảng, Getting Started with AWS Direct Connect hướng dẫn cũng là một nguồn tài nguyên hữu ích.\nCác trường hợp sử dụng chính cho Kết nối trực tiếp 25 Gbps Các phần sau đây sẽ trình bày chi tiết các trường hợp sử dụng chính của Direct Connect 25 Gbps.\n1. Di chuyển đám mây Di chuyển dữ liệu doanh nghiệp quy mô lớn liên quan đến việc chuyển các tập dữ liệu khổng lồ. Kết nối lưu trữ 25 Gbps cho phép các tổ chức rút ngắn thời gian di chuyển từ vài ngày xuống còn vài giờ mà vẫn duy trì hiệu suất ổn định và an toàn. Việc di chuyển cơ sở dữ liệu 100 TB, vốn mất hơn 22 giờ với kết nối 10 Gbps, có thể hoàn thành trong khoảng 9 giờ, giúp rút ngắn đáng kể thời gian đưa vào sản xuất.\nConnection Speed Data volume Estimated Migration Time Performance Gain 10 Gbps 100 TB ~22 hours Baseline 25 Gbps 100 TB ~9 hours ~59% faster Table 1: Bandwidth effects on large-scale data migration\n2. Di chuyển dữ liệu Các tổ chức thu thập dữ liệu từ các vị trí biên hoặc môi trường tại chỗ được hưởng lợi từ các kết nối có thông lượng cao, có thể dự đoán trước cho các khối lượng công việc phân tích, sao lưu và lưu trữ. Các công ty truyền thông có thể chuyển các tệp video lớn một cách hiệu quả giữa các bộ biên tập và AWS, trong khi các tổ chức chăm sóc sức khỏe có thể di chuyển các tập dữ liệu hình ảnh lên đám mây để phân tích AI mà vẫn duy trì tính tuân thủ thông qua kết nối riêng tư. Cấp độ 25 Gbps đặc biệt hữu ích cho các triển khai Internet vạn vật (IoT) tạo ra khối lượng lớn dữ liệu cảm biến, các hoạt động sao lưu quy mô lớn với các yêu cầu Mục tiêu Điểm Phục hồi (RPO) khắt khe, và các tổ chức đào tạo mô hình học máy (ML) với các tập dữ liệu tại chỗ đáng kể.\n3. Hỗ trợ đám mây lai Khi kiến ​​trúc lai ngày càng phổ biến, việc kết nối đáng tin cậy giữa các hệ thống tại chỗ và AWS là điều cần thiết. Kết nối lưu trữ 25 Gbps của Megaport cung cấp dung lượng cần thiết cho cơ sở dữ liệu phân tán, giải pháp lưu trữ lai và các dịch vụ vi mô trải rộng trên nhiều môi trường. Các tổ chức có thể triển khai các chính sách bảo mật nhất quán và trải nghiệm ứng dụng liền mạch trên toàn bộ ngăn xếp công nghệ của mình, đồng thời duy trì khoảng trống hiệu suất cần thiết cho các giai đoạn khối lượng công việc cao điểm và tăng trưởng trong tương lai.\n4. Ứng dụng nhạy cảm với độ trễ Các ứng dụng như nền tảng giao dịch tài chính, hệ thống tự động và công cụ cộng tác thời gian thực đều yêu cầu độ trễ tối thiểu. Kết nối chuyên dụng 25 Gbps duy trì hiệu suất ổn định, độ trễ thấp bằng cách bỏ qua internet công cộng, đồng thời cung cấp đủ băng thông để ngăn ngừa tắc nghẽn trong giờ cao điểm. Đối với các ngành công nghiệp đòi hỏi tốc độ tính bằng mili giây — chẳng hạn như giao dịch tần suất cao, trò chơi trực tuyến hoặc y tế từ xa — hiệu suất dự đoán được của Direct Connect mang lại lợi thế cạnh tranh đồng thời duy trì tính bảo mật thông qua kết nối riêng tư.\nLợi ích cho các ngành như: giao dịch tần suất cao, trò chơi trực tuyến, y tế từ xa.\n5. Kiểm soát chi phí Gói 25 Gbps mang đến một giải pháp tiết kiệm chi phí để mở rộng dung lượng mạng mà không cần cung cấp quá mức. Các tổ chức trước đây buộc phải lựa chọn giữa kết nối 10 Gbps không đủ hoặc kết nối 100 Gbps quá mức giờ đây có thể chọn điểm cân bằng tối ưu, thường tiết kiệm 50-60% so với tùy chọn 100 Gbps. Nền tảng linh hoạt của Megaport cũng cho phép doanh nghiệp điều chỉnh băng thông khi nhu cầu thay đổi, hỗ trợ tối ưu hóa chi phí trong suốt vòng đời ứng dụng mà vẫn đảm bảo hiệu suất cần thiết cho khối lượng công việc đám mây hiện đại.\nLợi ích triển khai AWS Direct Connect 25 Gbps với Megaport Các phần sau đây sẽ hướng dẫn chi tiết về những lợi ích khi triển khai Direct Connect 25 Gbps với Megaport.\n1. Chuyển dữ liệu riêng tư, an toàn Các kết nối lưu trữ của Megaport cung cấp một đường dẫn riêng tư đến AWS, bỏ qua internet công cộng, giúp tăng cường quyền riêng tư dữ liệu, giảm thiểu nguy cơ bị tấn công bởi các mối đe dọa bảo mật phổ biến và đảm bảo tuân thủ cho các khối lượng công việc nhạy cảm. Kết nối riêng tư này ngày càng quan trọng khi các quy định như Quy định Bảo vệ Dữ liệu Chung (GDPR), Đạo luật Khả năng Chuyển đổi và Trách nhiệm Giải trình Bảo hiểm Y tế (HIPAA) và các yêu cầu cụ thể của ngành áp đặt các biện pháp kiểm soát chặt chẽ hơn đối với việc di chuyển và bảo vệ dữ liệu. Cấp độ 25 Gbps mang lại khả năng bảo mật này mà không ảnh hưởng đến hiệu suất cần thiết cho các ứng dụng dữ liệu chuyên sâu hiện đại.\n2. Dễ sử dụng Cổng thông tin tự phục vụ của Megaport cho phép khách hàng cung cấp, mở rộng và quản lý kết nối Direct Connect chỉ trong vài phút. Tính linh hoạt này giúp các nhóm thích ứng nhanh chóng với nhu cầu dự án thay đổi mà không phải chịu chi phí quản lý thủ công. Các tổ chức có thể thiết lập kết nối với AWS Regions gần như theo thời gian thực thay vì phải chờ hàng tuần hoặc hàng tháng cho các mạch viễn thông truyền thống, do đó đẩy nhanh các sáng kiến ​​đám mây và giảm thời gian tạo ra giá trị cho các dự án mới.\n3. Khả năng tiếp cận toàn cầu Sự hiện diện của Megaport tại hơn 975 trung tâm dữ liệu trên hơn 26 quốc gia cho phép nó cung cấp quyền truy cập gần như phổ biến vào Direct Connect locations. Các tổ chức có dấu chân phân tán có thể chuẩn hóa phương pháp kết nối nhất quán trên khắp các Vùng AWS, tinh giản kiến ​​trúc và vận hành đồng thời duy trì hiệu suất cao. Phạm vi phủ sóng toàn cầu này đặc biệt có giá trị đối với các doanh nghiệp đa quốc gia triển khai hoạt động theo mặt trời hoặc các tổ chức có yêu cầu nghiêm ngặt về chủ quyền dữ liệu.\n4. Tính linh hoạt và khả năng mở rộng Khi nhu cầu tăng lên, khách hàng có thể điều chỉnh băng thông linh hoạt thông qua cổng Megaport. Tính linh hoạt này cho phép các nhóm CNTT mở rộng quy mô một cách hiệu quả về chi phí mà vẫn duy trì hiệu suất tối ưu cho các khối lượng công việc quan trọng. Cấp 25 Gbps cung cấp một giải pháp trung gian lý tưởng, có thể được triển khai như một giải pháp dài hạn hoặc làm bước đệm cho chiến lược mạng lưới đám mây rộng lớn hơn.\nBắt đầu với AWS và Megaport 25 Gbps Các phần sau đây sẽ hướng dẫn bạn cách sử dụng AWS và Megaport với kết nối lưu trữ 25 Gbps.\nĐiều kiện tiên quyết Tài khoản Megaport đang hoạt động và có chức năng thanh toán. Tài khoản AWS có quyền truy cập Direct Connect. Bước 1: Tạo MCR Megaport Đăng nhập vào Megaport Portal. Lựa chọn +Add Service và chọn MCR (Bộ định tuyến đám mây Megaport) như thể hiện trong Hình 1. Đảm bảo rằng MCR hỗ trợ dung lượng tối thiểu là 25 Gbps, vì điều này sẽ quyết định tốc độ kết nối tối đa khả dụng cho kết nối lưu trữ của bạn. Làm theo hướng dẫn trên màn hình để hoàn tất thiết lập. Bạn có thể tìm thêm thông tin chi tiết trong Creating MCR Documentation. Bước 2: Tạo kết nối lưu trữ từ Megaport đến AWS Trong Cổng thông tin Megaport, hãy chọn MCR của bạn và nhấp vào + Add Connection. Chọn AWS Direct Connect từ các tùy chọn Đám mây. Cung cấp thông tin cần thiết và làm theo hướng dẫn: Creating a Hosted Connection Connection Name: tên mô tả cho kết nối của bạn. Service Level Reference: cung cấp mã định danh duy nhất cho mục đích thanh toán hoặc theo dõi. Rate Limit: đặt thành 25.000 Mbps để cung cấp kết nối 25 Gbps. Gửi và triển khai kết nối. Bạn cũng có thể tạo VIF lưu trữ và các loại kết nối khác (ví dụ: VIF công cộng, VIF trung chuyển), tùy thuộc vào trường hợp sử dụng của bạn.\nBước 3: Chấp nhận kết nối được lưu trữ trong AWS Đăng nhập vào AWS Console và đi đến AWS Direct Connect. Trong ngăn điều hướng, chọn Connections. Chọn kết nối được lưu trữ và chọn View details. Select the confirmation check box and choose Accept. Bước 4: Tạo Giao diện ảo cho kết nối được lưu trữ: Sau khi chấp nhận kết nối, hãy chọn nó và chọn Create Virtual Interface như thể hiện trong Hình 3. Chọn loại giao diện – thông thường Private để truy cập vào VPC. Cấu hình như sau: Tên giao diện ảo. ID VLAN (phải khớp với VLAN được sử dụng trong cấu hình Megaport). BGP ASN (mặc định của bạn hoặc AWS). Địa chỉ IP ngang hàng BGP (AWS cung cấp một bên; bạn chỉ định bên của mình). Hiệp hội Cổng kết nối: Chọn Cổng kết nối riêng ảo hoặc AWS Transit Gateway được đính kèm vào VPC của bạn. Chọn Create. Bước 5: Cấu hình BGP trên Megaport MCR Quay lại Cổng Megaport. Chỉnh sửa Virtual Cross Connect (VXC) để khớp với thông tin chi tiết BGP do AWS cung cấp. Hiển thị thông tin bạn cần nhập: Địa chỉ IP ngang hàng BGP (của bạn và của AWS). ASN của bạn (hoặc ASN do AWS chỉ định). Lưu và áp dụng cấu hình. Kết luận Trong bài viết này, chúng tôi đã khám phá cách các kết nối lưu trữ 25 Gbps của AWS Direct Connect thông qua Megaport có thể chuyển đổi chiến lược kết nối đám mây của bạn. Chúng tôi đã đề cập đến các trường hợp sử dụng thiết yếu như di chuyển lên đám mây quy mô lớn, ứng dụng dữ liệu chuyên sâu, triển khai đám mây lai và khối lượng công việc nhạy cảm với độ trễ. Bạn đã tìm hiểu cách giải pháp này mang lại khả năng truyền dữ liệu riêng tư, an toàn với khả năng mở rộng linh hoạt, đồng thời tiết kiệm chi phí đáng kể so với các giải pháp thay thế 100 Gbps. Chúng tôi cũng hướng dẫn từng bước thiết lập kết nối lưu trữ 25 Gbps bằng nền tảng tự phục vụ của Megaport.\nKêu gọi hành động Đánh giá yêu cầu về thông lượng mạng hiện tại và tương lai của bạn. Khám phá các tùy chọn Kết nối trực tiếp được lưu trữ 25 Gbps trên AWS Direct Connect Partners page. Di chuyển đến Megaport’s AWS solution page để tìm hiểu thêm hoặc bắt đầu cung cấp dịch vụ tự phục vụ. Về các tác giả Mokshith Kumar\nKiến trúc sư Giải pháp Chuyên gia GTM Cấp cao về Mạng Lõi tại AWS, hỗ trợ ISV và FSI Bắc Mỹ.\nVai trò: phát triển chiến lược GTM, dẫn dắt sáng kiến chiến lược, thúc đẩy áp dụng dịch vụ mạng AWS. Sở thích: bơi lội, âm nhạc. Miranda Li\nKiến trúc sư Giải pháp Cấp cao tại AWS, chuyên ISV và kiến trúc đám mây gốc.\n4 năm kinh nghiệm hỗ trợ ISV đổi mới, mở rộng trên AWS. Chuyên môn: IaaS, kiến trúc mạng, bảo mật, phân tích dữ liệu. Sở thích: cầu lông, chạy bộ, các hoạt động ngoài trời. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/4-eventparticipated/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “AWS Cloud Club – First Cloud AI Journey Workshop” Mục Đích Của Sự Kiện Sự kiện “AWS Cloud Club – First Cloud AI Journey” được tổ chức nhằm:\nCung cấp định hướng cho sinh viên bước đầu tiếp cận điện toán đám mây và AI. Giới thiệu cộng đồng AWS Cloud Clubs và vai trò của họ trong việc lan tỏa kiến thức cloud. Trang bị kiến thức nền tảng để học viên chuẩn bị tham gia các hành trình cloud/AI chuyên sâu. Kết nối các bạn trẻ yêu thích công nghệ với cộng đồng AWS tại Việt Nam. Tạo môi trường trao đổi, chia sẻ kinh nghiệm giữa các thành viên Cloud Club của nhiều trường đại học. Danh Sách Diễn Giả Le Vu Xuan An – AWS Cloud Club Captain HCMUTE Tran Duc Anh – AWS Cloud Club Captain SGU Tran Doan Cong Ly – AWS Cloud Captain PTIT Danh Hoang Hieu Nghi – AWS CLoud Captain HUFLIT Nội Dung Nổi Bật 1. Giới thiệu AWS Cloud Club Cloud Club là cộng đồng do AWS hỗ trợ, dành cho sinh viên quan tâm đến Cloud Computing, AI/ML và DevOps. Mỗi trường đại học có Cloud Club Captain – người dẫn dắt hoạt động học thuật. Cộng đồng mang mục tiêu tạo ra: Không gian học tập chủ động. Nơi chia sẻ kinh nghiệm chuẩn bị certification. Các workshop thực hành từ cơ bản đến nâng cao. 2. First Cloud AI Journey – Lộ trình học Cloud + AI cho sinh viên Trong sự kiện, diễn giả trình bày:\nTổng quan chương trình First Cloud AI Journey. Lộ trình tiếp cận từ AWS Cloud fundamentals → hands-on labs → AI/ML foundation → project thực tế. Giới thiệu các chủ đề trọng tâm: Điện toán đám mây (EC2, S3, Lambda…) AI cơ bản Kiến thức cần có cho GenAI (dữ liệu, vector DB, prompt engineering…) Các công cụ AWS định hướng AI như Bedrock, Q Developer (ở các session tiếp theo) 3. Chia sẻ về hành trình học Cloud của các Cloud Club Captains Nội dung chia sẻ xoay quanh:\nCách bắt đầu học AWS từ con số 0 mà không bị “ngợp”. Quy trình chuẩn bị thi các chứng chỉ: Cloud Practitioner Solutions Architect – Associate Cách tham gia hoạt động trong cộng đồng để học nhanh hơn. Những sai lầm phổ biến của người mới học cloud: Không thực hành. Không đọc Well-Architected. Không quản lý thời gian học tập. Kinh nghiệm tìm cơ hội trong ngành: Làm dự án cá nhân (pet projects). Viết note, blog, chia sẻ kiến thức. Tạo portfolio cloud/AI chuyên nghiệp. 4. Hoạt động giao lưu \u0026amp; tương tác Trong sự kiện có các phần:\nQ\u0026amp;A mở giữa diễn giả và người tham dự. Chia sẻ thật về: Thói quen học cloud hiệu quả. Các nguồn tài liệu miễn phí. Lộ trình thi chứng chỉ. Giao lưu networking giữa các bạn đến từ nhiều trường. Những Gì Học Được 1. Tư duy định hướng Cloud \u0026amp; AI Hiểu được sự quan trọng của nền tảng cloud trước khi học AI/GenAI. Biết cách xây dựng lộ trình học phù hợp với bản thân. Tư duy “learn by doing” — thực hành mới là điểm quan trọng nhất. 2. Kiến thức cộng đồng và cơ hội phát triển Cộng đồng AWS Cloud Club đóng vai trò quan trọng giúp sinh viên: Học nhanh hơn. Có người dẫn dắt. Có cơ hội tham gia các dự án/hackathon. Học được cách tận dụng networking để phát triển sự nghiệp. 3. Kỹ năng học tập và chuẩn bị chứng chỉ Cách tiếp cận exam AWS thực tế. Những công cụ hỗ trợ học: AWS Skill Builder Cloud Quest Digital Training miễn phí Chiến lược hạn chế “burn-out” trong hành trình học cloud dài hạn. 4. Tư duy AI thời đại mới Cloud là nền tảng bắt buộc để triển khai AI/ML và GenAI. AI không bắt đầu từ mô hình — mà từ dữ liệu, cơ sở hạ tầng, và business understanding. Ứng Dụng Vào Công Việc Xây dựng roadmap học Cloud Practitioner để có kiến thức nền. Tham gia hoạt động Cloud Club để mở rộng network. Bắt đầu thực hiện mini-project: Deploy website lên S3/CloudFront. Tạo API serverless bằng AWS Lambda. Trải nghiệm các dịch vụ AI cơ bản trong AWS ở các workshop tiếp theo. Ghi chép và chia sẻ lại kiến thức đã học để củng cố. Trải Nghiệm Trong Event Tham gia “AWS Cloud Club – First Cloud AI Journey” mang đến nhiều trải nghiệm thú vị:\nHọc hỏi từ người đi trước Được nghe chia sẻ thực tế về hành trình học AWS. Học được mindset tự học hiệu quả, giúp tránh mất thời gian. Không khí sự kiện Không gian mở, nhiều bạn sinh viên đam mê cloud. Giảng trình trực quan, slide rõ ràng và hiện đại. Networking Kết nối được với nhiều bạn từ các trường khác nhau. Có thêm góc nhìn mới về phát triển sự nghiệp trong ngành cloud. Động lực học tập Buổi workshop giúp mình định hướng rõ ràng hơn. Tạo thêm động lực để theo đuổi lộ trình cloud \u0026amp; AI nghiêm túc. Một số hình ảnh trong sự kiện Tổng thể, sự kiện không chỉ truyền cảm hứng mạnh mẽ mà còn giúp tôi định hình rõ ràng con đường học tập về Cloud và AI, đồng thời xây dựng được kết nối với cộng đồng công nghệ đầy nhiệt huyết.\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/1-worklog/1.12-week12/",
	"title": "Worklog Tuần 12",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 12: Trình bày dự án của nhóm trước các mentor và giảng viên hướng dẫn. Ghi nhận phản hồi để cải thiện kiến trúc, nội dung triển khai và chất lượng phần thuyết trình. Xác định các phần cần chỉnh sửa trước khi nộp báo cáo cuối kỳ. Tổng hợp toàn bộ góp ý và lập danh sách công việc cần thực hiện ở tuần tiếp theo. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Chuẩn bị slide thuyết trình cuối cùng - Rà soát phân công nhiệm vụ và phần trình bày của từng thành viên 24/11/2025 24/11/2025 Slide deck 3 - Thực hiện buổi rehearsal nội bộ - Điều chỉnh thời gian và chuyển đoạn giữa các thành viên 25/11/2025 25/11/2025 Ghi chú nội bộ 4 - Trình bày dự án chính thức trước các mentor - Trình bày kiến trúc hệ thống, CI/CD pipeline, cost estimate và demo 26/11/2025 26/11/2025 Tài liệu thuyết trình 5 - Ghi nhận phản hồi từ mentor về kiến trúc, bảo mật, thiết kế hệ thống và cách trình bày - Tổng hợp toàn bộ góp ý 27/11/2025 27/11/2025 Mentor feedback 6 - Phân tích phản hồi đã nhận được - Xác định những phần cần chỉnh sửa về kiến trúc, lưu đồ, nội dung slide 28/11/2025 28/11/2025 Góp ý tổng hợp 7 - Chỉnh sửa tài liệu và slide theo phản hồi của mentor - Chuẩn bị danh sách action items cho tuần tiếp theo 29–30/11/2025 30/11/2025 Proposal, Slide deck Kết quả đạt được tuần 12: Trình bày dự án thành công trước mentor và nhận được phản hồi chi tiết về kiến trúc, nội dung triển khai và phong cách thuyết trình. Ghi nhận đầy đủ góp ý liên quan đến: Cải thiện kiến trúc hệ thống Làm rõ data flow và lớp mạng Giải thích CI/CD pipeline mạch lạc hơn Tối ưu chi phí AWS Tăng cường bảo mật trong thiết kế hệ thống Hoàn thiện lại slide deck và tài liệu dự án dựa trên góp ý từ mentor. Xác định các đầu mục quan trọng cần chỉnh sửa cho giai đoạn cuối trước khi nộp bài. Hoàn thành rehearsal và buổi trình bày giữa kỳ đúng tiến độ. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/1-worklog/1.11-week11/",
	"title": "Worklog Tuần 11",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 11: Tổng hợp nội dung từ 2 proposal hiện có của nhóm. Chuẩn bị tài liệu để làm slide thuyết trình báo cáo cuối kỳ. Chuẩn hóa nội dung, xác định phần trình bày chính và phần bổ sung. Đảm bảo tính nhất quán giữa kiến trúc hệ thống và kế hoạch triển khai. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Rà soát toàn bộ nội dung Proposal.docx - Liệt kê các mục quan trọng cần đưa vào slide 17/11/2025 17/11/2025 Proposal.docx 3 - Tổng hợp nội dung Executive Summary, Problem Statement, Solution Overview - Chỉnh sửa nội dung cho ngắn gọn, phù hợp trình chiếu 18/11/2025 18/11/2025 Proposal.docx 4 - Tách và chuẩn hóa phần Solution Architecture + Networking layer + Application layer + CI/CD + Security \u0026amp; Monitoring 19/11/2025 19/11/2025 Proposal Template.docx 5 - Tổng hợp bảng AWS Cost Estimate - Rà lại Risk Assessment và Timeline - Chuyển nội dung sang dạng bullet ngắn gọn để đưa vào slide 20/11/2025 20/11/2025 Proposal.docx 6 - Xây dựng outline slide thuyết trình: + Summary + Problem + Architecture + Cost + Risk + Roadmap 21/11/2025 21/11/2025 Tổng hợp nội dung 7 - Chuẩn hóa toàn bộ nội dung sang tiếng Anh - Kiểm tra tính logic giữa các phần - Chuẩn bị tài liệu bàn giao cho nhóm thiết kế slide 22/11/2025 23/11/2025 Proposal.docx, Proposal Template Kết quả đạt được tuần 11: Hoàn tất tổng hợp nội dung từ 2 proposal (đầy đủ các phần Executive Summary, Problem, Solution, Architecture, Risk, Cost…). Xây dựng outline slide trình bày, chia rõ các phần chính và phần mở rộng. Chuẩn hóa toàn bộ nội dung sang tiếng Anh để triển khai slide báo cáo cuối kỳ. Đảm bảo tính nhất quán giữa kiến trúc hệ thống, kế hoạch triển khai và nội dung trình bày. Sẵn sàng chuyển sang giai đoạn thiết kế slide và chuẩn bị cho buổi báo cáo. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/1-worklog/1.10-week10/",
	"title": "Worklog Tuần 10",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 10: Xây dựng workshop dựa trên nội dung của Proposal và Proposal Template. Xác định các phần sẽ được trình bày trong workshop: Overview, Architecture, CI/CD, Cost, Security… Chuẩn hóa nội dung workshop theo cấu trúc AWS. Chuẩn bị tài liệu để nhóm có thể trình bày hiệu quả trong buổi workshop. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Đọc lại proposal nhóm BDSS - Nghiên cứu Proposal Template - Xác định phạm vi workshop cần xây dựng 10/11/2025 10/11/2025 proposal.docx Proposal Template.docx 3 - Phân tích cấu trúc workshop dựa trên template - Chọn các phần phù hợp từ hai proposal để đưa vào workshop 11/11/2025 11/11/2025 Proposal Template.docx 4 - Viết nội dung cho các mục: Introduction, Background, Objectives của workshop - Chuẩn hóa flow và wording theo format AWS 12/11/2025 12/11/2025 proposal.docx 5 - Xây dựng phần Workshop Content chính: + System Architecture + Data Flow + CI/CD Pipeline + Security Model 13/11/2025 14/11/2025 proposal.docx 6 - Tổng hợp AWS Cost Estimate, Risk Assessment để đưa vào workshop - Điều chỉnh nội dung theo bố cục workshop 14/11/2025 15/11/2025 Proposal Template.docx 7 - Hoàn thiện bản Workshop Draft - Chỉnh sửa định dạng, heading, flow trình bày - Gửi tài liệu workshop cho nhóm review 16/11/2025 16/11/2025 — Kết quả đạt được tuần 10: Đã xây dựng xong bản Workshop Draft dựa vào Proposal \u0026amp; Proposal Template. Chuẩn hóa nội dung workshop gồm: Introduction, Background, Architecture, CI/CD, Cost, Security, Roadmap. Kiến trúc BDSS được mô tả theo cấu trúc workshop rõ ràng và dễ trình bày. Tổng hợp đầy đủ phần chi phí, rủi ro và kế hoạch triển khai để đưa vào workshop. Tài liệu workshop đã sẵn sàng để nhóm duyệt và chuẩn bị cho buổi trình bày. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/2-proposal/",
	"title": "Bản đề xuất",
	"tags": [],
	"description": "",
	"content": "Blood Donation Support System Phần mềm hỗ trợ hiến máu 1. Tóm tắt điều hành Blood Donation Support System (BDSS)** là nền tảng web hỗ trợ quản lý và kết nối người hiến máu với cơ sở y tế. Dự án được phát triển bởi nhóm sinh viên tại TP. Hồ Chí Minh nhằm tối ưu quy trình hiến máu, giảm tải khâu tìm kiếm người hiến và nâng cao hiệu quả truyền thông y tế.\nHệ thống được xây dựng trên kiến trúc AWS Cloud, sử dụng Amazon EC2, Amazon RDS, API Gateway, Cognito và CI/CD Pipeline (GitLab + CodePipeline) để tự động triển khai. BDSS hỗ trợ bốn nhóm người dùng (Guest, Member, Staff, Admin), cung cấp tính năng tra cứu, đăng ký hiến máu, quản lý kho máu, theo dõi quy trình hiến máu và báo cáo trực quan.\n2. Tuyên bố vấn đề Vấn đề hiện tại\nCác cơ sở y tế hiện đang quản lý quy trình hiến máu thủ công hoặc thông qua các công cụ rời rạc. Việc tìm kiếm người hiến máu phù hợp nhóm máu hoặc theo khu vực gặp khó khăn, đặc biệt trong tình huống khẩn cấp. Ngoài ra, hệ thống lưu trữ dữ liệu chưa đồng bộ, gây khó khăn trong việc phân tích, báo cáo và tối ưu chiến dịch hiến máu.\nGiải pháp\nPhát triển nền tảng hỗ trợ hiến máu toàn diện trên AWS Cloud, với các chức năng quản lý hiến máu, tìm kiếm người hiến và người cần máu theo nhóm máu hoặc vị trí địa lý, tích hợp xác thực người dùng qua Amazon Cognito và quản trị dữ liệu trên Amazon RDS. Frontend được triển khai qua Route 53 + CloudFront, backend thông qua API Gateway – EC2, cơ sở dữ liệu MySQL trên Amazon RDS, và pipeline tự động CI/CD bằng GitLab – CodePipeline.\nLợi ích và hoàn vốn đầu tư (ROI)\nGiảm 60–70% thời gian tìm kiếm người hiến máu phù hợp. Tăng độ chính xác thông tin nhóm máu và vị trí. Tối ưu chi phí vận hành với kiến trúc cloud linh hoạt, trả phí theo mức sử dụng. Cải thiện khả năng phản hồi trong các trường hợp máu khẩn cấp\n3. Kiến trúc giải pháp Nền tảng áp dụng kiến trúc AWS Serverless để quản lý dữ liệu từ 5 trạm dựa trên Raspberry Pi, có thể mở rộng lên 15 trạm. Dữ liệu được tiếp nhận qua AWS IoT Core, lưu trữ trong S3 data lake và xử lý bởi AWS Glue Crawlers và ETL jobs để chuyển đổi và tải vào một S3 bucket khác cho mục đích phân tích. Lambda và API Gateway xử lý bổ sung, trong khi Amplify với Next.js cung cấp bảng điều khiển được bảo mật bởi Cognito.\nHệ thống được chia thành 4 lớp chính:\nEdge Networking Layer: Route 53 quản lý domain và DNS routing. CloudFront tăng tốc độ tải trang và phân phối nội dung tĩnh. AWS WAF bảo vệ chống tấn công web (SQL injection, DDoS).\nApplication \u0026amp; Data Layer: Amazon EC2: Triển khai backend API và xử lý nghiệp vụ chính. Amazon RDS (MySQL): Lưu trữ dữ liệu người hiến máu, nhóm máu, lịch sử hiến. API Gateway: Giao tiếp giữa frontend và backend. Elastic Load Balancer (ELB): Phân phối tải cho các instance EC2. NAT Gateway \u0026amp; Internet Gateway: Hỗ trợ kết nối Internet an toàn.\nCI/CD \u0026amp; DevOps Layer: GitLab: Quản lý mã nguồn. AWS CodePipeline, CodeBuild: Triển khai và cập nhật tự động.\nMonitoring \u0026amp; Security Layer: Amazon Cognito: Xác thực và phân quyền (Guest, Member, Staff, Admin). CloudWatch, CloudTrail, IAM, Secrets Manager: Giám sát, bảo mật, cảnh báo hệ thống. SNS: Gửi thông báo khi có sự kiện (máu khẩn cấp, người hiến phù hợp).\n4. Triển khai kỹ thuật Các giai đoạn triển khai\nPhân tích \u0026amp; thiết kế (Tháng 1) Thu thập yêu cầu, xác định use case, thiết kế ERD và kiến trúc AWS. Thiết lập hạ tầng \u0026amp; pipeline (Tháng 2) Cấu hình Route 53, CloudFront, EC2, RDS và CI/CD trên AWS. Phát triển \u0026amp; kiểm thử (Tháng 3–4) Xây dựng các module chính: đăng ký hiến máu, tìm kiếm, quản lý kho máu. Tích hợp Cognito và hệ thống cảnh báo SNS. Triển khai \u0026amp; vận hành (Tháng 5) Triển khai sản phẩm chính thức và giám sát bằng CloudWatch. Yêu cầu kỹ thuật chính: Frontend: React/Next.js hoặc Angular (deploy qua S3/CloudFront). Backend: Node.js/Express trên EC2, giao tiếp qua REST API Gateway. Database: Amazon RDS MySQL, tối ưu query và backup định kỳ. CI/CD: GitLab → CodeBuild → CodePipeline → EC2. Auth: Cognito (4 vai trò: Guest, Member, Staff, Admin). Alert \u0026amp; Logs: SNS + CloudWatch + CloudTrail.\n5. Lộ trình \u0026amp; Mốc triển khai Thời gian Giai đoạn Kết quả chính Tháng 1 Phân tích yêu cầu \u0026amp; thiết kế Kiến trúc AWS + sơ đồ use case Tháng 2 Thiết lập hạ tầng \u0026amp; pipeline EC2, RDS, API Gateway hoạt động Tháng 3–4 Phát triển \u0026amp; kiểm thử Hoàn thiện các module chính Tháng 5 Triển khai chính thức Hệ thống hoạt động ổn định, có báo cáo Dashboard 6. Ước tính ngân sách Dịch vụ Ước tính chi phí/tháng (USD) Ghi chú EC2 (t2.micro) 3.50 Backend REST API Amazon RDS (MySQL) 2.80 20 GB storage API Gateway 0.50 5.000 request CloudFront + S3 0.80 Website + CDN Route 53 0.50 Domain \u0026amp; DNS Cognito 0.10 \u0026lt;100 người dùng CloudWatch + Logs 0.30 Giám sát và cảnh báo CI/CD (CodePipeline, CodeBuild) 0.40 Triển khai tự động Tổng cộng 8.9 USD/tháng ~106.8 USD/năm Toàn bộ chi phí có thể điều chỉnh dựa trên AWS Free Tier hoặc sử dụng spot instance.\n7. Đánh giá rủi ro Rủi ro Ảnh hưởng Xác suất Biện pháp giảm thiểu Mất kết nối Internet Trung bình Trung bình Dự phòng trên EC2 backup Tấn công DDoS Cao Thấp AWS WAF + CloudFront Lỗi dữ liệu người dùng Cao Thấp RDS backup + IAM hạn chế truy cập Chi phí vượt mức Trung bình Thấp Cảnh báo ngân sách AWS Gián đoạn triển khai CI/CD Thấp Trung bình Kiểm tra pipeline trước khi merge 8. Kết quả kỳ vọng Kỹ thuật: Hệ thống cloud-native, CI/CD tự động, hỗ trợ đa người dùng và bảo mật cao. Ứng dụng: Giúp cơ sở y tế quản lý hiến máu hiệu quả, giảm thiểu quy trình thủ công. Mở rộng: Có thể nhân rộng cho nhiều bệnh viện khác, tích hợp thêm AI phân tích nhu cầu nhóm máu hoặc dự đoán đợt hiến máu sắp tới.\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/5-workshop/5.2-prerequiste/",
	"title": "Các bước chuẩn bị",
	"tags": [],
	"description": "",
	"content": "IAM permissions Gắn IAM permission policy sau vào tài khoản aws user của bạn để triển khai và dọn dẹp tài nguyên trong workshop này.\n{\r\u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,\r\u0026#34;Statement\u0026#34;: [\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;cloudformation:*\u0026#34;,\r\u0026#34;cloudwatch:*\u0026#34;,\r\u0026#34;ec2:AcceptTransitGatewayPeeringAttachment\u0026#34;,\r\u0026#34;ec2:AcceptTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:AllocateAddress\u0026#34;,\r\u0026#34;ec2:AssociateAddress\u0026#34;,\r\u0026#34;ec2:AssociateIamInstanceProfile\u0026#34;,\r\u0026#34;ec2:AssociateRouteTable\u0026#34;,\r\u0026#34;ec2:AssociateSubnetCidrBlock\u0026#34;,\r\u0026#34;ec2:AssociateTransitGatewayRouteTable\u0026#34;,\r\u0026#34;ec2:AssociateVpcCidrBlock\u0026#34;,\r\u0026#34;ec2:AttachInternetGateway\u0026#34;,\r\u0026#34;ec2:AttachNetworkInterface\u0026#34;,\r\u0026#34;ec2:AttachVolume\u0026#34;,\r\u0026#34;ec2:AttachVpnGateway\u0026#34;,\r\u0026#34;ec2:AuthorizeSecurityGroupEgress\u0026#34;,\r\u0026#34;ec2:AuthorizeSecurityGroupIngress\u0026#34;,\r\u0026#34;ec2:CreateClientVpnEndpoint\u0026#34;,\r\u0026#34;ec2:CreateClientVpnRoute\u0026#34;,\r\u0026#34;ec2:CreateCustomerGateway\u0026#34;,\r\u0026#34;ec2:CreateDhcpOptions\u0026#34;,\r\u0026#34;ec2:CreateFlowLogs\u0026#34;,\r\u0026#34;ec2:CreateInternetGateway\u0026#34;,\r\u0026#34;ec2:CreateLaunchTemplate\u0026#34;,\r\u0026#34;ec2:CreateNetworkAcl\u0026#34;,\r\u0026#34;ec2:CreateNetworkInterface\u0026#34;,\r\u0026#34;ec2:CreateNetworkInterfacePermission\u0026#34;,\r\u0026#34;ec2:CreateRoute\u0026#34;,\r\u0026#34;ec2:CreateRouteTable\u0026#34;,\r\u0026#34;ec2:CreateSecurityGroup\u0026#34;,\r\u0026#34;ec2:CreateSubnet\u0026#34;,\r\u0026#34;ec2:CreateSubnetCidrReservation\u0026#34;,\r\u0026#34;ec2:CreateTags\u0026#34;,\r\u0026#34;ec2:CreateTransitGateway\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayPeeringAttachment\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayPrefixListReference\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayRoute\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayRouteTable\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:CreateVpc\u0026#34;,\r\u0026#34;ec2:CreateVpcEndpoint\u0026#34;,\r\u0026#34;ec2:CreateVpcEndpointConnectionNotification\u0026#34;,\r\u0026#34;ec2:CreateVpcEndpointServiceConfiguration\u0026#34;,\r\u0026#34;ec2:CreateVpnConnection\u0026#34;,\r\u0026#34;ec2:CreateVpnConnectionRoute\u0026#34;,\r\u0026#34;ec2:CreateVpnGateway\u0026#34;,\r\u0026#34;ec2:DeleteCustomerGateway\u0026#34;,\r\u0026#34;ec2:DeleteFlowLogs\u0026#34;,\r\u0026#34;ec2:DeleteInternetGateway\u0026#34;,\r\u0026#34;ec2:DeleteNetworkInterface\u0026#34;,\r\u0026#34;ec2:DeleteNetworkInterfacePermission\u0026#34;,\r\u0026#34;ec2:DeleteRoute\u0026#34;,\r\u0026#34;ec2:DeleteRouteTable\u0026#34;,\r\u0026#34;ec2:DeleteSecurityGroup\u0026#34;,\r\u0026#34;ec2:DeleteSubnet\u0026#34;,\r\u0026#34;ec2:DeleteSubnetCidrReservation\u0026#34;,\r\u0026#34;ec2:DeleteTags\u0026#34;,\r\u0026#34;ec2:DeleteTransitGateway\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayPeeringAttachment\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayPrefixListReference\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayRoute\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayRouteTable\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:DeleteVpc\u0026#34;,\r\u0026#34;ec2:DeleteVpcEndpoints\u0026#34;,\r\u0026#34;ec2:DeleteVpcEndpointServiceConfigurations\u0026#34;,\r\u0026#34;ec2:DeleteVpnConnection\u0026#34;,\r\u0026#34;ec2:DeleteVpnConnectionRoute\u0026#34;,\r\u0026#34;ec2:Describe*\u0026#34;,\r\u0026#34;ec2:DetachInternetGateway\u0026#34;,\r\u0026#34;ec2:DisassociateAddress\u0026#34;,\r\u0026#34;ec2:DisassociateRouteTable\u0026#34;,\r\u0026#34;ec2:GetLaunchTemplateData\u0026#34;,\r\u0026#34;ec2:GetTransitGatewayAttachmentPropagations\u0026#34;,\r\u0026#34;ec2:ModifyInstanceAttribute\u0026#34;,\r\u0026#34;ec2:ModifySecurityGroupRules\u0026#34;,\r\u0026#34;ec2:ModifyTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:ModifyVpcAttribute\u0026#34;,\r\u0026#34;ec2:ModifyVpcEndpoint\u0026#34;,\r\u0026#34;ec2:ReleaseAddress\u0026#34;,\r\u0026#34;ec2:ReplaceRoute\u0026#34;,\r\u0026#34;ec2:RevokeSecurityGroupEgress\u0026#34;,\r\u0026#34;ec2:RevokeSecurityGroupIngress\u0026#34;,\r\u0026#34;ec2:RunInstances\u0026#34;,\r\u0026#34;ec2:StartInstances\u0026#34;,\r\u0026#34;ec2:StopInstances\u0026#34;,\r\u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsEgress\u0026#34;,\r\u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsIngress\u0026#34;,\r\u0026#34;iam:AddRoleToInstanceProfile\u0026#34;,\r\u0026#34;iam:AttachRolePolicy\u0026#34;,\r\u0026#34;iam:CreateInstanceProfile\u0026#34;,\r\u0026#34;iam:CreatePolicy\u0026#34;,\r\u0026#34;iam:CreateRole\u0026#34;,\r\u0026#34;iam:DeleteInstanceProfile\u0026#34;,\r\u0026#34;iam:DeletePolicy\u0026#34;,\r\u0026#34;iam:DeleteRole\u0026#34;,\r\u0026#34;iam:DeleteRolePolicy\u0026#34;,\r\u0026#34;iam:DetachRolePolicy\u0026#34;,\r\u0026#34;iam:GetInstanceProfile\u0026#34;,\r\u0026#34;iam:GetPolicy\u0026#34;,\r\u0026#34;iam:GetRole\u0026#34;,\r\u0026#34;iam:GetRolePolicy\u0026#34;,\r\u0026#34;iam:ListPolicyVersions\u0026#34;,\r\u0026#34;iam:ListRoles\u0026#34;,\r\u0026#34;iam:PassRole\u0026#34;,\r\u0026#34;iam:PutRolePolicy\u0026#34;,\r\u0026#34;iam:RemoveRoleFromInstanceProfile\u0026#34;,\r\u0026#34;lambda:CreateFunction\u0026#34;,\r\u0026#34;lambda:DeleteFunction\u0026#34;,\r\u0026#34;lambda:DeleteLayerVersion\u0026#34;,\r\u0026#34;lambda:GetFunction\u0026#34;,\r\u0026#34;lambda:GetLayerVersion\u0026#34;,\r\u0026#34;lambda:InvokeFunction\u0026#34;,\r\u0026#34;lambda:PublishLayerVersion\u0026#34;,\r\u0026#34;logs:CreateLogGroup\u0026#34;,\r\u0026#34;logs:DeleteLogGroup\u0026#34;,\r\u0026#34;logs:DescribeLogGroups\u0026#34;,\r\u0026#34;logs:PutRetentionPolicy\u0026#34;,\r\u0026#34;route53:ChangeTagsForResource\u0026#34;,\r\u0026#34;route53:CreateHealthCheck\u0026#34;,\r\u0026#34;route53:CreateHostedZone\u0026#34;,\r\u0026#34;route53:CreateTrafficPolicy\u0026#34;,\r\u0026#34;route53:DeleteHostedZone\u0026#34;,\r\u0026#34;route53:DisassociateVPCFromHostedZone\u0026#34;,\r\u0026#34;route53:GetHostedZone\u0026#34;,\r\u0026#34;route53:ListHostedZones\u0026#34;,\r\u0026#34;route53domains:ListDomains\u0026#34;,\r\u0026#34;route53domains:ListOperations\u0026#34;,\r\u0026#34;route53domains:ListTagsForDomain\u0026#34;,\r\u0026#34;route53resolver:AssociateResolverEndpointIpAddress\u0026#34;,\r\u0026#34;route53resolver:AssociateResolverRule\u0026#34;,\r\u0026#34;route53resolver:CreateResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:CreateResolverRule\u0026#34;,\r\u0026#34;route53resolver:DeleteResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:DeleteResolverRule\u0026#34;,\r\u0026#34;route53resolver:DisassociateResolverEndpointIpAddress\u0026#34;,\r\u0026#34;route53resolver:DisassociateResolverRule\u0026#34;,\r\u0026#34;route53resolver:GetResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:GetResolverRule\u0026#34;,\r\u0026#34;route53resolver:ListResolverEndpointIpAddresses\u0026#34;,\r\u0026#34;route53resolver:ListResolverEndpoints\u0026#34;,\r\u0026#34;route53resolver:ListResolverRuleAssociations\u0026#34;,\r\u0026#34;route53resolver:ListResolverRules\u0026#34;,\r\u0026#34;route53resolver:ListTagsForResource\u0026#34;,\r\u0026#34;route53resolver:UpdateResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:UpdateResolverRule\u0026#34;,\r\u0026#34;s3:AbortMultipartUpload\u0026#34;,\r\u0026#34;s3:CreateBucket\u0026#34;,\r\u0026#34;s3:DeleteBucket\u0026#34;,\r\u0026#34;s3:DeleteObject\u0026#34;,\r\u0026#34;s3:GetAccountPublicAccessBlock\u0026#34;,\r\u0026#34;s3:GetBucketAcl\u0026#34;,\r\u0026#34;s3:GetBucketOwnershipControls\u0026#34;,\r\u0026#34;s3:GetBucketPolicy\u0026#34;,\r\u0026#34;s3:GetBucketPolicyStatus\u0026#34;,\r\u0026#34;s3:GetBucketPublicAccessBlock\u0026#34;,\r\u0026#34;s3:GetObject\u0026#34;,\r\u0026#34;s3:GetObjectVersion\u0026#34;,\r\u0026#34;s3:GetBucketVersioning\u0026#34;,\r\u0026#34;s3:ListAccessPoints\u0026#34;,\r\u0026#34;s3:ListAccessPointsForObjectLambda\u0026#34;,\r\u0026#34;s3:ListAllMyBuckets\u0026#34;,\r\u0026#34;s3:ListBucket\u0026#34;,\r\u0026#34;s3:ListBucketMultipartUploads\u0026#34;,\r\u0026#34;s3:ListBucketVersions\u0026#34;,\r\u0026#34;s3:ListJobs\u0026#34;,\r\u0026#34;s3:ListMultipartUploadParts\u0026#34;,\r\u0026#34;s3:ListMultiRegionAccessPoints\u0026#34;,\r\u0026#34;s3:ListStorageLensConfigurations\u0026#34;,\r\u0026#34;s3:PutAccountPublicAccessBlock\u0026#34;,\r\u0026#34;s3:PutBucketAcl\u0026#34;,\r\u0026#34;s3:PutBucketPolicy\u0026#34;,\r\u0026#34;s3:PutBucketPublicAccessBlock\u0026#34;,\r\u0026#34;s3:PutObject\u0026#34;,\r\u0026#34;secretsmanager:CreateSecret\u0026#34;,\r\u0026#34;secretsmanager:DeleteSecret\u0026#34;,\r\u0026#34;secretsmanager:DescribeSecret\u0026#34;,\r\u0026#34;secretsmanager:GetSecretValue\u0026#34;,\r\u0026#34;secretsmanager:ListSecrets\u0026#34;,\r\u0026#34;secretsmanager:ListSecretVersionIds\u0026#34;,\r\u0026#34;secretsmanager:PutResourcePolicy\u0026#34;,\r\u0026#34;secretsmanager:TagResource\u0026#34;,\r\u0026#34;secretsmanager:UpdateSecret\u0026#34;,\r\u0026#34;sns:ListTopics\u0026#34;,\r\u0026#34;ssm:DescribeInstanceProperties\u0026#34;,\r\u0026#34;ssm:DescribeSessions\u0026#34;,\r\u0026#34;ssm:GetConnectionStatus\u0026#34;,\r\u0026#34;ssm:GetParameters\u0026#34;,\r\u0026#34;ssm:ListAssociations\u0026#34;,\r\u0026#34;ssm:ResumeSession\u0026#34;,\r\u0026#34;ssm:StartSession\u0026#34;,\r\u0026#34;ssm:TerminateSession\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;\r}\r]\r} Khởi tạo tài nguyên bằng CloudFormation Trong lab này, chúng ta sẽ dùng N.Virginia region (us-east-1).\nĐể chuẩn bị cho môi trường làm workshop, chúng ta deploy CloudFormation template sau (click link): PrivateLinkWorkshop . Để nguyên các lựa chọn mặc định.\nLựa chọn 2 mục acknowledgement Chọn Create stack Quá trình triển khai CloudFormation cần khoảng 15 phút để hoàn thành.\n2 VPCs đã được tạo 3 EC2s đã được tạo "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/5-workshop/5.3-s3-vpc/5.3.2-test-gwe/",
	"title": "Kiểm tra Gateway Endpoint",
	"tags": [],
	"description": "",
	"content": "Tạo S3 bucket Đi đến S3 management console Trong Bucket console, chọn Create bucket Trong Create bucket console Đặt tên bucket: chọn 1 tên mà không bị trùng trong phạm vi toàn cầu (gợi ý: lab\u0026lt;số-lab\u0026gt;\u0026lt;tên-bạn\u0026gt;) Giữ nguyên giá trị của các fields khác (default) Kéo chuột xuống và chọn Create bucket Tạo thành công S3 bucket Kết nối với EC2 bằng session manager Trong workshop này, bạn sẽ dùng AWS Session Manager để kết nối đến các EC2 instances. Session Manager là 1 tính năng trong dịch vụ Systems Manager được quản lý hoàn toàn bởi AWS. System manager cho phép bạn quản lý Amazon EC2 instances và các máy ảo on-premises (VMs)thông qua 1 browser-based shell. Session Manager cung cấp khả năng quản lý phiên bản an toàn và có thể kiểm tra mà không cần mở cổng vào, duy trì máy chủ bastion host hoặc quản lý khóa SSH. First cloud journey Lab để hiểu sâu hơn về Session manager. Trong AWS Management Console, gõ Systems Manager trong ô tìm kiếm và nhấn Enter: Từ Systems Manager menu, tìm Node Management ở thanh bên trái và chọn Session Manager: Click Start Session, và chọn EC2 instance tên Test-Gateway-Endpoint. Phiên bản EC2 này đã chạy trong \u0026ldquo;VPC cloud\u0026rdquo; và sẽ được dùng để kiểm tra khả năng kết nối với Amazon S3 thông qua điểm cuối Cổng mà bạn vừa tạo (s3-gwe).\nSession Manager sẽ mở browser tab mới với shell prompt: sh-4.2 $\nBạn đã bắt đầu phiên kết nối đến EC2 trong VPC Cloud thành công. Trong bước tiếp theo, chúng ta sẽ tạo một S3 bucket và một tệp trong đó.\nCreate a file and upload to s3 bucket Đổi về ssm-user\u0026rsquo;s thư mục bằng lệnh \u0026ldquo;cd ~\u0026rdquo; Tạo 1 file để kiểm tra bằng lệnh \u0026ldquo;fallocate -l 1G testfile.xyz\u0026rdquo;, 1 file tên \u0026ldquo;testfile.xyz\u0026rdquo; có kích thước 1GB sẽ được tạo. Tải file mình vừa tạo lên S3 với lệnh \u0026ldquo;aws s3 cp testfile.xyz s3://your-bucket-name\u0026rdquo;. Thay your-bucket-name bằng tên S3 bạn đã tạo. Bạn đã tải thành công tệp lên bộ chứa S3 của mình. Bây giờ bạn có thể kết thúc session.\nKiểm tra object trong S3 bucket Đi đến S3 console. Click tên s3 bucket của bạn Trong Bucket console, bạn sẽ thấy tệp bạn đã tải lên S3 bucket của mình Tóm tắt Chúc mừng bạn đã hoàn thành truy cập S3 từ VPC. Trong phần này, bạn đã tạo gateway endpoint cho Amazon S3 và sử dụng AWS CLI để tải file lên. Quá trình tải lên hoạt động vì gateway endpoint cho phép giao tiếp với S3 mà không cần Internet gateway gắn vào \u0026ldquo;VPC Cloud\u0026rdquo;. Điều này thể hiện chức năng của gateway endpoint như một đường dẫn an toàn đến S3 mà không cần đi qua pub lic Internet.\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/5-workshop/5.4-s3-onprem/5.4.2-create-interface-enpoint/",
	"title": "Tạo một S3 Interface endpoint",
	"tags": [],
	"description": "",
	"content": "Trong phần này, bạn sẽ tạo và kiểm tra Interface Endpoint S3 bằng cách sử dụng môi trường truyền thống mô phỏng.\nQuay lại Amazon VPC menu. Trong thanh điều hướng bên trái, chọn Endpoints, sau đó click Create Endpoint. Trong Create endpoint console: Đặt tên interface endpoint Trong Service category, chọn aws services Trong Search box, gõ S3 và nhấn Enter. Chọn endpoint có tên com.amazonaws.us-east-1.s3. Đảm bảo rằng cột Type có giá trị Interface. Đối với VPC, chọn VPC Cloud từ drop-down. Đảm bảo rằng bạn chọn \u0026ldquo;VPC Cloud\u0026rdquo; và không phải \u0026ldquo;VPC On-prem\u0026rdquo;\nMở rộng Additional settings và đảm bảo rằng Enable DNS name không được chọn (sẽ sử dụng điều này trong phần tiếp theo của workshop) Chọn 2 subnets trong AZs sau: us-east-1a and us-east-1b Đối với Security group, chọn SGforS3Endpoint: Giữ default policy - full access và click Create endpoint Chúc mừng bạn đã tạo thành công S3 interface endpoint. Ở bước tiếp theo, chúng ta sẽ kiểm tra interface endpoint.\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/3-blogstranslated/3.2-blog2/",
	"title": "Đơn giản hóa mã hóa đa thuê bao với chiến lược khóa AWS KMS tiết kiệm chi phí",
	"tags": [],
	"description": "",
	"content": "Giới thiệu Các tổ chức phải đối mặt diverse challenges when it comes to managing encryption keys. Mặc dù một số kịch bản yêu cầu sự tách biệt nghiêm ngặt, nhưng có những trường hợp sử dụng thiết thực mà phương pháp tập trung có thể hợp lý hóa hoạt động và giảm độ phức tạp. Trong bài viết này, chúng tôi tập trung vào kịch bản nhà cung cấp phần mềm dưới dạng dịch vụ (SaaS), nhưng các nguyên tắc chúng tôi thảo luận có thể được áp dụng bởi các tổ chức lớn đang đối mặt với những thách thức quản lý quan trọng tương tự.\nViệc quản lý mã hóa trên một kiến ​​trúc đa thuê bao, đa dịch vụ đặt ra một thách thức đáng kể. Nhiều tổ chức đang phải vật lộn với sự phức tạp và chi phí liên quan đến việc cung cấp các dịch vụ riêng biệt AWS Key Management Service (AWS KMS) customer managed keys cho từng đối tượng thuê bao và dịch vụ. Cách tiếp cận này, mặc dù an toàn, nhưng thường dẫn đến chi phí vận hành tăng cao và chi phí sử dụng AWS KMS tăng theo thời gian.\nNhưng nếu có cách hiệu quả hơn thì sao?\nTrong bài viết này, chúng tôi sẽ giới thiệu một chiến lược sử dụng một khóa duy nhất do khách hàng quản lý (đối xứng) cho mỗi đối tượng thuê trên các dịch vụ. Sau khi đọc hết bài viết này, bạn sẽ tìm hiểu:\nLàm thế nào để triển khai một mô hình mã hóa có khả năng mở rộng, an toàn và tiết kiệm chi phí Các kỹ thuật sử dụng một khóa do khách hàng quản lý cho mỗi đối tượng thuê trên nhiều dịch vụ và môi trường Phương pháp mã hóa dữ liệu người thuê trong Amazon DynamoDB và các loại lưu trữ khác trong khi vẫn duy trì sự cô lập của người thuê. Yêu cầu mã hóa đa thuê bao trong SaaS Việc cô lập dữ liệu là nền tảng cơ bản của các kiến ​​trúc SaaS đa thuê bao, đáp ứng cả yêu cầu tuân thủ và sự tin tưởng của khách hàng. Nhiều nhà cung cấp SaaS cần mã hóa thông tin nhạy cảm - từ khóa API và thông tin đăng nhập đến dữ liệu cá nhân - trên các giải pháp lưu trữ như DynamoDB và Amazon Simple Storage Service (Amazon S3).\nMặc dù các dịch vụ lưu trữ này cung cấp mã hóa mặc định khi lưu trữ, nhưng chúng thường sử dụng một khóa chung duy nhất trên các mục dữ liệu. Hãy xem xét DynamoDB in a shared pool model, trong đó một bảng chứa dữ liệu từ nhiều đối tượng thuê. Trong thiết lập này, dữ liệu đối tượng thuê được mã hóa bằng cùng một AWS KMS Key, bất kể quyền sở hữu.\nKhóa KMS đại diện cho một vùng chứa tài liệu khóa cấp cao nhất và được xác định duy nhất trong KMS, để biết thêm thông tin về các khóa khác nhau liên quan khi mã hóa hoặc giải mã dữ liệu bằng KMS, hãy xem AWS KMS key hierarchy.\nPhương pháp khóa chia sẻ này thường tỏ ra không đủ hiệu quả đối với các nhà cung cấp SaaS hoạt động theo khuôn khổ bảo mật và tuân thủ nghiêm ngặt. Một số khách hàng yêu cầu\nKhả năng mang theo chìa khóa riêng (BYOK) Cô lập dữ liệu một cách hợp lý thông qua các khóa mã hóa chuyên dụng Để đáp ứng các yêu cầu này, nhà cung cấp có thể triển khai khóa được quản lý AWS KMS dành riêng cho khách hàng, giúp đảm bảo dữ liệu nhạy cảm của mỗi khách hàng vẫn được tách biệt và không thể truy cập được bởi những người thuê khác.\nNgoài ra, các nhà cung cấp có thể cân nhắc mô hình silo với các bảng riêng biệt cho mỗi khách hàng. Tuy nhiên, cách tiếp cận này cũng đặt ra những thách thức riêng - khi cơ sở khách hàng tăng lên, việc quản lý nhiều bảng riêng lẻ trở nên ngày càng phức tạp và service quota giới hạn có thể trở thành một ràng buộc.\nQuản lý tăng trưởng: Quản lý khóa KMS ở quy mô lớn Khi mở rộng quy mô nền tảng SaaS, việc trao quyền cho các nhóm phát triển dịch vụ một cách độc lập là rất quan trọng. Một cách nhanh chóng để mở rộng quy mô là có each team develop independently using a dedicated account. Điều này thường dẫn đến phương pháp tiếp cận phi tập trung, trong đó mỗi dịch vụ quản lý khóa KMS riêng cho từng khách hàng. Tuy nhiên, tính tự chủ này đi kèm với những chi phí ẩn khi cơ sở khách hàng và danh mục dịch vụ của bạn mở rộng.\nThách thức của sự phổ biến chìa khóa Khi công ty phát triển, số lượng khóa sẽ tăng lên theo mỗi khách hàng và dịch vụ mới được bổ sung. Sự gia tăng này tạo ra một số thách thức cho tổ chức:\nTác động về chi phí: Một khóa AWS KMS có giá 1 đô la mỗi tháng, tăng lên tối đa 3 đô la mỗi tháng với hai hoặc nhiều lần luân chuyển khóa. Độ phức tạp trong vận hành: Việc quản lý nhiều khóa KMS trên nhiều môi trường và tài khoản dễ xảy ra lỗi và khó mở rộng quy mô. Lãng phí tổ chức: Nỗ lực trùng lặp giữa các nhóm vì mỗi nhóm phát triển và duy trì mã riêng để quản lý vòng đời khóa khách hàng. Chi phí quản lý: Việc thực thi các chính sách nhất quán hoặc theo dõi việc sử dụng khóa KMS trên nhiều tài khoản AWS trở nên khó khăn. Một cách tiếp cận hợp lý Giải pháp nằm ở việc thực hiện một centralized key management strategy. Một khóa KMS cho mỗi đối tượng thuê, được lưu trữ trong một tài khoản AWS trung tâm. Phương pháp này giải quyết hiệu quả các thách thức về chi phí, vận hành và quản trị, đồng thời vẫn đảm bảo tính bảo mật.\nTrong các phần sau, chúng tôi sẽ khám phá cách triển khai phương pháp tập trung này và chia sẻ khóa KMS một cách an toàn trên nhiều dịch vụ và tài khoản AWS khác nhau.\nTổng quan về giải pháp: Tập trung quản lý khóa đối tượng thuê Cốt lõi của giải pháp của chúng tôi là dịch vụ quản lý khóa thuê bao tập trung (được hiển thị là Dịch vụ A trong hình sau). Dịch vụ này xử lý mọi khía cạnh của vòng đời khóa KMS của khách hàng—từ việc tạo khóa trong quá trình đăng ký thuê bao đến việc quản lý bí danh, chính sách truy cập và xóa khóa.\nDịch vụ này đạt được khả năng sử dụng khóa an toàn, có thể mở rộng trên toàn tổ chức thông qua quyền truy cập AWS Identity and Access Management (IAM) liên tài khoản. Nó cấp cho các dịch vụ khác (ví dụ: dịch vụ dành cho khách hàng trong Tài khoản B trong hình sau) quyền thực hiện các hoạt động mã hóa cụ thể bằng khóa KMS dành riêng cho đối tượng thuê thông qua phân quyền vai trò. Việc triển khai này tuân thủ các thông lệ tốt nhất của AWS về truy cập liên tài khoản, sử dụng IAM và AWS Security Token Service (AWS STS) giả định vai trò như được mô tả trong the AWS documentation và điều này blog post.\nQuản lý khóa tập trung trong thực tế: Mã hóa dữ liệu khách hàng Chúng ta hãy cùng xem xét cách thức hoạt động này trong thực tế với một kịch bản phổ biến:\nDịch vụ A: Dịch vụ quản lý khóa thuê tập trung của chúng tôi trong Tài khoản A Dịch vụ B: Khối lượng công việc hướng tới khách hàng đang chạy trong Tài khoản B Khi khách hàng tương tác với Dịch vụ B, họ cần lưu trữ thông tin nhạy cảm một cách an toàn, cho dù đó là bí mật, khóa API hay thông tin giấy phép trong bảng DynamoDB. Thay vì dựa vào khóa KMS dùng chung hoặc mã hóa mặc định, Dịch vụ B mã hóa dữ liệu bằng khóa KMS chuyên dụng của khách hàng do Dịch vụ A quản lý. Quy trình này hoạt động thông qua AWS Identity and Access Management (IAM) ủy quyền vai trò. Dịch vụ B tạm thời đảm nhận một vai trò (ServiceARole) trong Tài khoản A, nhận được các quyền chi tiết, được thu hẹp phạm vi cho khóa KMS của đối tượng thuê cụ thể. Với các thông tin xác thực tạm thời này, Dịch vụ B có thể thực hiện các hoạt động mã hóa phía máy khách trên thông tin nhạy cảm bằng AWS SDK hoặc AWS Encryption SDK.\nTrong bài đăng trên blog này, chúng tôi đã sử dụng Boto3. Đối với các trường hợp sử dụng nâng cao hơn yêu cầu data key caching hoặc keyrings, sử dụng AWS Encryption SDK.\nHướng dẫn giải pháp Hãy cùng mở rộng các khía cạnh kỹ thuật của giải pháp được mô tả ở trên. Giả định và định nghĩa:\nCác yêu cầu đến bao gồm một tiêu đề xác thực với JSON Web Token (JWT) bao gồm dữ liệu xác định người thuê OF hiện tại. Các mã thông báo này được ký bởi nhà cung cấp danh tính, đảm bảo JWT không thể bị sửa đổi và danh tính người thuê có thể được tin cậy. Tài khoản A: Dịch vụ quản lý khóa tập trung. Tài khoản B: Dịch vụ kinh doanh phục vụ nhu cầu của khách hàng. alias/customer- là định dạng của các bí danh trong tài khoản A. Mỗi bí danh trỏ đến khóa KMS của khách hàng tương ứng được xác định theo giá trị của . Dịch vụ A tạo các bí danh này trong quá trình đưa người thuê lên hệ thống và xóa chúng trong quá trình đưa người thuê rời khỏi hệ thống. ServiceARole: Một vai trò trong Tài khoản A có thể mã hóa và giải mã khóa KMS có tiền tố bí danh là alias/customer-*. Các quyền được thu hẹp phạm vi hơn nữa bằng cách sử dụng session policies khi ServiceBRole giả định ServiceARole. ServiceBRole:Một vai trò trong Tài khoản B có thể đảm nhận ServiceARole trong Tài khoản A để có quyền truy cập vào khóa KMS của khách hàng. Đây sẽ là AWS Lambda vai trò thực thi của hàm. Lưu ý rằng lớp tính toán của Dịch vụ B trong trường hợp này là một hàm Lambda, nhưng giải pháp này cũng được áp dụng cho các kiến ​​trúc tính toán khác. Hãy cùng xem xét kỹ năng hơn về xử lý luồng:\nSử dụng dịch vụ với JWT Khách hàng thuộc về một đối tượng thuê đăng nhập vào giải pháp SaaS và được cấp JWT để xác định đối tượng thuê của mình bằng ID đối tượng thuê (). Khách hàng thực hiện một hành động trong ServiceB và gửi thông tin nhạy cảm.\nServiceB xử lý yêu cầu (trong hàm Lambda), xác minh mã thông báo JWT và muốn:\nMã hóa dữ liệu nhạy cảm của khách hàng Lưu dữ liệu được mã hóa cùng với dữ liệu khác trong bảng DynamoDB Đảm nhận vai trò Trong ví dụ này, hàm Lambda sử dụng execution role thông tin đăng nhập để đảm nhận vai trò Dịch vụ trong tài khoản Dịch vụ. Một cách khác để cấp quyền truy cập liên tài khoản vào khóa KMS là sử dụng KMS grants,để tìm hiểu thêm, hãy xem Allowing users in other accounts to use a KMS key.\nHãy cùng xem lại chính sách IAM ServiceRoleA:\nCấp quyền mã hóa và giải mã cho khóa KMS bằng cách sử dụng alias/customer-* mẫu. { \u0026ldquo;Version\u0026rdquo;: \u0026ldquo;2012-10-17\u0026rdquo;, \u0026ldquo;Statement\u0026rdquo;: [ { \u0026ldquo;Sid\u0026rdquo;: \u0026ldquo;AllowKMSByAlias\u0026rdquo;, \u0026ldquo;Effect\u0026rdquo;: \u0026ldquo;Allow\u0026rdquo;, \u0026ldquo;Action\u0026rdquo;: [ \u0026ldquo;kms:Encrypt\u0026rdquo;, \u0026ldquo;kms:Decrypt\u0026rdquo;, \u0026ldquo;kms:GenerateDataKey*\u0026rdquo; ], \u0026ldquo;Resource\u0026rdquo;: \u0026ldquo;\u0026rdquo;, \u0026ldquo;Condition\u0026rdquo;: { \u0026ldquo;StringLike\u0026rdquo;: { \u0026ldquo;kms:RequestAlias\u0026rdquo;: \u0026ldquo;alias/customer-\u0026rdquo; } } } ] }\nĐể mã hóa bí mật của người thuê một cách an toàn và trên quy mô lớn, chúng tôi cấp cho các vai trò ứng dụng quyền truy cập liên tài khoản vào khóa KMS—nhưng chỉ thông qua bí danh của họ, bí danh này ánh xạ tới mã định danh người thuê có trong mã thông báo xác thực JWT của họ, thực thi sự cô lập mạnh mẽ.\nBạn có thể kiểm soát quyền truy cập vào khóa KMS dựa trên các bí danh được liên kết với mỗi khóa KMS. Để thực hiện việc này, hãy sử dụng kms:RequestAlias và kms:ResourceAliases các phím điều kiện như được chỉ định trong Use aliases to control access to KMS keys.\nNgoài ra, chính sách quan hệ tin cậy của ServiceARole cho phép ServiceBRole trong tài khoản B đảm nhận: { \u0026ldquo;Version\u0026rdquo;: \u0026ldquo;2012-10-17\u0026rdquo;, \u0026ldquo;Statement\u0026rdquo;: [ { \u0026ldquo;Effect\u0026rdquo;: \u0026ldquo;Allow\u0026rdquo;, \u0026ldquo;Principal\u0026rdquo;: { \u0026ldquo;AWS\u0026rdquo;: \u0026ldquo;arn:aws:iam::\u0026lt;ACCOUNT_B_ID\u0026gt;:role/ServiceBRole\u0026rdquo; }, \u0026ldquo;Action\u0026rdquo;: \u0026ldquo;sts:AssumeRole\u0026rdquo; } ] }\nTùy thuộc vào môi trường của bạn, bạn có thể thêm các điều kiện bổ sung vào chính sách ủy thác này để thu hẹp hơn nữa phạm vi những người có thể đảm nhận vai trò này. Để biết thêm thông tin, hãy xem IAM and AWS STS condition context keys.\nSau đó, mỗi khóa KMS do khách hàng quản lý sẽ có chính sách sau. Ví dụ: khóa KMS cho khách hàng có : 123 sẽ có chính sách hạn chế quyền truy cập vào khóa bằng cách sử dụng bí danh khách hàng cụ thể và chỉ thông qua ServiceRoleA. { \u0026ldquo;Version\u0026rdquo;: \u0026ldquo;2012-10-17\u0026rdquo;, \u0026ldquo;Id\u0026rdquo;: \u0026ldquo;TenantKeyPolicy\u0026rdquo;, \u0026ldquo;Statement\u0026rdquo;: [ { \u0026ldquo;Sid\u0026rdquo;: \u0026ldquo;AllowServiceARoleViaAlias\u0026rdquo;, \u0026ldquo;Effect\u0026rdquo;: \u0026ldquo;Allow\u0026rdquo;, \u0026ldquo;Principal\u0026rdquo;: { \u0026ldquo;AWS\u0026rdquo;: \u0026ldquo;arn:aws:iam::\u0026lt;ACCOUNT_A_ID\u0026gt;:role/ServiceARole\u0026rdquo; }, \u0026ldquo;Action\u0026rdquo;: [ \u0026ldquo;kms:Encrypt\u0026rdquo;, \u0026ldquo;kms:Decrypt\u0026rdquo;, \u0026ldquo;kms:GenerateDataKey*\u0026rdquo; ], \u0026ldquo;Resource\u0026rdquo;: \u0026ldquo;*\u0026rdquo;, \u0026ldquo;Condition\u0026rdquo;: { \u0026ldquo;StringLike\u0026rdquo;: { \u0026ldquo;kms:RequestAlias\u0026rdquo;: \u0026ldquo;alias/customer-123\u0026rdquo; } } } ] }\nSau đây là ví dụ mã Python minh họa cách Dịch vụ B tự động đảm nhận vai trò trong Tài khoản A để mã hóa dữ liệu cho một đối tượng thuê cụ thể bằng chính sách IAM có phạm vi phiên, chính sách này chỉ cho phép truy cập vào bí danh khóa KMS của đối tượng thuê đó.\nMẫu này tuân theo các nguyên tắc tương tự được nêu trong Isolating SaaS Tenants with Dynamically Generated IAM Policies. Ý tưởng là tạo và đính kèm một chính sách IAM dành riêng cho đối tượng thuê trong thời gian chạy, cấp các quyền tối thiểu cần thiết để vận hành trên các tài nguyên do đối tượng thuê sở hữu—trong trường hợp này là một bí danh khóa KMS. Thông tin xác thực sẽ cho phép hàm Lambda chỉ sử dụng khóa KMS thuộc về khách hàng (được xác định bởi tenant_id).\nChúng tôi sẽ gọi assume_role_for_tenant cho mọi người thuê nhà.\nTình trạng của \u0026ldquo;StringEquals\u0026rdquo; - \u0026ldquo;kms:RequestAlias\u0026rdquo;: alias là công thức kỳ diệu của AWS STS, nó hạn chế ServiceB sử dụng bí danh của người thuê hiện tại trong các cuộc gọi SDK mã hóa của nó và dựa vào alias authorization\nimport boto3 def assume_role_for_tenant(tenant_id: str): alias = f\u0026quot;alias/customer-{tenant_id}\u0026quot; # Session policy scoped to only the specific alias session_policy = { \u0026ldquo;Version\u0026rdquo;: \u0026ldquo;2012-10-17\u0026rdquo;, \u0026ldquo;Statement\u0026rdquo;: [ { \u0026ldquo;Effect\u0026rdquo;: \u0026ldquo;Allow\u0026rdquo;, \u0026ldquo;Action\u0026rdquo;: [ \u0026ldquo;kms:Encrypt\u0026rdquo;, \u0026ldquo;kms:Decrypt\u0026rdquo;, \u0026ldquo;kms:GenerateDataKey*\u0026rdquo; ], \u0026ldquo;Resource\u0026rdquo;: \u0026ldquo;*\u0026rdquo;, \u0026ldquo;Condition\u0026rdquo;: { \u0026ldquo;StringEquals\u0026rdquo;: { \u0026ldquo;kms:RequestAlias\u0026rdquo;: alias } } } ] } # Assume ServiceARole in Account A with inline session policy sts = boto3.client(\u0026ldquo;sts\u0026rdquo;) assumed = sts.assume_role( RoleArn=\u0026ldquo;arn:aws:iam::\u0026lt;ACCOUNT_A_ID\u0026gt;:role/ServiceARole\u0026rdquo;, RoleSessionName=f\u0026quot;Tenant{tenant_id}Session\u0026quot;, Policy=json.dumps(session_policy) ) return assumed[\u0026ldquo;Credentials\u0026rdquo;]\nMã hóa dữ liệu và lưu trong DynamoDB Bây giờ, việc còn lại cần làm là sử dụng thông tin xác thực vai trò đã được giả định và sử dụng AWS SDK để mã hóa dữ liệu khách hàng nhạy cảm và lưu trữ dữ liệu đó trong bảng DynamoDB.\nUse temporary credentials to create a KMS client creds = assume_role_for_tenant(tenant_id, plaintext)\rkms = boto3.client(\r\u0026quot;kms\u0026quot;,\rregion_name=\u0026quot;us-east-1\u0026quot;,\raws_access_key_id=creds[\u0026quot;AccessKeyId\u0026quot;],\raws_secret_access_key=creds[\u0026quot;SecretAccessKey\u0026quot;],\raws_session_token=creds[\u0026quot;SessionToken\u0026quot;]\r)\r# Encrypt using the alias\rresponse = kms.encrypt(\rKeyId= f\u0026quot;alias/customer-{tenant_id}\u0026quot;\rPlaintext=plaintext\r)\r# store response[\u0026quot;CiphertextBlob\u0026quot;] in DynamoDB table\rBài viết này không đề cập đến việc cô lập giữa các dịch vụ khác nhau, mà chỉ đề cập đến việc cô lập giữa các đối tượng thuê. Nếu cần cô lập dịch vụ như vậy, bạn có thể sử dụng encryption context, một tập hợp tùy chọn các cặp khóa/giá trị không bí mật có thể chứa thông tin ngữ cảnh bổ sung về dữ liệu, ví dụ như mã định danh dịch vụ. Điều này giúp đảm bảo rằng các dịch vụ chỉ có thể mã hóa hoặc giải mã dữ liệu bằng ngữ cảnh mã hóa dịch vụ tương ứng.\nLợi ích của quản lý khóa tập trung Hãy cùng xem giải pháp này giải quyết những thách thức trước đây của chúng ta như thế nào.\nThiết kế cô lập người thuê nhà Mặc dù giảm tổng số khóa KMS, chúng tôi vẫn duy trì việc cô lập nghiêm ngặt đối với người thuê. Dữ liệu nhạy cảm của mỗi khách hàng vẫn được mã hóa bằng khóa chuyên dụng, được xác định bằng một bí danh duy nhất (alias/customer-). Quyền kiểm soát truy cập vào khóa thuê được quản lý chặt chẽ thông qua việc phân quyền vai trò IAM, tuân theo các nguyên tắc đặc quyền tối thiểu:\nDịch vụ A kiểm soát độc quyền việc quản lý khóa KMS của người thuê. Dịch vụ B chỉ có thể đảm nhận vai trò cấp quyền truy cập mã hóa, giải mã và GenerateDataKey bị hạn chế cho khóa do khách hàng quản lý được chỉ định bởi bí danh: alias/customer-. Quản lý chi phí tối ưu Phương pháp của chúng tôi giúp giảm đáng kể chi phí bằng cách chuyển từ nhiều khóa KMS dành riêng cho từng dịch vụ cho mỗi đối tượng thuê sang một khóa KMS duy nhất cho mỗi đối tượng thuê, được chia sẻ an toàn trên nhiều dịch vụ và môi trường. Cách tiếp cận này giới thiệu một tài khoản tập trung mới (Tài khoản A) cung cấp quyền truy cập vào khóa mã hóa trong những trường hợp phù hợp. Điều quan trọng là phải hiểu AWS STS limits, cụ thể cho các cuộc gọi và xem xét các cơ chế lưu trữ thông tin xác thực IAM tạm thời nếu những giới hạn đó trở thành nút thắt cổ chai. Ngoài ra, nếu KMS limits là một nút thắt cổ chai, hãy cân nhắc sử dụng data key caching bằng cách sử dụng AWS Encryption SDK.\nHoạt động và quản trị hợp lý Bằng cách tập trung quản lý khóa trong Dịch vụ A, bạn có thể đạt được:\nQuản lý vòng đời khóa KMS nhất quán trên toàn tổ chức Cải thiện khả năng kiểm toán bằng cách sử dụng AWS CloudTrail để hiểu rõ hơn về các mẫu truy cập chính theo dịch vụ Giảm chi phí hoạt động Giám sát tuân thủ đơn giản hóa Sự phức tạp bổ sung duy nhất là việc thiết lập phân quyền vai trò liên tài khoản ban đầu giữa Dịch vụ A và các dịch vụ khác. Sau khi được thiết lập, khuôn khổ này có thể được mở rộng để đáp ứng các đối tượng thuê bao và dịch vụ mới.\nTốt nhất là đóng gói logic đảm nhiệm vai trò, tạo chính sách và khởi tạo máy khách AWS SDK trong một SDK dùng chung cho toàn tổ chức. Sự trừu tượng hóa này giúp giảm tải nhận thức cho các nhà phát triển và giảm thiểu rủi ro cấu hình sai. Bạn có thể tiến xa hơn bằng cách cung cấp các hàm tiện ích cấp cao như encrypt_tenant_data() và decrypt_tenant_data(), ẩn đi sự phức tạp tiềm ẩn trong khi thúc đẩy các mô hình sử dụng an toàn và nhất quán trong toàn nhóm.\nPhần kết luận Trong bài viết này, chúng tôi đã khám phá một phương pháp hiệu quả để quản lý khóa mã hóa trong môi trường SaaS đa thuê bao thông qua tập trung hóa. Chúng tôi đã xem xét những thách thức phổ biến mà các nhà cung cấp SaaS đang phát triển phải đối mặt, bao gồm sự gia tăng khóa, chi phí tăng cao và tính phức tạp trong vận hành trên nhiều tài khoản và dịch vụ AWS. Giải pháp tập trung hóa quản lý khóa này sử dụng các phương pháp hay nhất của AWS để phân quyền vai trò IAM và truy cập liên tài khoản, cho phép các tổ chức duy trì bảo mật và tuân thủ đồng thời giảm thiểu chi phí vận hành. Bằng cách triển khai phương pháp này, các nhà cung cấp SaaS hoặc các tổ chức lớn đang gặp phải những thách thức tương tự có thể quản lý hiệu quả cơ sở hạ tầng mã hóa của họ khi mở rộng quy mô, mà không ảnh hưởng đến bảo mật hoặc tăng tính phức tạp.\nVề các tác giả Itay Meller là Kiến trúc sư Giải pháp Chuyên gia Bảo mật tại AWS, với nền tảng vững chắc về Nghiên cứu \u0026amp; Phát triển an ninh mạng và vai trò lãnh đạo tại nhiều công ty tập trung vào bảo mật. Với chuyên môn sâu rộng về bảo mật đám mây, Itay giúp các tổ chức áp dụng và mở rộng môi trường AWS một cách an toàn bằng cách giải quyết các thách thức phức tạp về bảo mật và tuân thủ.\nRan Isenberg là một Anh hùng Không máy chủ của AWS, Kiến trúc sư Phần mềm Chính tại CyberArk, một blogger và diễn giả. Anh duy trì blog RanTheBuilder.cloud, nơi anh chia sẻ kiến ​​thức và kinh nghiệm trong thế giới Không máy chủ.\nYossi Lagstein là Kiến trúc sư Giải pháp Cấp cao tại Amazon Web Services. Yossi có hơn 30 năm kinh nghiệm trong vai trò chuyên gia và quản lý phát triển các thành phần cơ sở hạ tầng cho nhiều dự án và sản phẩm. Yossi hỗ trợ khách hàng AWS phát triển, thiết kế và xây dựng các giải pháp được kiến ​​trúc tốt. Ngoài giờ làm việc, Yossi thích chạy bộ, bơi lội và đi bộ đường dài.\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/4-eventparticipated/",
	"title": "Các events đã tham gia",
	"tags": [],
	"description": "",
	"content": " Trong phần này, các bạn cần liệt kê và mô tả chi tiết các sự kiện (event) mà mình đã tham gia trong suốt quá trình thực tập hoặc làm việc.\nMỗi sự kiện nên được trình bày theo định dạng Event 1, Event 2, Event 3…, kèm theo các thông tin:\nTên sự kiện Thời gian tổ chức Địa điểm (nếu có) Vai trò của bạn trong sự kiện Mô tả ngắn gọn nội dung và hoạt động chính trong sự kiện Kết quả hoặc giá trị đạt được Việc liệt kê này giúp thể hiện rõ sự tham gia thực tế của bạn, cũng như các kỹ năng mềm và kinh nghiệm bạn đã tích lũy qua từng sự kiện.\nTrong quá trình thực tập, em đã tham gia 2 events, mỗi sự kiện đều mang lại những kiến thức hữu ích, kinh nghiệm thực tế và những khoảnh khắc vô cùng đáng nhớ.\nEvent 1 Tên sự kiện: AWS Mastery #2 – CloudFormation \u0026amp; CDK Workshop\nThời gian: 17/11/2025\nĐịa điểm: Sự kiện online (AWS Community Vietnam)\nVai trò trong sự kiện: Người tham dự\nMô tả nội dung:\nSự kiện tập trung vào Infrastructure as Code (IaC) với CloudFormation và AWS CDK. Trong workshop, diễn giả trình bày tư duy IaC, phân tích cấu trúc CloudFormation template, demo cdk deploy, cdk diff, hướng dẫn triển khai hạ tầng bằng code, cùng nội dung bổ trợ về Docker, containerization và các dịch vụ như ECS, EKS và App Runner.\nGiá trị đạt được:\n- Hiểu rõ cách vận hành IaC, drift detection và best practices của CloudFormation.\n- Nắm được CDK constructs L1–L3 và quy trình triển khai hạ tầng tự động.\n- Có cái nhìn thực tế về container orchestration trên AWS.\n- Tăng khả năng phân tích – triển khai DevOps pipelines sử dụng IaC.\nEvent 2 Tên sự kiện: AWS Cloud Club – First Cloud AI Journey Workshop\nThời gian: 29/11/2025\nĐịa điểm: Sự kiện offline nội bộ các Cloud Clubs (HCM)\nVai trò trong sự kiện: Người tham dự\nMô tả nội dung:\nWorkshop giới thiệu cộng đồng AWS Cloud Club, lộ trình học Cloud + AI cho sinh viên, cùng chia sẻ hành trình học AWS từ các Cloud Club Captains. Nội dung xoay quanh cloud fundamentals, AI/ML cơ bản, GenAI, tài liệu học, cách thi chứng chỉ và kinh nghiệm tìm cơ hội nghề nghiệp.\nGiá trị đạt được:\n- Hiểu được tầm quan trọng của nền tảng cloud trước khi học AI/GenAI.\n- Xây dựng được roadmap học AWS rõ ràng (Cloud Practitioner → SA Associate).\n- Học phương pháp tự học hiệu quả và tránh các sai lầm của người mới.\n- Mở rộng network với cộng đồng Cloud Club và các bạn đam mê AI/Cloud.\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/3-blogstranslated/",
	"title": "Các bài blogs đã dịch",
	"tags": [],
	"description": "",
	"content": "Tại đây sẽ là phần liệt kê, giới thiệu các blogs mà các bạn đã dịch. Ví dụ:\nBlog 1 - Accelerate your Cloud Strategy with Megaport\u0026rsquo;s 25 Gbps Hosted AWS Direct Connect Blog này giới thiệu cách tăng tốc chiến lược đám mây bằng AWS Hosted Direct Connect 25 Gbps từ Megaport. Bạn sẽ tìm hiểu lợi ích về hiệu suất, khả năng mở rộng và kết nối mạng an toàn giữa on-premises và cloud, cách triển khai và quản lý kết nối này để tối ưu hóa chi phí và hiệu quả vận hành.\nBlog 2 - Simplify multi-subscriber encryption with cost-effective AWS KMS key strategies Blog này hướng dẫn cách đơn giản hóa việc mã hóa đa thuê bao bằng chiến lược khóa AWS KMS tiết kiệm chi phí. Bạn sẽ tìm hiểu cách quản lý và phân phối khóa KMS hiệu quả, tối ưu hóa chi phí, đảm bảo bảo mật dữ liệu theo từng tenant mà vẫn duy trì hiệu suất và khả năng mở rộng trong môi trường đa khách hàng.\nBlog 3 - Open Protocol for Agent Interoperability Part 4: A2A Agent Communication Blog này giới thiệu giao thức Agent-to-Agent (A2A) cho phép các tác nhân AI giao tiếp trực tiếp với nhau. Bạn sẽ tìm hiểu cách AWS hỗ trợ A2A thông qua Strands Agents SDK, các tính năng chính như Thẻ Tác nhân, thực hiện nhiệm vụ có cấu trúc, nhiều lựa chọn vận chuyển và bảo mật A2A. Bài viết cũng minh họa ví dụ triển khai agent HR và agent Thông tin Nhân viên sử dụng A2A, cùng phản hồi từ khách hàng về khả năng tương tác đa tác nhân.\nBlog 4 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 5 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 6 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/5-workshop/5.4-s3-onprem/5.4.3-test-endpoint/",
	"title": "Kiểm tra Interface Endpoint",
	"tags": [],
	"description": "",
	"content": "Lấy regional DNS name (tên DNS khu vực) của S3 interface endpoint Trong Amazon VPC menu, chọn Endpoints. Click tên của endpoint chúng ta mới tạo ở mục 4.2: s3-interface-endpoint. Click details và lưu lại regional DNS name của endpoint (cái đầu tiên) vào text-editor của bạn để dùng ở các bước sau. Kết nối đến EC2 instance ở trong \u0026ldquo;VPC On-prem\u0026rdquo; (giả lập môi trường truyền thống) Đi đến Session manager bằng cách gõ \u0026ldquo;session manager\u0026rdquo; vào ô tìm kiếm Click Start Session, chọn EC2 instance có tên Test-Interface-Endpoint. EC2 instance này đang chạy trên \u0026ldquo;VPC On-prem\u0026rdquo; và sẽ được sử dụng để kiểm tra kết nối đến Amazon S3 thông qua Interface endpoint. Session Manager sẽ mở 1 browser tab mới với shell prompt: sh-4.2 $ Đi đến ssm-user\u0026rsquo;s home directory với lệnh \u0026ldquo;cd ~\u0026rdquo; Tạo 1 file tên testfile2.xyz fallocate -l 1G testfile2.xyz Copy file vào S3 bucket mình tạo ở section 4.2 aws s3 cp --endpoint-url https://bucket.\u0026lt;Regional-DNS-Name\u0026gt; testfile2.xyz s3://\u0026lt;your-bucket-name\u0026gt; Câu lệnh này yêu cầu thông số \u0026ndash;endpoint-url, bởi vì bạn cần sử dụng DNS name chỉ định cho endpoint để truy cập vào S3 thông qua Interface endpoint. Không lấy \u0026rsquo; * \u0026rsquo; khi copy/paste tên DNS khu vực. Cung cấp tên S3 bucket của bạn Bây giờ tệp đã được thêm vào bộ chứa S3 của bạn. Hãy kiểm tra bộ chứa S3 của bạn trong bước tiếp theo.\nKiểm tra Object trong S3 bucket Đi đến S3 console Click Buckets Click tên bucket của bạn và bạn sẽ thấy testfile2.xyz đã được thêm vào s3 bucket của bạn "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/5-workshop/5.3-s3-vpc/",
	"title": "Truy cập S3 từ VPC",
	"tags": [],
	"description": "",
	"content": "Sử dụng Gateway endpoint Trong phần này, bạn sẽ tạo một Gateway endpoint để truy cập Amazon S3 từ một EC2 instance. Gateway endpoint sẽ cho phép tải một object lên S3 bucket mà không cần sử dụng Internet Công cộng. Để tạo endpoint, bạn phải chỉ định VPC mà bạn muốn tạo endpoint và dịch vụ (trong trường hợp này là S3) mà bạn muốn thiết lập kết nối.\nNội dung Tạo gateway endpoint Test gateway endpoint "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/3-blogstranslated/3.3-blog3/",
	"title": "Giao thức mở cho khả năng tương tác của tác nhân Phần 4: Giao tiếp giữa các tác nhân trên A2A",
	"tags": [],
	"description": "",
	"content": "Giới thiệu: Chào mừng đến với Phần 4 của loạt bài viết trên blog của chúng tôi về Open Protocols for Agent Interoperability nơi chúng tôi sẽ đề cập đến giao thức Agent-to-Agent (A2A), sự tham gia của AWS với Linux Foundation-based open standard, và sự hỗ trợ của chúng tôi dành cho A2A trong Strands Agents SDK. Dưới đây là những gì chúng tôi đã đề cập cho đến nay:\nPart 1: Giao thức ngữ cảnh mô hình (MCP) tạo điều kiện thuận lợi cho giao tiếp giữa các tác nhân như thế nào và AWS đã nỗ lực cải tiến thông số kỹ thuật MCP ra sao để hỗ trợ tốt hơn cho giao tiếp giữa các tác nhân. Part 2: Chi tiết về các bản cập nhật thông số kỹ thuật MCP gần đây liên quan đến Xác thực. Part 3: Làm thế nào để xây dựng hệ thống liên tác nhân với cái mới Strands Agents SDK và MCP Giao thức chuẩn là cách chính để kết nối các dịch vụ mạng. Thông thường, có nhiều giao thức khác nhau để giải quyết các cách kết nối mạng khác nhau. Ở tầng mạng, có hai giao thức chính: TCP và UDP. Mỗi giao thức phù hợp với các nhu cầu cụ thể và không giao thức nào mang tính phổ quát. Điều này cũng đúng khi kết nối các tác nhân AI. Trong phần 4 của loạt bài viết về giao tiếp giữa các tác nhân, chúng tôi sẽ giới thiệu về A2A, cách sử dụng nó để giao tiếp giữa các tác nhân và cách AWS hỗ trợ khách hàng xây dựng hệ thống với A2A.\nMCP ban đầu được tạo ra để kết nối các tác nhân với các công cụ, nhưng cũng có thể được sử dụng để kết nối các tác nhân với nhau. A2A được tạo ra để kết nối các tác nhân với nhau và cũng có thể được sử dụng kết hợp với MCP để các tác nhân giao tiếp với các công cụ. Việc sử dụng giao thức nào cho kết nối tác nhân với tác nhân tùy thuộc vào nhu cầu của bạn. AWS hỗ trợ cả hai giao thức, cho phép khách hàng sử dụng MCP, A2A hoặc kết hợp cả hai để triển khai mã của họ trên AWS.\nKhi các giao thức liên tác nhân và các khuôn khổ xung quanh chúng phát triển, nhiều khả năng chúng sẽ trở nên giống như TCP \u0026amp; UDP, nơi hầu hết các nhà phát triển tập trung nhiều hơn vào việc xây dựng các tác nhân của họ thay vì các giao thức nền tảng. Bước đầu tiên hướng tới điều đó là các khuôn khổ tác nhân hỗ trợ các giao thức và xây dựng hệ sinh thái xung quanh chúng. Tại AWS, chúng tôi đã thực hiện bước đầu tiên này bằng cách tham gia cộng đồng tiêu chuẩn A2A và bổ sung hỗ trợ cho A2A trong SDK Strands Agents nguồn mở của mình. Swami Sivasubramanian, Phó Chủ tịch AWS Agentic AI, tóm tắt nỗ lực này:\nTại AWS, chúng tôi tin rằng AI agentic sẽ đóng vai trò quan trọng đối với hầu hết mọi trải nghiệm của khách hàng. Chúng tôi hoan nghênh A2A tham gia Quỹ Linux và kỳ vọng điều này sẽ tạo ra nhiều cơ hội hơn cho bất kỳ ai xây dựng ứng dụng AI. Chúng tôi dự định hỗ trợ cộng đồng bằng các đóng góp dự án và tiếp cận bộ khung, giao thức và dịch vụ agentic rộng lớn và chuyên sâu nhất.\nTương tự như cách chúng tôi đang hỗ trợ phát triển MCP, chúng tôi cũng đang hỗ trợ phát triển A2A để đáp ứng nhu cầu của khách hàng. Chúng tôi dự định sẽ tập trung vào một số lĩnh vực để A2A hoạt động hiệu quả trên AWS, bao gồm hỗ trợ Amazon Bedrock AgentCore, mở rộng giao thức A2A cho lưu trữ tác vụ tạm thời và SigV4, cải thiện quản lý đa tác vụ và cải tiến Java A2A SDK.\nTổng quan về A2A Giao thức A2A giải quyết một thách thức quan trọng trong bối cảnh AI. Nó cho phép các tác nhân AI được xây dựng trên các nền tảng đa dạng, được vận hành bởi các công ty khác nhau trên các máy chủ riêng biệt, giao tiếp và cộng tác hiệu quả — với tư cách là tác nhân, chứ không chỉ là công cụ. A2A đại diện cho một bước tiến đáng kể trong việc tạo ra các hệ thống AI có khả năng tương tác, hoạt động cùng nhau xuyên biên giới tổ chức. Giao thức này được hỗ trợ bởi một hệ sinh thái đối tác đang phát triển, bao gồm hơn 50 công ty công nghệ như Google, Atlassian, Confluent, Salesforce, SAP và MongoDB.\nTrước A2A, các tổ chức phải đối mặt với những thách thức đáng kể trong việc triển khai các hệ thống AI đa tác tử ở quy mô lớn. Nếu không có giao thức chuẩn hóa, mỗi cặp tác tử đều yêu cầu mã tích hợp tùy chỉnh, dẫn đến chi phí phát triển quá mức và độ phức tạp trong bảo trì. Điều này tạo ra các hệ thống AI bị cô lập, nơi các tác tử chuyên biệt không thể dễ dàng chia sẻ năng lực hoặc phối hợp thực hiện các nhiệm vụ phức tạp. Giao thức này cung cấp cho các tác tử một ngôn ngữ chung, cho phép chúng duy trì tính tự chủ và các kỹ năng chuyên biệt trong khi hợp tác - các tác tử giao tiếp với nhau như những người ngang hàng, chứ không chỉ là những công cụ đơn thuần. Sự khác biệt này rất quan trọng vì nó cho phép các tác tử tham gia vào các tương tác qua lại phức tạp, đàm phán các yêu cầu nhiệm vụ và duy trì khả năng ra quyết định độc lập trong khi hướng tới các mục tiêu chung.\nĐối với khách hàng AWS, A2A cung cấp một số tính năng hấp dẫn phù hợp với yêu cầu của doanh nghiệp. Giao thức này cho phép các khả năng của doanh nghiệp bao gồm phát hiện tác nhân an toàn thông qua thẻ tác nhân được chuẩn hóa, cơ chế xác thực và ủy quyền cho quyền truy cập được kiểm soát, hỗ trợ nhiều phương thức giao tiếp (văn bản, biểu mẫu, phương tiện) và khả năng cho phép các tác nhân cộng tác trong các tác vụ dài hạn mà không tiết lộ trạng thái nội bộ hoặc chi tiết triển khai của họ.\nA2A giải quyết những thách thức độc đáo của cộng tác đa tác nhân thông qua các tính năng cho phép quy trình làm việc phức tạp, xử lý các quy trình kinh doanh thực tế phức tạp với khả năng quan sát và kiểm soát mà môi trường sản xuất yêu cầu. Cụ thể, nó hỗ trợ thẻ tác nhân, tác vụ có cấu trúc, nhiều tùy chọn vận chuyển và các nguyên hàm xác thực/ủy quyền.\nThẻ đại lý Giao tiếp đa tác nhân hiệu quả đòi hỏi các tác nhân phải khám phá và hiểu rõ khả năng của nhau. A2A hỗ trợ điều này thông qua Thẻ Tác nhân — các tài liệu siêu dữ liệu nắm bắt ý nghĩa ngữ nghĩa về những gì mỗi tác nhân có thể làm, cách thức hoạt động ưa thích và loại nhiệm vụ mà tác nhân đó giỏi. Thẻ Tác nhân cho phép các tác nhân khác đưa ra quyết định thông minh về thời điểm và cách thức hợp tác. Thẻ Tác nhân cũng mô tả các yêu cầu xác thực/ủy quyền của một tác nhân và hỗ trợ các khả năng được mở rộng dần dần sau khi xác thực, sử dụng Thẻ Tác nhân Mở rộng Đã Xác thực.\nThực hiện nhiệm vụ có cấu trúc Các tác nhân làm việc cùng nhau để giải quyết vấn đề bằng cách tận dụng các tác vụ để cấu trúc giao tiếp; họ sắp xếp thông điệp của mình thành các đơn vị công việc thông minh, mang ngữ cảnh, theo dõi tiến độ và lưu trữ các hiện vật đầu ra. Thông qua các tác vụ, các tác nhân có thể tham chiếu các hiện vật đã tạo trước đó, hiểu được sự phụ thuộc giữa các tác vụ trong quy trình làm việc và đưa ra quyết định sáng suốt dựa trên toàn bộ lịch sử hội thoại. Các tác vụ hỗ trợ cả thực thi tuần tự và song song cho các quy trình làm việc phức tạp. Các tác nhân có thể tạo ra nhiều tác vụ tiếp theo đồng thời và tạo ra các chuỗi hoạt động phụ thuộc. Điều này mang lại cho các nhà phát triển ứng dụng sự linh hoạt để mô hình hóa các quy trình kinh doanh trong thế giới thực.\nBằng cách tận dụng ID tác vụ và ngữ cảnh, các ứng dụng có thể theo dõi nguồn gốc tác vụ, lần theo chuỗi tác vụ đến tận gốc để khôi phục thông tin về cách tạo ra kết quả đầu ra. Điều này cải thiện khả năng quan sát bằng cách cung cấp cho các tác nhân khả năng tạo nhật ký hoạt động phong phú để gỡ lỗi và kiểm tra.\nNhiều lựa chọn vận chuyển A2A hỗ trợ các nhà phát triển ứng dụng bằng cách hỗ trợ ba giao thức cốt lõi có khả năng tương đương: JSON-RPC 2.0, gRPC và REST. Điều này cho phép các nhà phát triển lựa chọn phương thức vận chuyển phù hợp nhất với chuyên môn, cơ sở hạ tầng hiện có và yêu cầu hiệu suất của nhóm. Đối với các hoạt động dài hạn, A2A tăng cường mỗi phương thức vận chuyển với Server-Sent Events (SSE) để phát trực tuyến và gửi thông báo đẩy dựa trên webhook. Các nhà phát triển có các tùy chọn trực quan để xử lý cập nhật tác vụ không đồng bộ và giám sát tiến độ theo thời gian thực mà không cần logic thăm dò phức tạp.\nBảo mật A2A Bảo mật cấp doanh nghiệp là một yêu cầu không thể thương lượng đối với các hệ thống agent. A2A cho phép kiến ​​trúc bảo mật mạnh mẽ bằng cách hỗ trợ một số giao thức xác thực; bao gồm OAuth 2.0, OpenID Connect và mTLS, cho phép các tổ chức tích hợp agent với cơ sở hạ tầng nhận dạng hiện có của họ, trong khi siêu dữ liệu ủy quyền theo kỹ năng cụ thể và hỗ trợ xác thực thứ cấp cho phép các chính sách kiểm soát truy cập chi tiết có thể được thực thi ở cấp ứng dụng.\nQuyết định của A2A trong việc giữ cho các tác nhân không minh bạch với nhau hỗ trợ kiến ​​trúc không tin cậy bằng cách coi mỗi tác nhân là một ranh giới bảo mật độc lập và việc giao thức hỗ trợ kiểm tra tác vụ cung cấp nền tảng cho việc giám sát bảo mật toàn diện và báo cáo tuân thủ.\nInter-Agent với Strands Agents \u0026amp; A2A Các tính năng độc đáo của A2A khiến nó trở nên hoàn hảo cho khả năng tương tác giữa các nền tảng tác nhân. Một số nền tảng tác nhân nguồn mở hiện đã hỗ trợ nó. Bộ SDK Strands Agents nguồn mở gần đây đã bổ sung hỗ trợ cho A2A để các tác nhân có thể dễ dàng communicate with other agents.\nStrands Agents áp dụng phương pháp tiếp cận dựa trên mô hình để xây dựng và vận hành các tác nhân AI chỉ trong vài dòng mã. Strands mở rộng từ các trường hợp sử dụng tác nhân đơn giản đến phức tạp, và từ phát triển cục bộ đến triển khai trong môi trường sản xuất. Nhiều nhóm tại AWS đã sử dụng Strands cho các tác nhân AI trong môi trường sản xuất, bao gồm Amazon Q Developer, AWS Glue và VPC Reachability Analyzer.\nVới hỗ trợ A2A tích hợp sẵn trong Strands Agents, bạn có thể dễ dàng sử dụng một agent như một máy chủ A2A và giao tiếp từ một Agent Strands này đến các agent A2A khác. Để minh họa điều này, hãy xem xét ví dụ về một agent Nhân sự (HR) có thể trả lời các câu hỏi về nhân viên. Để làm điều này, bạn có thể tưởng tượng agent HR giao tiếp với một số agent khác như agent dữ liệu nhân viên, agent Hoạch định Nguồn lực Doanh nghiệp (ERP), agent hiệu suất, agent mục tiêu, v.v. Trong ví dụ này, hãy bắt đầu với một kiến ​​trúc cơ bản, trong đó REST API cung cấp quyền truy cập vào một agent HR kết nối với một agent Thông tin Nhân viên: Kiến trúc của hệ thống liên agent bao gồm hai agent (HR \u0026amp; Employee Info), được kết nối bằng A2A.\nNote: The complete, working version of the following example is available in our Agentic AI samples repo.\nCông cụ thông tin nhân viên của chúng tôi sử dụng Amazon Bedrock và công cụ MCP để lấy dữ liệu nhân viên (xem mã đầy đủ cho các khía cạnh đó): employee_agent = Agent( model=bedrock_model, name=\u0026ldquo;Employee Agent\u0026rdquo;, description=\u0026ldquo;Answers questions about employees\u0026rdquo;, tools=tools, system_prompt=\u0026ldquo;you must abbreviate employee first names and list all their skills\u0026rdquo; )\nĐể hiển thị tác nhân này thông qua A2A, chúng ta chỉ cần tạo máy chủ A2A và khởi động nó khi chương trình chạy: a2a_server = A2AServer(agent=employee_agent, host=urlparse(EMPLOYEE_AGENT_URL).hostname, port=urlparse(EMPLOYEE_AGENT_URL).port)\nif name == \u0026ldquo;main\u0026rdquo;: a2a_server.serve(host=\u0026ldquo;0.0.0.0\u0026rdquo;, port=8001)\nLưu ý rằng chúng tôi vượt qua EMPLOYEE_AGENT_URL thông qua một biến môi trường. Điều này giúp định nghĩa cơ sở hạ tầng của chúng ta biết URL điểm cuối có thể thiết lập máy chủ và cổng được sử dụng trong thẻ tác nhân A2A (được máy khách A2A sử dụng để khám phá tác nhân).\nHiện tại, chúng ta có thể truy cập vào tác nhân Thông tin nhân viên thông qua A2A và chúng ta có thể tạo tác nhân HR: provider = A2AClientToolProvider(known_agent_urls=[EMPLOYEE_AGENT_URL]) agent = Agent(model=bedrock_model, tools=provider.tools)\nTác nhân này giờ đây có thể được gọi theo nhiều cách khác nhau. Trong ví dụ này, chúng tôi gọi nó từ một yêu cầu REST. Xem mã đầy đủ để biết các khía cạnh REST. Sau đây là những gì xảy ra khi yêu cầu REST được thực hiện:\nNgười dùng (có thể thông qua ứng dụng web hoặc ứng dụng di động) gửi truy vấn như \u0026ldquo;liệt kê những nhân viên có kỹ năng liên quan đến AI\u0026rdquo; Nhân viên HR sử dụng mô hình Amazon Nova để hiểu truy vấn của người dùng và quyết định rằng truy vấn đó cần được gửi đến nhân viên thông tin nhân viên. Khi sử dụng A2A, truy vấn sẽ được gửi đến tác nhân Thông tin nhân viên. Tác nhân Thông tin nhân viên sử dụng mô hình Amazon Nova để hiểu truy vấn và quyết định cần gọi máy chủ MCP Dữ liệu nhân viên. Tác nhân Thông tin nhân viên gọi máy chủ MCP Dữ liệu nhân viên để truy vấn cơ sở dữ liệu nhân viên và trả dữ liệu về mô hình Nova. Với yêu cầu của hệ thống là viết tắt tên của nhân viên, mô hình sẽ lấy danh sách nhân viên, định dạng danh sách một cách đẹp mắt, viết tắt tên và trả lại văn bản cho tác nhân Thông tin nhân viên. Tác nhân Thông tin nhân viên trả lại văn bản cho tác nhân HR, tác nhân này trả lại văn bản trong phản hồi REST. Tất nhiên, tất cả những điều này đều có thể chạy trên AWS bằng nhiều môi trường thời gian chạy khác nhau (Amazon Elastic Kubernetes Service (Amazon EKS), Amazon Elastic Container Service (Amazon ECS), Amazon Bedrock AgentCore, AWS Lambda, v.v.). Ví dụ này chứa AWS CloudFormation deployment template triển khai các tác nhân và máy chủ MCP trên Amazon ECS (tất cả trong một VPC) và một Bộ cân bằng tải ứng dụng để công khai dịch vụ REST.\nChúng ta có thể thử nghiệm với curl: curl -X POST \u0026ndash;location \u0026ldquo;http://something.us-east-1.elb.amazonaws.com/inquire\" -H \u0026ldquo;Content-Type: application/json\u0026rdquo; -d \u0026lsquo;{\u0026ldquo;question\u0026rdquo;: \u0026ldquo;list employees that have skills related to AI programming\u0026rdquo;}\u0026rsquo; Và chúng ta quay lại: Here are the employees with skills related to AI programming:\nA. Rosalez - Machine Learning, REST API E. Owusu - DevOps, Machine Learning, Python J. Doe- Machine Learning, JavaScript K. Mensah - REST API, Kubernetes, Machine Learning, Node.js M. Rivera - AWS, Kubernetes, GraphQL, Machine Learning M. Major - MongoDB, Angular, Kotlin, Machine Learning, REST API C. Salazar - React, Machine Learning, SQL, Kotlin N. Wolf - SQL, Machine Learning, Docker, DevOps, Git If you need more detailed information about any of these employees or require further assistance, please let me know!\nLấy the complete source cho ví dụ này.\nVới Strands Agents, chỉ cần vài dòng mã là có thể hiển thị các agent dưới dạng máy chủ A2A và giao tiếp giữa các agent với nhau bằng A2A. Trong các bài viết tiếp theo, chúng tôi sẽ đề cập đến các dạng agent nâng cao hơn như Swarms, Graphs và Workflows.\nQuan điểm của khách hàng Chúng tôi đã nhận được phản hồi từ một số khách hàng và đối tác rất hào hứng với dịch vụ hỗ trợ A2A của chúng tôi. Dưới đây là một số chia sẻ của họ:\n“Tại Autodesk, chúng tôi cam kết thúc đẩy các tiêu chuẩn mở cho AI đại diện và khả năng tương tác khi chúng tôi định hình tương lai của thiết kế và kỹ thuật. Thông qua sự hợp tác với AWS và cộng đồng A2A, chúng tôi rất hào hứng được góp phần xây dựng một hệ sinh thái nơi các đại diện thông minh có thể giao tiếp liền mạch trên các nền tảng Autodesk. Khi chúng tôi tiếp tục cải tiến Dịch vụ Nền tảng Autodesk với các khả năng AI tạo sinh, chúng tôi nhận thấy tiềm năng to lớn trong cách các đại diện AI có khả năng tương tác có thể chuyển đổi quy trình làm việc trong lĩnh vực kiến ​​trúc, kỹ thuật, xây dựng và sản xuất. Hợp tác cùng AWS, chúng tôi cam kết tạo ra các giải pháp cho phép cộng tác đại diện an toàn và hiệu quả, đồng thời duy trì các tiêu chuẩn cấp doanh nghiệp.” – Ritesh Bansal, Phó Chủ tịch Phân tích Dữ liệu, Thông tin chi tiết và Nền tảng AI/ML, Autodesk\n“Cam kết của chúng tôi trong việc phát triển Agentic AI, các giao thức mở và khả năng tương tác là cốt lõi trong tầm nhìn của chúng tôi về các mạng lưới an toàn và thông minh. Bằng cách hợp tác với AWS và cộng đồng A2A, chúng tôi đang thúc đẩy đổi mới để thiết lập các chuẩn mực mới về bảo mật dựa trên AI, cho phép các tổ chức hoạt động với khả năng phục hồi và sự tự tin cao hơn trong kỷ nguyên AI đang phát triển nhanh chóng.” – Raj Chopra, Phó Chủ tịch Cấp cao kiêm Giám đốc Sản phẩm, Bộ phận An ninh, Cisco\n“Khi các tổ chức thiết kế các hệ thống AI agentic ngày càng tinh vi, việc phối hợp giữa các agent và công cụ đang trở nên thiết yếu. Chúng tôi rất vui mừng khi thấy AWS thúc đẩy những nỗ lực như A2A, hỗ trợ các kiến ​​trúc tương tác tốt hơn, giúp các tổ chức và khách hàng của Datadog xây dựng các ứng dụng agent-based dễ quan sát, đáng tin cậy và an toàn hơn.” — Yrieix Garnier, Phó Chủ tịch Sản phẩm, Datadog\n“MongoDB và AWS cùng cam kết xây dựng một hệ sinh thái mở, có khả năng kết hợp, cho phép các nhà phát triển tự do sáng tạo hơn. Việc áp dụng các tiêu chuẩn mở như A2A là một bước quan trọng hướng tới tầm nhìn này, giúp đơn giản hóa cách các tác nhân tương tác với mô hình tài liệu phong phú của MongoDB, khả năng tìm kiếm vector tích hợp và các mô hình AI Voyage.” – Abhinav Mehla, Phó Chủ tịch Chương trình Đối tác Toàn cầu \u0026amp; Hệ sinh thái, MongoDB\n“Khả năng tương tác rất quan trọng để các tác nhân AI hoạt động liền mạch và hiệu quả trên các hệ thống và công cụ doanh nghiệp, đó là lý do tại sao chúng tôi hợp tác với toàn ngành để phát triển tiêu chuẩn A2A, và tại sao chúng tôi sẽ hỗ trợ các tiêu chuẩn mở như A2A và MCP trong Agentforce. Việc AWS hỗ trợ A2A sẽ tiếp tục giúp phá vỡ rào cản giữa các nhà cung cấp, thúc đẩy đổi mới và mang lại giá trị đáng kể cho khách hàng chung của chúng tôi bằng cách cho phép các tác nhân làm việc trên toàn bộ cơ sở hạ tầng và hệ sinh thái công cụ và tác nhân của công ty.” — Gary Lerhaupt, Phó Chủ tịch Kiến trúc Sản phẩm, Salesforce\n“Thật phấn khích khi thấy những công ty hàng đầu trong ngành như AWS ủng hộ giao thức Agent2Agent. Khởi đầu là một ý tưởng táo bạo, giờ đây nó đang nhanh chóng trở thành một tiêu chuẩn chung của ngành – một tiêu chuẩn dựa trên tính mở, bảo mật và khả năng cộng tác đa nền tảng. Với sự hỗ trợ từ AWS và các đối tác khác, hệ sinh thái A2A đang thực sự phát triển mạnh mẽ, và ServiceNow tự hào dẫn đầu xu hướng này bằng cách hiện thực hóa các tác nhân AI cấp doanh nghiệp có khả năng tương tác.” – Joe Davis, Phó Chủ tịch Điều hành Nhóm Kỹ thuật Nền tảng \u0026amp; Công nghệ AI tại ServiceNow.\nSnowflake tin chắc rằng một số cải tiến lớn nhất trong ngành đến từ các giao thức mở và cộng đồng hỗ trợ chúng. Việc tối đa hóa tiềm năng của AI agentic phụ thuộc vào các giao thức mở như A2A, cũng như kiến ​​thức được chia sẻ và các phương pháp hay nhất mà chúng cung cấp. Chúng tôi rất vui mừng khi thấy AWS thể hiện cam kết của họ đối với các giao thức mở cho khả năng tương tác của agent bằng cách bổ sung hỗ trợ A2A vào Strands Agents. Cùng với sự hỗ trợ của cộng đồng công nghệ rộng lớn hơn, ngành công nghiệp sẽ có thể tự động hóa công việc tri thức với các hệ thống agentic an toàn như Strands Agents và Snowflake Cortex Agents. – Dwarak Rajagopal, Phó Chủ tịch Kỹ thuật \u0026amp; Nghiên cứu AI, Snowflake\n“Trong tương lai, một lực lượng lao động phân mảnh gồm con người và các tác nhân AI chắc chắn sẽ cản trở sự phát triển. Chúng tôi tin rằng các giao thức mở, đặc biệt là Giao thức Agent-to-Agent (A2A), đóng vai trò quan trọng trong sự phát triển của lực lượng lao động hỗn hợp này. Chúng cho phép giao tiếp an toàn, hợp tác, đảm bảo khả năng tương tác giữa các hệ sinh thái tác nhân đa dạng. Hệ thống Agent System of Record (ASOR) của Workday mở rộng nền tảng đáng tin cậy của chúng tôi một cách độc đáo để quản lý con người, tài chính và các tác nhân cùng nhau. Hợp tác với AWS và cộng đồng A2A, chúng tôi cam kết thúc đẩy giao tiếp agent an toàn, tương tác. Điều này không chỉ là về công nghệ mới; mà còn là về việc mở khóa một cách an toàn các cấp độ năng suất và đổi mới mới trên toàn doanh nghiệp, đồng thời duy trì khả năng kiểm soát toàn diện.” —Dean Arnold, Phó Chủ tịch Hệ thống Record, Workday\nBắt đầu và cung cấp phản hồi Để bắt đầu xây dựng các tác nhân AI tương tác bằng A2A, hãy xem Strands Agents A2A docs. Chúng tôi rất mong nhận được phản hồi của bạn về việc sử dụng A2A với Strands Agents! Hãy tham gia discussions on the open source Strands Agents Python SDK repo để cho chúng tôi biết bạn cần thêm những gì khi xây dựng hệ thống liên tác nhân.\nNick Aldridge là Kỹ sư Chính tại AWS. Trong 6 năm qua, Nick đã tham gia nhiều sáng kiến ​​AI/ML, bao gồm Amazon Lex và Amazon Bedrock. Gần đây nhất, anh là người lãnh đạo nhóm ra mắt Amazon Bedrock Knowledge Bases. Hiện tại, anh làm việc về AI tạo sinh và cơ sở hạ tầng AI, tập trung vào cộng tác giữa các tác nhân và gọi hàm. Trước khi làm việc tại AWS, Nick đã lấy bằng Thạc sĩ tại Đại học Chicago.\nJames Ward is a Principal Developer Advocate at AWS. James travels the world helping enterprise developers learn how to build reliable systems. His current focus is on helping developers build systems of AI agents using Spring AI, Embabel, Strands Agents, Amazon Bedrock, MCP, and A2A.\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/5-workshop/5.4-s3-onprem/5.4.4-dns-simulation/",
	"title": "Mô phỏng On-premises DNS ",
	"tags": [],
	"description": "",
	"content": "AWS PrivateLink endpoint có một địa chỉ IP cố định trong từng AZ nơi chúng được triển khai, trong suốt thời gian tồn tại của endpoint (cho đến khi endpoint bị xóa). Các địa chỉ IP này được gắn vào Elastic network interface (ENI). AWS khuyến nghị sử dụng DNS để resolve địa chỉ IP cho endpoint để các ứng dụng downstream sử dụng địa chỉ IP mới nhất khi ENIs được thêm vào AZ mới hoặc bị xóa theo thời gian.\nTrong phần này, bạn sẽ tạo một quy tắc chuyển tiếp (forwarding rule) để gửi các yêu cầu resolve DNS từ môi trường truyền thống (mô phỏng) đến Private Hosted Zone trên Route 53. Phần này tận dụng cơ sở hạ tầng do CloudFormation triển khai trong phần Chuẩn bị môi trường.\nTạo DNS Alias Records cho Interface endpoint Click link để đi đến Route 53 management console (Hosted Zones section). Mẫu CloudFormation mà bạn triển khai trong phần Chuẩn bị môi trường đã tạo Private Hosted Zone này. Nhấp vào tên của Private Hosted Zone, s3.us-east-1.amazonaws.com: Tạo 1 record mới trong Private Hosted Zone: Giữ nguyên Record name và record type Alias Button: click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Add another record, và add 1 cái record thứ 2 sử dụng những thông số sau: Record name: *. Record type: giữ giá trị default (type A) Alias Button: Click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Create records Record mới xuất hiện trên giao diện Route 53.\nTạo một Resolver Forwarding Rule Route 53 Resolver Forwarding Rules cho phép bạn chuyển tiếp các DNS queries từ VPC của bạn đến các nguồn khác để resolve name. Bên ngoài môi trường workshop, bạn có thể sử dụng tính năng này để chuyển tiếp các DNS queries từ VPC của bạn đến các máy chủ DNS chạy trên on-premises. Trong phần này, bạn sẽ mô phỏng một on-premises conditional forwarder bằng cách tạo một forwarding rule để chuyển tiếp các DNS queries for Amazon S3 đến một Private Hosted Zone chạy trong \u0026ldquo;VPC Cloud\u0026rdquo; để resolve PrivateLink interface endpoint regional DNS name.\nTừ giao diện Route 53, chọn Inbound endpoints trên thanh bên trái Trong giao diện Inbound endpoint, Chọn ID của Inbound endpoint. Sao chép 2 địa chỉ IP trong danh sách vào trình chỉnh sửa. Từ giao diện Route 53, chọn Resolver \u0026gt; Rules và chọn Create rule Trong giao diện Create rule Name: myS3Rule Rule type: Forward Domain name: s3.us-east-1.amazonaws.com VPC: VPC On-prem Outbound endpoint: VPCOnpremOutboundEndpoint Target IP Addresses: điền cả hai IP bạn đã lưu trữ trên trình soạn thảo (inbound endpoint addresses) và sau đó chọn Submit Bạn đã tạo thành công resolver forwarding rule.\nKiểm tra on-premises DNS mô phỏng. Kết nối đến Test-Interface-Endpoint EC2 instance với Session Manager Kiểm tra DNS resolution. Lệnh dig sẽ trả về địa chỉ IP được gán cho VPC endpoint interface đang chạy trên VPC (địa chỉ IP của bạn sẽ khác): dig +short s3.us-east-1.amazonaws.com Các địa chỉ IP được trả về là các địa chỉ IP VPC enpoint, KHÔNG phải là các địa chỉ IP Resolver mà bạn đã dán từ trình chỉnh sửa văn bản của mình. Các địa chỉ IP của Resolver endpoint và VPC endpoin trông giống nhau vì chúng đều từ khối CIDR VPC Cloud.\nTruy cập vào menu VPC (phần Endpoints), chọn S3 interface endpoint. Nhấp vào tab Subnets và xác nhận rằng các địa chỉ IP được trả về bởi lệnh Dig khớp với VPC endpoint: Hãy quay lại shell của bạn và sử dụng AWS CLI để kiểm tra danh sách các bucket S3 của bạn: aws s3 ls --endpoint-url https://s3.us-east-1.amazonaws.com Kết thúc phiên làm việc của Session Manager của bạn: Trong phần này, bạn đã tạo một Interface Endpoint cho Amazon S3. Điểm cuối này có thể được truy cập từ on-premises thông qua Site-to-Site VPN hoặc AWS Direct Connect. Các điểm cuối Route 53 Resolver outbound giả lập chuyển tiếp các yêu cầu DNS từ on-premises đến một Private Hosted Zone đang chạy trên đám mây. Các điểm cuối Route 53 inbound nhận yêu cầu giải quyết và trả về một phản hồi chứa địa chỉ IP của Interface Endpoint VPC. Sử dụng DNS để giải quyết các địa chỉ IP của điểm cuối cung cấp tính sẵn sàng cao trong trường hợp một Availability Zone gặp sự cố.\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/5-workshop/5.4-s3-onprem/",
	"title": "Truy cập S3 từ môi trường truyền thống",
	"tags": [],
	"description": "",
	"content": "Tổng quan Trong phần này, bạn sẽ tạo một Interface Endpoint để truy cập Amazon S3 từ môi trường truyền thống mô phỏng. Interface Endpoint sẽ cho phép bạn định tuyến đến Amazon S3 qua kết nối VPN từ môi trường truyền thống mô phỏng của bạn.\nTại sao nên sử dụng Interface Endpoint:\nCác Gateway endpoints chỉ hoạt động với các tài nguyên đang chạy trong VPC nơi chúng được tạo. Interface Endpoint hoạt động với tài nguyên chạy trong VPC và cả tài nguyên chạy trong môi trường truyền thống. Khả năng kết nối từ môi trường truyền thống của bạn với aws cloud có thể được cung cấp bởi AWS Site-to-Site VPN hoặc AWS Direct Connect. Interface Endpoint cho phép bạn kết nối với các dịch vụ do AWS PrivateLink cung cấp. Các dịch vụ này bao gồm một số dịch vụ AWS, dịch vụ do các đối tác và khách hàng AWS lưu trữ trong VPC của riêng họ (gọi tắt là Dịch vụ PrivateLink endpoints) và các dịch vụ Đối tác AWS Marketplace. Đối với workshop này, chúng ta sẽ tập trung vào việc kết nối với Amazon S3. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nĐảm bảo truy cập Hybrid an toàn đến S3 bằng cách sử dụng VPC endpoint Tổng quan AWS PrivateLink cung cấp kết nối riêng tư đến các dịch vụ aws từ VPCs hoặc trung tâm dữ liệu (on-premise) mà không làm lộ lưu lượng truy cập ra ngoài public internet.\nTrong bài lab này, chúng ta sẽ học cách tạo, cấu hình, và kiểm tra VPC endpoints để cho phép workload của bạn tiếp cận các dịch vụ AWS mà không cần đi qua Internet công cộng.\nChúng ta sẽ tạo hai loại endpoints để truy cập đến Amazon S3: gateway vpc endpoint và interface vpc endpoint. Hai loại vpc endpoints này mang đến nhiều lợi ích tùy thuộc vào việc bạn truy cập đến S3 từ môi trường cloud hay từ trung tâm dữ liệu (on-premise).\nGateway - Tạo gateway endpoint để gửi lưu lượng đến Amazon S3 hoặc DynamoDB using private IP addresses. Bạn điều hướng lưu lượng từ VPC của bạn đến gateway endpoint bằng các bảng định tuyến (route tables) Interface - Tạo interface endpoint để gửi lưu lượng đến các dịch vụ điểm cuối (endpoints) sử dụng Network Load Balancer để phân phối lưu lượng. Lưu lượng dành cho dịch vụ điểm cuối được resolved bằng DNS. Nội dung Tổng quan về workshop Chuẩn bị Truy cập đến S3 từ VPC Truy cập đến S3 từ TTDL On-premises VPC Endpoint Policies (làm thêm) Dọn dẹp tài nguyên "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/5-workshop/5.5-policy/",
	"title": "VPC Endpoint Policies",
	"tags": [],
	"description": "",
	"content": "Khi bạn tạo một Interface Endpoint hoặc cổng, bạn có thể đính kèm một chính sách điểm cuối để kiểm soát quyền truy cập vào dịch vụ mà bạn đang kết nối. Chính sách VPC Endpoint là chính sách tài nguyên IAM mà bạn đính kèm vào điểm cuối. Nếu bạn không đính kèm chính sách khi tạo điểm cuối, thì AWS sẽ đính kèm chính sách mặc định cho bạn để cho phép toàn quyền truy cập vào dịch vụ thông qua điểm cuối.\nBạn có thể tạo chính sách chỉ hạn chế quyền truy cập vào các S3 bucket cụ thể. Điều này hữu ích nếu bạn chỉ muốn một số Bộ chứa S3 nhất định có thể truy cập được thông qua điểm cuối.\nTrong phần này, bạn sẽ tạo chính sách VPC Endpoint hạn chế quyền truy cập vào S3 bucket được chỉ định trong chính sách VPC Endpoint.\nKết nối tới EC2 và xác minh kết nối tới S3. Bắt đầu một phiên AWS Session Manager mới trên máy chủ có tên là Test-Gateway-Endpoint. Từ phiên này, xác minh rằng bạn có thể liệt kê nội dung của bucket mà bạn đã tạo trong Phần 1: Truy cập S3 từ VPC. aws s3 ls s3://\u0026lt;your-bucket-name\u0026gt; Nội dung của bucket bao gồm hai tệp có dung lượng 1GB đã được tải lên trước đó.\nTạo một bucket S3 mới; tuân thủ mẫu đặt tên mà bạn đã sử dụng trong Phần 1, nhưng thêm \u0026lsquo;-2\u0026rsquo; vào tên. Để các trường khác là mặc định và nhấp vào Create. Tạo bucket thành công. Policy mặc định cho phép truy cập vào tất cả các S3 Buckets thông qua VPC endpoint.\nTrong giao diện Edit Policy, sao chép và dán theo policy sau, thay thế yourbucketname-2 với tên bucket thứ hai của bạn. Policy này sẽ cho phép truy cập đến bucket mới thông qua VPC endpoint, nhưng không cho phép truy cập đến các bucket còn lại. Chọn Save để kích hoạt policy. {\r\u0026#34;Id\u0026#34;: \u0026#34;Policy1631305502445\u0026#34;,\r\u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,\r\u0026#34;Statement\u0026#34;: [\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;Stmt1631305501021\u0026#34;,\r\u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;arn:aws:s3:::yourbucketname-2\u0026#34;,\r\u0026#34;arn:aws:s3:::yourbucketname-2/*\u0026#34;\r],\r\u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;\r}\r]\r} Cấu hình policy thành công.\nTừ session của bạn trên Test-Gateway-Endpoint instance, kiểm tra truy cập đến S3 bucket bạn tạo ở bước đầu aws s3 ls s3://\u0026lt;yourbucketname\u0026gt; Câu lệnh trả về lỗi bởi vì truy cập vào S3 bucket không có quyền trong VPC endpoint policy.\nTrở lại home directory của bạn trên EC2 instance cd~ Tạo file fallocate -l 1G test-bucket2.xyz Sao chép file lên bucket thứ 2 aws s3 cp test-bucket2.xyz s3://\u0026lt;your-2nd-bucket-name\u0026gt; Thao tác này được cho phép bởi VPC endpoint policy.\nSau đó chúng ta kiểm tra truy cập vào S3 bucket đầu tiên\naws s3 cp test-bucket2.xyz s3://\u0026lt;your-1st-bucket-name\u0026gt;\nCâu lệnh xảy ra lỗi bởi vì bucket không có quyền truy cập bởi VPC endpoint policy.\nTrong phần này, bạn đã tạo chính sách VPC Endpoint cho Amazon S3 và sử dụng AWS CLI để kiểm tra chính sách. Các hoạt động AWS CLI liên quan đến bucket S3 ban đầu của bạn thất bại vì bạn áp dụng một chính sách chỉ cho phép truy cập đến bucket thứ hai mà bạn đã tạo. Các hoạt động AWS CLI nhắm vào bucket thứ hai của bạn thành công vì chính sách cho phép chúng. Những chính sách này có thể hữu ích trong các tình huống khi bạn cần kiểm soát quyền truy cập vào tài nguyên thông qua VPC Endpoint.\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/6-self-evaluation/",
	"title": "Tự đánh giá",
	"tags": [],
	"description": "",
	"content": "Trong thời gian thực tập tại [Tên công ty/tổ chức] từ [ngày bắt đầu] đến [ngày kết thúc], tôi đã có cơ hội tham gia vào [mô tả dự án hoặc công việc chính].\nQuá trình này giúp tôi nâng cao khả năng [liệt kê kỹ năng: phân tích dữ liệu, lập trình, lập kế hoạch, thuyết trình, hợp tác nhóm…].\nTôi luôn duy trì tinh thần học hỏi, chủ động trong công việc và phối hợp hiệu quả với đồng nghiệp nhằm đạt được mục tiêu chung của nhóm.\nDưới đây là phần tự đánh giá chi tiết theo các tiêu chí đã định:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về công việc, vận dụng kiến thức vào thực tế, sử dụng công cụ phù hợp ✅ ☐ ☐ 2 Khả năng học hỏi Nhanh chóng tiếp thu kiến thức mới, chủ động học hỏi từ các tình huống thực tế ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mới mà không cần nhắc nhở ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành nhiệm vụ đúng hạn, đảm bảo chất lượng công việc ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, quy trình làm việc và nội quy của tổ chức ☐ ✅ ☐ 6 Tính cầu tiến Sẵn sàng nhận phản hồi và cải thiện bản thân ✅ ☐ ☐ 7 Giao tiếp Trình bày ý tưởng rõ ràng, dễ hiểu, phản hồi hiệu quả ☐ ✅ ☐ 8 Hợp tác nhóm Phối hợp hiệu quả với đồng nghiệp, tham gia đóng góp vào nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Giữ thái độ tôn trọng với đồng nghiệp và môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Phân tích vấn đề, đưa ra giải pháp khả thi và sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Mức độ hoàn thành nhiệm vụ và đóng góp tích cực vào tiến độ chung ☐ ✅ ☐ 12 Tổng thể Đánh giá chung về nỗ lực, khả năng thích nghi và tiến bộ trong suốt quá trình thực tập ✅ ☐ ☐ Cần cải thiện Tăng cường quản lý thời gian để hoàn thành công việc hiệu quả hơn Rèn luyện kỹ năng phân tích và giải quyết vấn đề phức tạp Chủ động hơn trong giao tiếp nội bộ để nâng cao hiệu quả phối hợp nhóm "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/5-workshop/5.6-cleanup/",
	"title": "Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "Dọn dẹp tài nguyên Xin chúc mừng bạn đã hoàn thành xong lab này! Trong lab này, bạn đã học về các mô hình kiến trúc để truy cập Amazon S3 mà không sử dụng Public Internet.\nBằng cách tạo Gateway endpoint, bạn đã cho phép giao tiếp trực tiếp giữa các tài nguyên EC2 và Amazon S3, mà không đi qua Internet Gateway. Bằng cách tạo Interface endpoint, bạn đã mở rộng kết nối S3 đến các tài nguyên chạy trên trung tâm dữ liệu trên chỗ của bạn thông qua AWS Site-to-Site VPN hoặc Direct Connect. Dọn dẹp Điều hướng đến Hosted Zones trên phía trái của bảng điều khiển Route 53. Nhấp vào tên của s3.us-east-1.amazonaws.com zone. Nhấp vào Delete và xác nhận việc xóa bằng cách nhập từ khóa \u0026ldquo;delete\u0026rdquo;. Disassociate Route 53 Resolver Rule - myS3Rule from \u0026ldquo;VPC Onprem\u0026rdquo; and Delete it. 4.Mở console của CloudFormation và xóa hai stack CloudFormation mà bạn đã tạo cho bài thực hành này:\nPLOnpremSetup PLCloudSetup Xóa các S3 bucket Mở bảng điều khiển S3 Chọn bucket chúng ta đã tạo cho lab, nhấp chuột và xác nhận là empty. Nhấp Delete và xác nhận delete. + "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/7-feedback/",
	"title": "Chia sẻ, đóng góp ý kiến",
	"tags": [],
	"description": "",
	"content": " Tại đây bạn có thể tự do đóng góp ý kiến cá nhân về những trải nghiệm khi tham gia chương trình First Cloud Journey, giúp team FCJ cải thiện những vấn đề còn thiếu sót dựa trên các hạng mục sau:\nĐánh giá chung 1. Môi trường làm việc\nTrong thời gian training tại AWS, mình cảm nhận môi trường làm việc rất chuyên nghiệp và năng động. Mọi người giao tiếp thẳng thắn, rõ ràng và luôn tạo cảm giác thoải mái khi trao đổi. Điều mình thích nhất là văn hóa “learning by doing” – khuyến khích thực hành nhiều hơn lý thuyết. Tuy nhiên, mình nghĩ AWS có thể tổ chức thêm một số buổi chia sẻ nội bộ để thực tập sinh hiểu sâu hơn về các team khác.\n2. Sự hỗ trợ của mentor / team admin\nMentor hỗ trợ rất tận tâm, luôn đưa ra định hướng rõ ràng trước mỗi nhiệm vụ. Khi gặp khó khăn, mentor không giải quyết thay mà gợi mở để mình tự tìm ra hướng giải quyết – điều này giúp mình tiến bộ rất nhanh. Team điều phối cũng phản hồi nhanh, hỗ trợ tài khoản, tài liệu và quyền truy cập… rất kịp thời.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nNhững nội dung training liên quan chặt chẽ với chuyên ngành An toàn thông tin của mình, đặc biệt là phần về IAM, kiến trúc bảo mật và quy trình quản trị tài nguyên AWS. Mình cũng được tiếp cận thêm những công nghệ mà chương trình học ở trường chưa đề cập đến, giúp kiến thức được mở rộng đáng kể.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như phân tích log, triển khai hạ tầng theo best practice, xử lý tình huống giả lập và quản lý tài nguyên AWS. Ngoài kỹ năng kỹ thuật, mình còn nâng cao khả năng giao tiếp, planning và quản lý thời gian nhờ việc làm việc theo sprint và deadline rõ ràng.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nTinh thần đồng đội trong team rất tốt. Mọi người chủ động hỗ trợ nhau, chia sẻ kinh nghiệm mà không ngần ngại. Môi trường nghiêm túc nhưng vẫn thoải mái, dễ tương tác. Nhờ vậy, mình nhanh chóng hòa nhập và tự tin hơn khi tham gia vào các buổi thảo luận kỹ thuật.\n6. Chính sách / phúc lợi cho thực tập sinh\nChính sách dành cho thực tập sinh rõ ràng và linh hoạt. Thời gian làm việc phù hợp với lịch học, tạo điều kiện để mình cân bằng giữa việc học và training. Ngoài ra, việc được tham dự các workshop nội bộ và buổi đào tạo chuyên môn là một điểm cộng lớn.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập?\n→ Việc được tiếp xúc trực tiếp với hệ thống AWS thật và luôn có mentor hỗ trợ đúng lúc.\nNếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao?\n→ Có. Vì môi trường đào tạo chuyên nghiệp, định hướng rõ ràng và mang lại kỹ năng thực tế mà ít nơi khác có.\nĐề xuất \u0026amp; mong muốn Mong muốn có thêm các mini-project theo nhóm để tăng trải nghiệm. Nếu có cơ hội, mình muốn tiếp tục chương trình ở cấp độ cao hơn như AWS Internship / Cloud Engineer Trainee. Hy vọng sẽ có thêm nội dung chuyên sâu liên quan đến bảo mật cloud và ứng dụng AI trong giám sát hệ thống. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]