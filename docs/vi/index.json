[
{
	"uri": "https://phuong721.github.io/learning-aws/vi/5-workshop/5.1-workshop-overview/",
	"title": "Tổng quan Workshop",
	"tags": [],
	"description": "",
	"content": "Giới thiệu Workshop này hướng dẫn bạn triển khai một ứng dụng phân tích DNA full-stack trên AWS. Ứng dụng cho phép người dùng phân tích chuỗi DNA, quản lý kết quả, và trực quan hóa dữ liệu sinh học.\nKiến trúc Ứng dụng Frontend (React + Vite) Framework: React 18 với TypeScript UI Libraries: Material-UI, TailwindCSS, Recharts State Management: React Context API Routing: React Router v6 Form Handling: React Hook Form với Zod validation HTTP Client: Axios Hosting: S3 + CloudFront CDN Backend (Spring Boot) Framework: Spring Boot 3.x Language: Java 17 Database: MySQL 8.0 với Spring Data JPA Security: Spring Security với JWT authentication API: RESTful API với proper error handling Hosting: EC2 instances với Auto Scaling Database (RDS MySQL) Engine: MySQL 8.0.40 Instance: db.t3.micro (có thể scale up) Storage: 20GB gp3 với encryption Backup: Automated backups với 3-7 days retention High Availability: Multi-AZ deployment (optional) Kiến trúc AWS Network Layer VPC (10.0.0.0/16)\r├── Public Subnets (10.0.1.0/24, 10.0.3.0/24)\r│ ├── Internet Gateway\r│ ├── NAT Gateway\r│ └── Application Load Balancer\r│\r└── Private Subnets (10.0.2.0/24, 10.0.4.0/24)\r├── EC2 Instances (Auto Scaling Group)\r├── RDS MySQL (Multi-AZ)\r└── VPC Endpoints (S3, CloudWatch, SSM, Cognito) Application Flow User Browser\r│\r├─── HTTPS ──\u0026gt; CloudFront ──\u0026gt; S3 (Static Frontend)\r│\r└─── HTTPS ──\u0026gt; API Gateway ──\u0026gt; ALB ──\u0026gt; EC2 (Backend API)\r│\r└──\u0026gt; RDS MySQL Security Architecture Internet\r│\r├─── CloudFront (HTTPS only)\r│ └─── S3 Bucket Policy (CloudFront OAI)\r│\r└─── API Gateway (Resource Policy)\r└─── ALB Security Group (Port 80/443)\r└─── EC2 Security Group (Port 8080 from ALB only)\r└─── RDS Security Group (Port 3306 from EC2 only) Các Tính năng Chính 1. User Authentication Đăng ký và đăng nhập người dùng JWT token-based authentication AWS Cognito integration (optional) Session management 2. DNA Analysis Upload và phân tích chuỗi DNA Hỗ trợ nhiều định dạng file Xử lý batch processing Lưu trữ kết quả phân tích 3. Data Visualization Biểu đồ phân tích DNA Dashboard với metrics Export kết quả dưới nhiều định dạng 4. User Management Quản lý profile người dùng Lịch sử phân tích Role-based access control Infrastructure as Code CloudFormation Template Template infrastructure.yaml bao gồm:\nNetworking (Lines 1-400)\nVPC với DNS support 2 Public Subnets (Multi-AZ) 2 Private Subnets (Multi-AZ) Internet Gateway NAT Gateway (có thể tắt để tiết kiệm chi phí) Route Tables VPC Endpoints (S3, CloudWatch, SSM, Cognito) Compute (Lines 400-700)\nLaunch Template với User Data script Auto Scaling Group (1-4 instances) Application Load Balancer Target Group với health checks Scaling Policies (CPU-based) Storage \u0026amp; CDN (Lines 700-900)\nS3 Bucket cho Frontend S3 Bucket Policy CloudFront Distribution CloudFront Origin Access Identity Database (Lines 900-1000)\nRDS MySQL Instance DB Subnet Group Automated Backups Encryption at rest Security (Lines 1000-1200)\nSecurity Groups (ALB, EC2, RDS, VPC Endpoints) IAM Roles (EC2, CloudWatch, S3) IAM Instance Profile Cognito User Pool (optional) Secrets Manager (optional) Monitoring (Lines 1200-1393)\nCloudWatch Log Groups CloudWatch Alarms (CPU, Memory) SNS Topic cho alerts API Gateway với CORS Tối ưu Chi phí 1. VPC Endpoints thay vì NAT Gateway Tiết kiệm: ~$20-25/tháng\nS3 Gateway Endpoint: FREE Interface Endpoints: $7.20/endpoint/tháng Tổng: ~$28/tháng vs NAT Gateway $32/tháng + data transfer 2. Instance Sizing Development: t3.micro ($7-10/tháng) Production: t3.small hoặc t3.medium\n3. RDS Optimization Single-AZ cho development Multi-AZ cho production Automated backups với retention phù hợp 4. CloudFront Caching Giảm requests đến S3 Giảm latency cho users Free tier: 1TB data transfer/tháng Best Practices được áp dụng 1. Security ✅ Private subnets cho EC2 và RDS ✅ Security Groups với least privilege ✅ IAM Roles thay vì hardcoded credentials ✅ Encryption at rest và in transit ✅ VPC Endpoints cho private connectivity ✅ CloudTrail cho audit logging (optional)\n2. High Availability ✅ Multi-AZ deployment ✅ Auto Scaling Group ✅ Application Load Balancer ✅ RDS automated backups ✅ CloudFront global CDN\n3. Monitoring \u0026amp; Logging ✅ CloudWatch Logs cho application logs ✅ CloudWatch Alarms cho metrics ✅ SNS notifications ✅ Health checks trên ALB và ASG\n4. Automation ✅ Infrastructure as Code với CloudFormation ✅ User Data scripts cho EC2 initialization ✅ Systemd service cho application management ✅ Automated deployments với scripts\nCác Bước Triển khai Chuẩn bị (10 phút)\nCài đặt AWS CLI Tạo EC2 Key Pair Cấu hình parameters Deploy Infrastructure (15-20 phút)\nValidate CloudFormation template Create stack Đợi resources được tạo Deploy Backend (20-30 phút)\nBuild JAR file Upload lên S3 Deploy lên EC2 Cấu hình database connection Deploy Frontend (10-15 phút)\nBuild React application Upload lên S3 Invalidate CloudFront cache Testing (15-30 phút)\nTest authentication Test DNA analysis features Verify monitoring Cleanup (5-10 phút)\nDelete CloudFormation stack Verify all resources deleted Kết quả Mong đợi Sau khi hoàn thành workshop, bạn sẽ có:\n✅ Một ứng dụng full-stack hoạt động trên AWS ✅ Hiểu biết sâu về AWS networking và security ✅ Kinh nghiệm với Infrastructure as Code ✅ Kiến thức về cost optimization ✅ Best practices cho production deployment\nTài nguyên Tham khảo AWS CloudFormation Documentation AWS VPC Best Practices AWS Well-Architected Framework Spring Boot on AWS React Deployment Best Practices "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/",
	"title": "Báo cáo thực tập",
	"tags": [],
	"description": "",
	"content": "Báo cáo thực tập Thông tin sinh viên: Họ và tên: Đỗ Đoàn Duy Phương\nSố điện thoại: 0983394370\nEmail: phuongdddse180235@fpt.edu.vn\nTrường: Đại học FPT TP.HCM\nNgành: An toàn thông tin\nLớp: AWS082025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 08/09/2025 đến ngày 30/12/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/4-eventparticipated/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “AWS Mastery #2 – CloudFormation \u0026amp; CDK Workshop” Mục Đích Của Sự Kiện Workshop “AWS Mastery #2 – CloudFormation \u0026amp; CDK” được tổ chức nhằm giúp người tham dự:\nNắm bắt tư duy Infrastructure as Code (IaC) – phương pháp quản lý hệ thống hạ tầng bằng mã nguồn. Hiểu rõ cách AWS triển khai, tự động hóa và vận hành tài nguyên thông qua CloudFormation và CDK. Cung cấp góc nhìn tổng quan và thực tiễn về Docker, container orchestration, và các dịch vụ như ECS, EKS, App Runner. Trau dồi tư duy DevOps, khả năng kiểm soát thay đổi, tái sử dụng hạ tầng, và triển khai nhanh chóng. Trực tiếp quan sát các demo giúp củng cố khả năng triển khai hạ tầng thực tế. Sự kiện phù hợp với lập trình viên, DevOps engineer, cloud engineer hoặc bất kỳ ai đang muốn tiếp cận tự động hóa trên AWS.\nDanh Sách Diễn Giả Bao Huynh Thinh Nguyen – AWS Community Builder Vi Tran – AWS Community Builder Các diễn giả đều có nhiều kinh nghiệm triển khai hệ thống AWS thực tế, nên phần trình bày rất thực tiễn, dễ theo kịp và chứa nhiều kinh nghiệm áp dụng ngay.\nNội Dung Nổi Bật 1. Tư duy Infrastructure as Code (IaC) Workshop bắt đầu với việc chỉ ra lý do vì sao ClickOps (click chuột thủ công trên console) gây ra hạn chế:\nDễ bị lỗi do thao tác người dùng. Khó tái tạo môi trường giữa các team. Không kiểm soát được các thay đổi ngoài quy trình. Khó audit, khó rollback và khó mở rộng. IaC được giới thiệu như một bước chuyển đổi tất yếu trong DevOps:\nAutomation: Hạ tầng được tạo và quản lý hoàn toàn tự động. Reproducibility: Môi trường được build ra giống 100%. Scalability: Mở rộng nhanh chóng bằng code. Collaboration: Mọi thay đổi được version-control (Git), dễ phối hợp nhóm. 2. AWS CloudFormation – Công cụ IaC “native” của AWS CloudFormation là gì? CloudFormation cho phép mô tả toàn bộ hạ tầng bằng YAML hoặc JSON và AWS sẽ tự động tạo mọi thứ.\nCác khái niệm quan trọng được trình bày:\nCloudFormation Template Anatomy Parameters:\nCho phép template tái sử dụng bằng cách truyền tham số. Ví dụ: AMI ID, instance type, VPC ID. Mappings:\nChứa các giá trị phụ thuộc vùng, ví dụ AMI khác nhau giữa us-east-1 và ap-southeast-1. Conditions:\nTạo tài nguyên theo điều kiện (ví dụ chỉ tạo EC2 nếu environment = production). Resources:\nPhần quan trọng nhất của template. Mô tả full tài nguyên S3, EC2, IAM, VPC,\u0026hellip; Outputs:\nXuất giá trị ra ngoài, dùng để cross-stack reference hoặc chia sẻ cho team. Drift Detection Tính năng cho phép phát hiện khi một tài nguyên bị thay đổi trực tiếp trên console. Giúp giữ hạ tầng “khớp” với template đã định nghĩa. Diễn giả trình bày minh hoạ trực quan giúp tôi dễ hiểu về sự khác biệt giữa “state từ template” và “state ngoài đời thực”.\n3. AWS CDK – Viết hạ tầng bằng ngôn ngữ lập trình CDK được giới thiệu như phiên bản nâng cấp của CloudFormation:\nDùng ngôn ngữ lập trình như TypeScript, Python, Java, Go. Code CDK sẽ được dịch thành CloudFormation template thông qua cdk synth. Dễ tái sử dụng, dễ tạo abstraction, dễ maintain. Các khái niệm cốt lõi: Constructs L1: mapping 1:1 CloudFormation (chi tiết nhất). L2: API thân thiện hơn, có default best practice. L3: solution patterns triển khai trọn gói (như website hosting, pipeline). Stack \u0026amp; App Stack = 1 CloudFormation stack. App có thể gồm nhiều stack. CDK CLI Một số lệnh quan trọng:\ncdk init – tạo project. cdk bootstrap – chuẩn bị môi trường lần đầu. cdk synth – generate CloudFormation template. cdk deploy – triển khai. cdk destroy – xóa. cdk diff – so sánh thay đổi. cdk drift – kiểm tra drift. CDK giúp người làm DevOps và developer tự động hóa dễ dàng hơn rất nhiều so với viết YAML thủ công.\n4. Docker \u0026amp; Container Services trên AWS Phần này rất quan trọng vì container gần như là tiêu chuẩn hiện nay.\nDocker Fundamentals Container nhẹ, khởi động nhanh hơn VM. Dockerfile: mô tả cách build image. Image: blueprint tạo container. Amazon ECR Registry chứa images. Hỗ trợ scanning, immutable tags và IAM authorization. 5. Orchestration: ECS, EKS và App Runner Amazon ECS Dịch vụ orchestration “simple \u0026amp; native”. 2 kiểu chạy: EC2 launch type (tự quản lý server) Fargate launch type (serverless) Thành phần: Cluster – Task Definition – Service Amazon EKS Managed Kubernetes. Dùng cho workloads cần multi-cloud hoặc cần đầy đủ sức mạnh Kubernetes. App Runner Dịch vụ đơn giản nhất để chạy web app/container. Tự build → deploy → scale. Thích hợp cho team nhỏ hoặc prototype. Những Gì Học Được 1. Tư duy quản trị hạ tầng hiện đại IaC không chỉ là công cụ, mà còn là triết lý quản lý hạ tầng chuẩn hoá, giảm rủi ro vận hành. Drift detection là công cụ hữu ích để đảm bảo sự ổn định. 2. Kiến thức chuyên sâu về IaC Hiểu chi tiết các component của CloudFormation template giúp tôi có thể đọc – viết template tốt hơn. Học được cách viết CDK với construct L2/L3 nhanh và “clean” hơn nhiều so với YAML. 3. Kiến trúc container hiện đại Khả năng phân biệt rõ khi nào dùng ECS, khi nào dùng Fargate, khi nào dùng EKS. Biết cách đánh giá workloads dựa trên chi phí – hiệu suất – yêu cầu vận hành. 4. Kinh nghiệm thực tế trong DevOps cdk diff cực kỳ hữu ích trước khi deploy production. IaC giúp các team rất dễ review code trước khi bản thân hạ tầng được tạo ra. Ứng Dụng Vào Công Việc Bắt đầu chuyển hạ tầng nhỏ sang IaC bằng CloudFormation hoặc CDK. Viết template cho S3 bucket, IAM role, hoặc VPC cơ bản để thực hành. Triển khai ứng dụng mẫu bằng ECS Fargate để hiểu end-to-end pipeline. Tự xây dựng demo CDK áp dụng constructs ở cả L1–L3. Đề xuất áp dụng container registry ECR cho pipeline CI/CD của team. Tạo tài liệu nội bộ hướng dẫn cách dùng cdk diff để kiểm soát thay đổi. Trải Nghiệm Trong Event Buổi workshop có không khí chuyên nghiệp nhưng rất gần gũi, diễn giả nhiệt tình trả lời câu hỏi. Demo trực tiếp CDK và ECS giúp tôi hiểu rõ bản chất “as code” của toàn bộ hệ thống AWS. Tôi đặc biệt thích phần so sánh ECS vs EKS vì giúp tôi định hình khi nào sử dụng orchestration đơn giản hoặc Kubernetes. Kết nối với những người tham gia khác giúp tôi học thêm nhiều kinh nghiệm trong nghề DevOps. Một số hình ảnh trong sự kiện Sau sự kiện, tôi cảm thấy mình tự tin hơn rất nhiều trong việc tiếp cận AWS Infrastructure as Code và container orchestration, đồng thời có định hướng rõ ràng để áp dụng chúng vào công việc thực tế.\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/1-worklog/1.9-week9/",
	"title": "Worklog Tuần 9",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 9: Thu thập yêu cầu và bắt đầu xây dựng nội dung cho Proposal và Proposal Template của dự án BDSS. Viết các phần mở đầu: Executive Summary, Problem Statement, Solution Overview. Xác định kiến trúc AWS để đưa vào cả hai tài liệu. Hoàn thiện bản nháp đầu tiên cho Proposal và phần khung (structure) của Proposal Template. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Nhận yêu cầu từ mentor về nội dung cần có trong Proposal \u0026amp; Proposal Template - Xác định outline chung cho cả hai tài liệu 03/11/2025 03/11/2025 proposal.docx Proposal Template.docx 3 - Viết Executive Summary cho Proposal - Chuẩn bị phần mở đầu tương ứng trong Proposal Template 04/11/2025 04/11/2025 proposal.docx 4 - Viết Problem Statement: mô tả vấn đề tại các cơ sở y tế \u0026amp; nhu cầu kết nối người hiến máu - Điều chỉnh nội dung để phù hợp khi đưa vào Proposal Template 05/11/2025 05/11/2025 Tài liệu nhóm 5 - Viết Proposed Solution cho Proposal - Đồng thời hoàn thiện phần Solution Overview trong Proposal Template 06/11/2025 06/11/2025 proposal.docx 6 - Mô tả Solution Architecture theo 4 layer - Rà soát cách trình bày kiến trúc trong Proposal Template để khớp layout chuẩn 07/11/2025 07/11/2025 AWS Docs 7 - Viết phần Technical Implementation và lộ trình triển khai - Đồng thời điền các mục tương ứng trong Proposal Template (Activities, Deliverables, Scope…) 08/11/2025 08/11/2025 Proposal Template.docx CN - Hoàn thiện bản nháp đầu cho cả Proposal và Proposal Template - Gửi mentor review và ghi nhận feedback - Cập nhật Worklog tuần 9 09/11/2025 09/11/2025 Slack/Meeting Kết quả đạt được tuần 9: Hoàn thành bản nháp đầu tiên của Proposal và phần skeleton của Proposal Template, gồm các mục:\nExecutive Summary Problem Statement Proposed Cloud Solution Solution Architecture (4 lớp) Technical Implementation (draft) Xây dựng được cấu trúc hoàn chỉnh cho Proposal Template, sẵn sàng điền nội dung chi tiết ở tuần sau.\nHiểu rõ hơn yêu cầu từ mentor và cách trình bày nội dung theo hai định dạng khác nhau:\nProposal: mô tả chi tiết Proposal Template: mô hình chuẩn AWS Xác định rõ kiến trúc AWS sử dụng trong cả hai tài liệu:\nRoute 53, CloudFront API Gateway – EC2 RDS MySQL Cognito Authorization CI/CD Pipeline Monitoring \u0026amp; Security Layer Tạo nền tảng nội dung quan trọng để tuần tới tiếp tục hoàn thiện:\nTechnical Plan, Budget Estimate, Risk Assessment và hoàn chỉnh Proposal Template.\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/1-worklog/1.8-week8/",
	"title": "Worklog Tuần 8",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 8: Nắm được yêu cầu kiến trúc cần xây dựng cho dự án. Thành thạo cách sử dụng draw.io để dựng sơ đồ hệ thống. Hiểu rõ mối quan hệ giữa các service AWS trong kiến trúc: Networking, Compute, Database, CI/CD, Monitoring. Hoàn thiện bản Network Architecture Diagram và gửi mentor review. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Thu thập yêu cầu kiến trúc từ mentor - Xác định phạm vi kiến trúc cần vẽ (VPC, subnet, routing, frontend, backend, database, CI/CD…) 27/10/2025 27/10/2025 Nội bộ FCJ 3 - Bắt đầu dựng sơ đồ kiến trúc mạng trên draw.io - Tạo VPC, public/private subnet, Internet Gateway - Thêm Route 53, CloudFront, S3 FE 28/10/2025 28/10/2025 AWS Docs 4 - Thêm API Gateway, EC2, Security Group - Thiết kế RDS trong private subnet - Vẽ luồng xử lý FE → CloudFront → API → EC2 → RDS 29/10/2025 29/10/2025 AWS Architecture Icons 5 - Tích hợp CI/CD pipeline (CodePipeline, CodeBuild, CloudFormation) - Thêm Cognito/Auth và hoàn thiện Security Layer 30/10/2025 30/10/2025 aws.amazon.com 6 - Tối ưu bố cục sơ đồ, chỉnh màu + border - Đánh số thứ tự luồng xử lý - Xuất bản sơ đồ và gửi mentor nhận xét 31/10/2025 31/10/2025 Nội bộ FCJ 7 - Nhận feedback từ mentor: cập nhật subnet, luồng xử lý API, lớp bảo mật - Chỉnh sửa lại sơ đồ theo góp ý 01/11/2025 01/11/2025 Trao đổi trực tiếp CN - Tổng hợp bài học rút ra trong khi xây dựng kiến trúc - Hoàn thiện Worklog tuần 02/11/2025 02/11/2025 Kết quả đạt được tuần 8: Hoàn thành sơ đồ AWS Network Architecture Diagram đầy đủ thành phần:\nRoute 53, CloudFront, S3 bucket frontend. API Gateway → EC2 backend. NAT Gateway + Internet Gateway. RDS trong private subnet. CI/CD: CodePipeline, CodeBuild, CloudFormation. Monitoring \u0026amp; Security: CloudWatch, CloudTrail, IAM, Secrets Manager, SNS. Hiểu rõ cách các thành phần kết nối trong mô hình:\nLuồng request của user đến FE/BE. Cách tách biệt public/private subnet. Cơ chế NAT để EC2 truy cập internet an toàn. Luồng API Gateway → EC2 → RDS. Nắm được cách chuẩn hoá sơ đồ kỹ thuật theo chuẩn AWS:\nSử dụng đúng icon, nhóm dịch vụ, phân layer rõ ràng. Đánh dấu số thứ tự các bước xử lý. Hoàn thiện bản diagram để đưa vào báo cáo và gửi cho mentor đánh giá.\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/1-worklog/1.7-week7/",
	"title": "Worklog Tuần 7",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 7: Triển khai và quản lý dữ liệu trên S3, DynamoDB, Redshift. Tạo pipeline dữ liệu với Kinesis, Glue, DataBrew, EMR. Phân tích dữ liệu bằng Athena, Kinesis Data Analytics và trực quan hóa bằng QuickSight. Xây dựng ứng dụng serverless và dashboard tương tác. Làm quen với CloudShell, AWS SDK và Cloud9 cho thao tác lập trình và xử lý dữ liệu. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tạo S3 Bucket, Delivery Stream, dữ liệu mẫu, Glue Crawler, kiểm tra dữ liệu, session setup, phân tích với Athena, trực quan hóa QuickSight, dọn dẹp tài nguyên (Module 07-Lab35-3.1 đến 7) 20/10/2025 20/10/2025 https://000035.awsstudygroup.com/ 3 - Làm quen DynamoDB, khám phá console, backup dữ liệu, dọn dẹp, áp dụng Advanced Design Patterns, triển khai global serverless app, event-driven architecture (Module 07-Lab39-1 đến 8) 21/10/2025 21/10/2025 https://000039.awsstudygroup.com/ 4 - Chuẩn bị, xây dựng cơ sở dữ liệu, quản lý dữ liệu trong bảng, chi phí, tagging, sử dụng và truy vấn dữ liệu, dọn dẹp tài nguyên (Module 07-Lab40-2.1 đến 4) 22/10/2025 22/10/2025 https://000040.awsstudygroup.com/ 5 - Làm quen với CloudShell, console, SDK; tạo Cloud9 instance, tải và upload dataset lên S3; setup DataBrew, data profiling, clean \u0026amp; transform data (Module 07-Lab60 \u0026amp; 07-Lab70) 23/10/2025 23/10/2025 https://000060.awsstudygroup.com/ 6 - Chuẩn bị pipeline, ingest \u0026amp; store dữ liệu, catalog data, transform data với Glue (interactive \u0026amp; GUI), DataBrew, EMR; phân tích dữ liệu với Athena \u0026amp; Kinesis Data Analytics; visualize với QuickSight; serve với Lambda; warehouse trên Redshift (Module 07-Lab72-2 đến 13) 24/10/2025 24/10/2025 https://000070.awsstudygroup.com/ 7 - Xây dựng dashboard, cải thiện dashboard, tạo interactive dashboard (Module 07-Lab73-3 đến 5) 25/10/2025 25/10/2025 https://000072.awsstudygroup.com/ CN - Tổng hợp, kiểm tra kết quả, dọn dẹp tài nguyên, tự đánh giá tuần và chuẩn bị nội dung tuần tiếp theo 26/10/2025 26/10/2025 https://000073.awsstudygroup.com/ Kết quả đạt được tuần 7: Quản lý và xử lý dữ liệu:\nTriển khai dữ liệu trên S3, DynamoDB, Redshift. Tạo pipeline dữ liệu với Kinesis, Glue, DataBrew và EMR. Phân tích \u0026amp; trực quan hóa:\nPhân tích dữ liệu bằng Athena và Kinesis Data Analytics. Trực quan hóa dữ liệu và xây dựng dashboard tương tác với QuickSight. Ứng dụng serverless:\nTriển khai ứng dụng serverless trên DynamoDB và Lambda. Xây dựng event-driven architecture cho global serverless app. Công cụ lập trình \u0026amp; thao tác dữ liệu:\nSử dụng CloudShell, AWS SDK và Cloud9 để thao tác và xử lý dữ liệu. Quản lý tài nguyên:\nDọn dẹp toàn bộ tài nguyên đã triển khai để tránh chi phí phát sinh. Tự đánh giá:\nNắm vững quản lý dữ liệu, pipeline, phân tích \u0026amp; trực quan hóa, serverless application. Chuẩn bị tốt cho tuần tiếp theo với các nội dung nâng cao về bảo mật, tagging và quản lý chi phí. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/1-worklog/1.6-week6/",
	"title": "Worklog Tuần 6",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 6: Thực hành triển khai VPC, EC2, RDS và các cấu hình bảo mật. Triển khai ứng dụng và thực hiện backup/restore. Quản lý kết nối EC2 qua RDP và Fleet Manager. Thực hiện cấu hình SQL Server và Oracle database. Thực hiện chuyển đổi schema từ MSSQL/Oracle sang Aurora MySQL. Thực hành Serverless Migration, kiểm tra logs và troubleshoot các kịch bản test. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tạo VPC (Module 06-Lab05-2.1) - Tạo EC2 Security Group (Module 06-Lab05-2.2) - Tạo RDS Security Group (Module 06-Lab05-2.3) - Tạo DB Subnet Group (Module 06-Lab05-2.4) - Triển khai EC2 instance (Module 06-Lab05-3) - Triển khai RDS database instance (Module 06-Lab05-4) - Deploy ứng dụng (Module 06-Lab05-5) - Backup \u0026amp; Restore (Module 06-Lab05-6) - Dọn dẹp tài nguyên (Module 06-Lab05-7) 13/10/2025 13/10/2025 https://000006.awsstudygroup.com/ 3 - Kết nối EC2 bằng RDP Client (Module 06-Lab43-01) - Kết nối EC2 bằng Fleet Manager (Module 06-Lab43-02) - Cấu hình SQL Server Source DB (Module 06-Lab43-03) 14/10/2025 14/10/2025 https://000043.awsstudygroup.com/ 4 - Kết nối và cấu hình Oracle Source DB (Module 06-Lab43-04 \u0026amp; 05) - Drop Constraint (Module 06-Lab43-06) - MSSQL → Aurora MySQL target config (Module 06-Lab43-07) - Tạo project migration (Module 06-Lab43-08) 15/10/2025 15/10/2025 https://000043.awsstudygroup.com/ 5 - Chuyển đổi schema MSSQL/Oracle sang Aurora MySQL (Module 06-Lab43-09 \u0026amp; 10) - Tạo Migration Task và Endpoints (Module 06-Lab43-11) - Kiểm tra dữ liệu trên S3 (Module 06-Lab43-12) 16/10/2025 16/10/2025 https://000043.awsstudygroup.com/ 6 - Tạo Serverless Migration (Module 06-Lab43-13) - Tạo Event Notification (Module 06-Lab43-14) - Kiểm tra logs (Module 06-Lab43-15) - Troubleshoot Mem Pressure \u0026amp; Table Errors (Module 06-Lab43-16 \u0026amp; 17) 17/10/2025 17/10/2025 https://000043.awsstudygroup.com/ 7 - Tổng hợp kết quả, kiểm tra và dọn dẹp toàn bộ tài nguyên thực hành 18/10/2025 18/10/2025 N/A CN - Tự đánh giá tuần, chuẩn bị kiến thức cho tuần tiếp theo 19/10/2025 19/10/2025 N/A Kết quả đạt được tuần 6: Triển khai mạng \u0026amp; cơ sở dữ liệu:\nTạo và cấu hình VPC, EC2 Security Group, RDS Security Group, DB Subnet Group. Triển khai EC2 \u0026amp; RDS instance thành công, deploy ứng dụng và thực hiện backup/restore. Quản lý kết nối EC2:\nKết nối EC2 bằng RDP Client và Fleet Manager, quản lý Source DB SQL Server \u0026amp; Oracle. Chuyển đổi dữ liệu \u0026amp; Migration:\nThực hiện schema conversion từ MSSQL/Oracle sang Aurora MySQL. Tạo Migration Task, Endpoints, kiểm tra dữ liệu trên S3. Serverless Migration \u0026amp; Troubleshooting:\nTạo Serverless Migration, cấu hình Event Notification, kiểm tra logs. Xử lý các kịch bản test Mem Pressure và Table Errors thành công. Quản lý tài nguyên:\nDọn dẹp toàn bộ tài nguyên đã triển khai để tránh phát sinh chi phí ngoài ý muốn. Tự đánh giá:\nNắm vững triển khai VPC, EC2, RDS, backup/restore, kết nối database và Serverless Migration. Hiểu quy trình chuyển đổi dữ liệu và kiểm soát logs. Chuẩn bị tốt cho tuần tiếp theo với các nội dung nâng cao về bảo mật và tối ưu hạ tầng. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/1-worklog/1.5-week5/",
	"title": "Worklog Tuần 5",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 5: Thực hành AWS Security Hub và đánh giá bảo mật. Quản lý VPC, EC2 và Lambda với Web-hooks và Tagging. Quản lý IAM Users, Policies, Roles và Switch Roles nâng cao. Thực hành kiểm soát quyền hạn người dùng IAM và giới hạn truy cập. Quản lý CloudTrail, Athena và dữ liệu S3 được mã hóa. Triển khai và quản lý EC2, S3 và IAM Role/Key. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Bật AWS Security Hub (Module 05-Lab18-02) - Đánh giá score theo tiêu chí (Module 05-Lab18-03) - Dọn dẹp tài nguyên Security Hub (Module 05-Lab18-04) 06/10/2025 06/10/2025 https://000018.awsstudygroup.com/ 3 - Tạo VPC, Security Group, EC2 (Module 05-Lab22-2.1 đến 2.3) - Cấu hình Incoming Web-hooks Slack (Module 05-Lab22-2.4) - Tạo Tag Instance (Module 05-Lab22-3) - Tạo Role cho Lambda (Module 05-Lab22-4) - Stop/Start function, kiểm tra kết quả (Module 05-Lab22-5.1 đến 6) - Dọn dẹp tài nguyên (Module 05-Lab22-7) 07/10/2025 07/10/2025 https://000022.awsstudygroup.com/ 4 - Quản lý Tag trên EC2 và AWS Resources (Module 05-Lab27-2.1.1 đến 2.2) - Tạo Resource Group (Module 05-Lab27-3) - Dọn dẹp tài nguyên (Module 05-Lab27-4) 08/10/2025 08/10/2025 https://000027.awsstudygroup.com/ 5 - Tạo IAM Users, Policies, Roles (Module 05-Lab28-2.1 đến 4) - Switch Roles \u0026amp; kiểm tra truy cập EC2 ở nhiều Region (Module 05-Lab28-5.1 đến 5.2.5) - Dọn dẹp tài nguyên (Module 05-Lab28-6) 09/10/2025 09/10/2025 https://000028.awsstudygroup.com/ 6 - Tạo IAM Limited User \u0026amp; Restriction Policy, test hạn chế quyền (Module 05-Lab30-3 đến 5) - Dọn dẹp tài nguyên (Module 05-Lab30-6) 10/10/2025 10/10/2025 https://000030.awsstudygroup.com/ 7 - Tạo Policy, Role, Group, User, KMS, Bucket S3, upload dữ liệu, CloudTrail, Athena, test mã hóa dữ liệu (Module 05-Lab33-2.1 đến 6) - Dọn dẹp tài nguyên (Module 05-Lab33-7) 11/10/2025 11/10/2025 https://000033.awsstudygroup.com/ CN - Quản lý IAM Group, User, Admin Role, Switch Role, hạn chế theo IP \u0026amp; thời gian (Module 05-Lab44) - Tạo EC2, S3, IAM Role, Access Key và dọn dẹp tài nguyên (Module 05-Lab48) 12/10/2025 12/10/2025 https://000044.awsstudygroup.com/ https://000048.awsstudygroup.com/ Kết quả đạt được tuần 5: AWS Security Hub:\nBật Security Hub, đánh giá score theo tiêu chí, dọn dẹp tài nguyên. VPC, EC2 \u0026amp; Lambda:\nTạo VPC, Security Group, EC2, Lambda functions với stop/start, Incoming Web-hooks Slack. Sử dụng Tags để quản lý resource, tạo Resource Group, kiểm tra kết quả. IAM Management:\nTạo Users, Policies, Roles, Switch Roles nâng cao. Triển khai IAM Limited User với hạn chế quyền và giới hạn truy cập theo IP/Time. Quản lý nhiều Region với EC2 console, kiểm tra Tag \u0026amp; Policy. CloudTrail, Athena \u0026amp; S3:\nTạo Bucket, upload dữ liệu, bật CloudTrail, truy xuất dữ liệu bằng Athena, test mã hóa dữ liệu. Quản lý tài nguyên:\nDọn dẹp toàn bộ tài nguyên đã triển khai sau khi thực hành để tránh phát sinh chi phí. Tự đánh giá:\nNắm vững thực hành Security Hub, VPC, EC2, Lambda, Tag, IAM, CloudTrail \u0026amp; Athena. Hiểu và triển khai các hạn chế truy cập nâng cao cho IAM Users. Sẵn sàng cho tuần tiếp theo với các nội dung tối ưu bảo mật và chi phí. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/1-worklog/1.4-week4/",
	"title": "Worklog Tuần 4",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 4: Thực hành AWS Backup nâng cao và thiết lập thông báo. Triển khai và quản lý máy ảo từ On-Premises lên AWS bằng AMI. Thực hành S3, Storage Gateway và File Shares nâng cao. Triển khai Multi-AZ file system với SSD và HDD, giám sát hiệu suất và quản lý người dùng. Quản lý website tĩnh S3, CloudFront, versioning, replication và dọn dẹp tài nguyên. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tạo S3 Bucket (Module 04-Lab13-02.1) - Triển khai hạ tầng Backup (Module 04-Lab13-02.2) - Tạo Backup Plan (Module 04-Lab13-03) - Thiết lập thông báo (Module 04-Lab13-04) 29/09/2025 29/09/2025 https://000013.awsstudygroup.com/, https://000014.awsstudygroup.com/ 3 - Thử nghiệm khôi phục dữ liệu (Module 04-Lab13-05) - Dọn dẹp tài nguyên Backup (Module 04-Lab13-06) 30/09/2025 30/09/2025 https://000013.awsstudygroup.com/, https://000014.awsstudygroup.com/ 4 - Làm việc với VMWare Workstation (Module 04-Lab14-01) - Export VM từ On-Premises (Module 04-Lab14-02.1) - Upload VM lên AWS (Module 04-Lab14-02.2) - Import VM vào AWS (Module 04-Lab14-02.3) - Triển khai Instance từ AMI (Module 04-Lab14-02.4) 01/10/2025 01/10/2025 https://000024.awsstudygroup.com/, https://000025.awsstudygroup.com/ 5 - Quản lý S3 Bucket ACL (Module 04-Lab14-03.1) - Export VM từ Instance (Module 04-Lab14-03.2) - Dọn dẹp tài nguyên VM \u0026amp; AWS (Module 04-Lab14-05) 02/10/2025 02/10/2025 https://000024.awsstudygroup.com/, https://000025.awsstudygroup.com/ 6 - Tạo Storage Gateway (Module 04-Lab24-2.1) - Tạo File Shares (Module 04-Lab24-2.2) - Mount File Shares trên máy On-Premises (Module 04-Lab24-2.3) - Dọn dẹp tài nguyên (Module 04-Lab24-3) 03/10/2025 03/10/2025 https://000024.awsstudygroup.com/ 7 - Tạo SSD \u0026amp; HDD Multi-AZ File System (Module 04-Lab25-2.2 \u0026amp; 2.3) - Tạo file shares, test \u0026amp; monitor performance (Module 04-Lab25-3, 4, 5) - Enable deduplication, shadow copies, quản lý user \u0026amp; quotas, scale throughput \u0026amp; storage (Module 04-Lab25-6 đến 12) 04/10/2025 04/10/2025 https://000024.awsstudygroup.com/ CN - Dọn dẹp môi trường Multi-AZ (Module 04-Lab25-13) - Tạo S3 Bucket, load dữ liệu, website tĩnh, CloudFront, versioning \u0026amp; replication, test \u0026amp; cleanup (Module 04-Lab57-2.1 đến 11) 05/10/2025 05/10/2025 https://000057.awsstudygroup.com/ Kết quả đạt được tuần 4: AWS Backup nâng cao:\nTriển khai Backup Plan, thiết lập thông báo, test restore dữ liệu thành công. Dọn dẹp tài nguyên backup. Máy ảo \u0026amp; AMI:\nExport VM từ On-Premises, upload \u0026amp; import vào AWS. Triển khai Instance từ AMI và quản lý S3 Bucket ACL. Dọn dẹp VM \u0026amp; tài nguyên sau thử nghiệm. Storage Gateway \u0026amp; Multi-AZ File System:\nTạo Storage Gateway, File Shares, mount trên máy On-Premises. Triển khai SSD \u0026amp; HDD Multi-AZ File System, tạo file shares, test \u0026amp; monitor performance. Quản lý user, enable deduplication, shadow copies, quotas, scale throughput \u0026amp; storage. S3 \u0026amp; CloudFront:\nTạo S3 Bucket, load dữ liệu, triển khai website tĩnh, cấu hình CloudFront. Sử dụng versioning, replication multi-region, test \u0026amp; dọn dẹp tài nguyên. Tự đánh giá:\nNắm vững triển khai Backup nâng cao, Storage Gateway, Multi-AZ File System, quản lý VM \u0026amp; website tĩnh. Thực hành dọn dẹp tài nguyên đúng cách, tránh phát sinh chi phí. Sẵn sàng cho tuần tiếp theo với các bài học về bảo mật, IAM \u0026amp; tối ưu chi phí. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/1-worklog/1.3-week3/",
	"title": "Worklog Tuần 3",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 3: Thực hành triển khai AWS Backup và đảm bảo phục hồi dữ liệu. Triển khai S3, Storage Gateway, quản lý dữ liệu và file shares. Thiết lập và quản lý website tĩnh trên S3 cùng với CloudFront. Tìm hiểu các tính năng nâng cao của S3: versioning, replication, quản lý quyền truy cập. Dọn dẹp tài nguyên sau khi thử nghiệm để tránh phát sinh chi phí. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Deploy AWS Backup to the system - Introduction (Module 03-Lab13-01) - Triển khai hạ tầng Backup (Module 03-Lab13-02.2) - Tạo Backup Plan (Module 03-Lab13-03) 22/09/2025 22/09/2025 https://000013.awsstudygroup.com/ 3 - Thử nghiệm khôi phục dữ liệu (Module 03-Lab13-05) - Dọn dẹp tài nguyên Backup (Module 03-Lab13-06) 23/09/2025 23/09/2025 https://000013.awsstudygroup.com/ 4 - Tạo S3 Bucket \u0026amp; EC2 cho Storage Gateway (Module 03-Lab24-01.1 \u0026amp; 01.2) - Tạo Storage Gateway và File Shares (Module 03-Lab24-02.1 \u0026amp; 02.2) 24/09/2025 24/09/2025 https://000024.awsstudygroup.com/ 5 - Tạo S3 Bucket, load dữ liệu, enable static website (Module 03-Lab57-02.1, 02.2 \u0026amp; 03) - Cấu hình quyền truy cập công khai và test website (Module 03-Lab57-04, 05, 06) 25/09/2025 25/09/2025 https://000057.awsstudygroup.com/ 6 - Block all public access, cấu hình CloudFront \u0026amp; test (Module 03-Lab57-07.1 đến 07.3) - Sử dụng bucket versioning, di chuyển đối tượng, replication multi-region (Module 03-Lab57-08, 09, 10) 26/09/2025 26/09/2025 https://000057.awsstudygroup.com/ 7 - Dọn dẹp tài nguyên S3 \u0026amp; CloudFront (Module 03-Lab57-11) 27/09/2025 27/09/2025 https://000057.awsstudygroup.com/ CN - Tổng kết tuần 3, đánh giá kết quả, ghi nhận kinh nghiệm triển khai Backup, Storage Gateway và S3/CloudFront 28/09/2025 28/09/2025 N/A Kết quả đạt được tuần 3: AWS Backup:\nTriển khai Backup Plan và thử nghiệm khôi phục dữ liệu thành công. Dọn dẹp tài nguyên backup sau khi kiểm tra. Storage Gateway \u0026amp; S3:\nTạo S3 Bucket và EC2 cho Storage Gateway. Thiết lập Storage Gateway và file shares, load dữ liệu thành công. Website tĩnh \u0026amp; CloudFront:\nTriển khai website tĩnh trên S3, cấu hình public access, và kiểm tra hiển thị. Cấu hình CloudFront để phân phối nội dung, kiểm tra hoạt động. Sử dụng versioning, di chuyển đối tượng và replication multi-region. Tự đánh giá:\nNắm vững các bước triển khai AWS Backup, Storage Gateway, S3 và CloudFront. Thực hành test restore, versioning, replication và dọn dẹp tài nguyên. Sẵn sàng cho tuần tiếp theo với các bài tập AWS nâng cao về bảo mật và tối ưu chi phí. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/1-worklog/1.2-week2/",
	"title": "Worklog Tuần 2",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 2: Học và thực hành thiết lập mạng AWS bằng VPC, Subnet, Route Table, Internet Gateway, NAT Gateway và các cơ chế bảo mật. Cấu hình EC2 instances trong các subnet và kiểm tra kết nối. Thiết lập Hybrid DNS với Route 53 Resolver. Tìm hiểu và triển khai VPC Peering và AWS Transit Gateway. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Giới thiệu Amazon VPC và AWS VPN Site-to-Site (Module 02-Lab03-01) - Subnets (Module 02-Lab03-01.1) - Route Table (Module 02-Lab03-01.2) - Internet Gateway (IGW) (Module 02-Lab03-01.3) - NAT Gateway (Module 02-Lab03-01.4) 15/09/2025 15/09/2025 https://000003.awsstudygroup.com/ 3 - Cấu hình Security Group (Module 02-Lab03-02.1) - Network ACLs (Module 02-Lab03-02.2) - VPC Resource Map (Module 02-Lab03-02.3) 16/09/2025 16/09/2025 https://000003.awsstudygroup.com/ 4 - Tạo VPC (Module 02-Lab03-03.1) - Tạo Subnet (Module 02-Lab03-03.2) - Tạo Internet Gateway (Module 02-Lab03-03.3) - Tạo Route Table cho Outbound Internet Routing qua IGW (Module 02-Lab03-03.4) - Tạo Security Groups (Module 02-Lab03-03.5) 17/09/2025 17/09/2025 https://000010.awsstudygroup.com/ 5 - Tạo EC2 Instances trong Subnets (Module 02-Lab03-04.1) - Kiểm tra kết nối (Module 02-Lab03-04.2) - Tạo NAT Gateway (Module 02-Lab03-04.3) - EC2 Instance Connect Endpoint (Module 02-Lab03-04.5) 18/09/2025 18/09/2025 https://000010.awsstudygroup.com/ 6 - Thiết lập Hybrid DNS với Route 53 Resolver (Module 02-Lab10-01) - Tạo Key Pair (Module 02-Lab10-02.1) - Khởi tạo CloudFormation Template (Module 02-Lab10-02.2) - Cấu hình Security Group (Module 02-Lab10-02.3) - Kết nối đến RDGW (Module 02-Lab10-03) 19/09/2025 19/09/2025 https://000019.awsstudygroup.com/ 7 - Thiết lập DNS: Route 53 Outbound Endpoint (Module 02-Lab10-05.1) - Tạo Resolver Rules (Module 02-Lab10-05.2) - Tạo Inbound Endpoints (Module 02-Lab10-05.3) - Kiểm tra kết quả (Module 02-Lab10-05.4) - Dọn dẹp tài nguyên (Module 02-Lab10-06) 20/09/2025 20/09/2025 https://000019.awsstudygroup.com/ CN - VPC Peering setup: Giới thiệu (Module 02-Lab19-01) - Khởi tạo CloudFormation Templates (Module 02-Lab19-02.1) - Tạo Security Group (Module 02-Lab19-02.2) - Tạo EC2 instance (Module 02-Lab19-02.3) - Cập nhật Network ACLs (Module 02-Lab19-03) - Tạo peering connection (Module 02-Lab19-04) - Cấu hình Route Tables (Module 02-Lab19-05) - Bật Cross-Peer DNS (Module 02-Lab19-06) - Dọn dẹp tài nguyên (Module 02-Lab19-07) - AWS Transit Gateway setup: Giới thiệu (Module 02-Lab20-01) - Các bước chuẩn bị (Module 02-Lab20-02) - Tạo Transit Gateway (Module 02-Lab20-03) - Tạo TGW Attachments (Module 02-Lab20-04) - Tạo TGW Route Tables (Module 02-Lab20-05) - Thêm TGW Routes vào VPC Route Tables (Module 02-Lab20-06) - Dọn dẹp tài nguyên (Module 02-Lab20-07) 21/09/2025 21/09/2025 https://000020.awsstudygroup.com/ Kết quả đạt được tuần 2: Mạng AWS:\nTạo và cấu hình VPC, Subnet, Route Table, Internet Gateway, NAT Gateway, Security Groups. Triển khai EC2 instances trong các subnet và kiểm tra kết nối thành công. Cấu hình EC2 Instance Connect Endpoint để truy cập dễ dàng hơn. Hybrid DNS:\nTạo Key Pairs và khởi tạo CloudFormation Templates. Cấu hình Security Groups và kết nối đến RDGW. Tạo Route 53 Outbound/Inbound Endpoints, thiết lập Resolver Rules và kiểm tra kết quả. Dọn dẹp tài nguyên DNS sau khi kiểm tra. VPC Peering \u0026amp; Transit Gateway:\nThiết lập VPC Peering, cấu hình Route Tables và bật Cross-Peer DNS. Tạo AWS Transit Gateway, attachments, route tables, thêm routes vào VPC route tables. Dọn dẹp các tài nguyên để tránh phát sinh chi phí không mong muốn. Tự đánh giá:\nCó kinh nghiệm thực hành với mạng AWS, Hybrid DNS, VPC Peering và Transit Gateway. Triển khai, kiểm tra và dọn dẹp tài nguyên thành công. Sẵn sàng cho các tuần tiếp theo với kiến thức nâng cao hơn. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/3-blogstranslated/3.4-blog4/",
	"title": "Blog 4",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/3-blogstranslated/3.5-blog5/",
	"title": "Blog 5",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/3-blogstranslated/3.6-blog6/",
	"title": "Blog 6",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/1-worklog/",
	"title": "Nhật ký công việc",
	"tags": [],
	"description": "",
	"content": "Tổng quan: Phần này giới thiệu worklog, tóm tắt các tuần hoàn thành, các công việc đã thực hiện và kết quả đạt được.\nTôi đã hoàn thành chương trình thực tập trong vòng 12 tuần, tập trung vào việc học và thực hành các dịch vụ AWS cơ bản, quản lý dữ liệu, bảo mật, ứng dụng serverless, phân tích và trực quan hóa dữ liệu. Dưới đây là tóm tắt công việc từng tuần:\nTuần 1: Làm quen với AWS, tạo tài khoản Free Tier, thiết lập bảo mật, quản lý IAM và tạo Budget cơ bản\nTuần 2: Thiết lập VPC, subnet, Internet Gateway, NAT Gateway, Security Group, EC2 instance, VPN site-to-site, Route53 hybrid DNS, VPC peering và Transit Gateway\nTuần 3: Triển khai AWS Backup, tạo kế hoạch backup, thử nghiệm restore; S3 Bucket, Storage Gateway, triển khai website tĩnh với S3 \u0026amp; CloudFront, versioning, replication\nTuần 4: Tạo S3 bucket, triển khai hạ tầng, backup plan \u0026amp; notifications, test restore; Virtual Machine import/export, Storage Gateway, file system Multi-AZ, test hiệu năng, website S3 nâng cao\nTuần 5: Bảo mật với Security Hub, quản lý VPC, EC2 \u0026amp; Lambda với Tagging; IAM Users, Policies, Roles, KMS; CloudTrail \u0026amp; Athena; kiểm soát quyền hạn; dọn dẹp tài nguyên\nTuần 6: Tạo VPC, EC2 \u0026amp; RDS Security Group, triển khai RDS database, deploy ứng dụng, backup/restore; kết nối EC2 qua RDP \u0026amp; Fleet Manager; cấu hình SQL Server \u0026amp; Oracle; tạo Migration Task; troubleshoot\nTuần 7: Quản lý dữ liệu trên S3, DynamoDB, Redshift; pipeline dữ liệu với Kinesis, Glue, DataBrew, EMR; phân tích dữ liệu bằng Athena \u0026amp; Kinesis Data Analytics; trực quan hóa với QuickSight; ứng dụng serverless và dashboard tương tác; sử dụng CloudShell, SDK, Cloud9\nTuần 8: Xây dựng kiến trúc AWS cho dự án; thu thập yêu cầu, dựng Network Architecture Diagram, thiết kế VPC, subnet, routing, EC2, RDS, API Gateway, CloudFront, CI/CD và hoàn thiện sơ đồ theo feedback mentor\nTuần 9: Xây dựng bản nháp Proposal BDSS; viết Executive Summary, Problem Statement, Solution Overview; phân tích kiến trúc BDSS; tổng hợp nội dung từ proposal nhóm và chuẩn hóa theo template\nTuần 10: Xây dựng workshop dựa trên Proposal \u0026amp; Proposal Template; viết Introduction, Background, Objectives; xây dựng Architecture, Data Flow, CI/CD, Security; tổng hợp Cost \u0026amp; Risk để hoàn thiện Workshop Draft\nTuần 11: Tổng hợp nội dung từ 2 proposal; chuẩn hóa Executive Summary, Problem, Solution Architecture; xây dựng outline slide; chuẩn hóa toàn bộ nội dung sang tiếng Anh để chuẩn bị báo cáo cuối kỳ\nTuần 12: Trình bày dự án trước mentor; ghi nhận phản hồi về kiến trúc, CI/CD, cost, security; chỉnh sửa slide và tài liệu; tổng hợp action items để chuẩn bị cho báo cáo cuối kỳ\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/1-worklog/1.1-week1/",
	"title": "Worklog Tuần 1",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 1: Khởi tạo và quản lý tài khoản AWS cơ bản. Làm quen với các cơ chế bảo mật, quản lý người dùng, ngân sách và hỗ trợ trên AWS. Thực hành thao tác trên AWS Console và AWS CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tạo AWS Free Tier account (Module 01-Lab01-01) - Thiết lập Virtual MFA (Module 01-Lab01-02) 08/09/2025 08/09/2025 https://000001.awsstudygroup.com/ 3 - Tạo nhóm quản trị (Admin Group) và user Admin (Module 01-Lab01-03) - Cấu hình Account Authentication Support (Module 01-Lab01-04) 09/09/2025 09/09/2025 https://000007.awsstudygroup.com/ 4 - Tạo Budget bằng template (Module 01-Lab07-01) - Tạo Cost Budget (Module 01-Lab07-02) 10/09/2025 10/09/2025 https://000009.awsstudygroup.com/ 5 - Tạo Usage Budget (Module 01-Lab07-03) - Tạo Reservation Instance (RI) Budget (Module 01-Lab07-04) 11/09/2025 11/09/2025 https://000009.awsstudygroup.com/ 6 - Tạo Savings Plans Budget (Module 01-Lab07-05) - Clean Up Budgets (Module 01-Lab07-06) 12/09/2025 12/09/2025 https://000009.awsstudygroup.com/ 7 - Tìm hiểu gói hỗ trợ AWS (Module 01-Lab09-01) - Các loại yêu cầu hỗ trợ (Module 01-Lab09-02) - Thay đổi gói hỗ trợ (Module 01-Lab09-03) - Quản lý yêu cầu hỗ trợ (Module 01-Lab09-04) 13/09/2025 13/09/2025 https://000007.awsstudygroup.com/ CN - Ôn tập, tổng hợp và hoàn thiện các thiết lập, clean up các tài nguyên thử nghiệm 14/09/2025 14/09/2025 - Kết quả đạt được tuần 1: Khởi động tài khoản AWS:\nTạo thành công AWS Free Tier account. Thiết lập MFA cho root account để bảo mật. Tạo Admin Group và Admin User để quản lý thay vì dùng root. Hoàn tất cấu hình Account Authentication Support. Quản lý ngân sách:\nTạo Budget bằng template, Cost Budget, Usage Budget, RI Budget, Savings Plans Budget. Thực hành Clean Up các Budget đã tạo để tránh chi phí phát sinh. Hỗ trợ và xử lý sự cố:\nHiểu và biết cách sử dụng các gói hỗ trợ AWS. Thực hành tạo, quản lý và thay đổi các yêu cầu hỗ trợ trên AWS Console. Tự đánh giá:\nNắm được quy trình khởi tạo tài khoản, bảo mật, quản lý người dùng và nhóm. Thực hành quản lý ngân sách AWS cơ bản và các gói hỗ trợ. Sẵn sàng tiếp tục sang các tuần sau với nội dung chuyên sâu hơn về dịch vụ AWS. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/3-blogstranslated/3.1-blog1/",
	"title": "Blog 1",
	"tags": [],
	"description": "",
	"content": "Tăng tốc Chiến lược Đám mây của bạn với Kết nối Trực tiếp AWS được Lưu trữ 25 Gbps của Megaport Khi các doanh nghiệp di chuyển khối lượng công việc quan trọng lên đám mây, hiệu suất mạng đã trở thành yêu cầu kinh doanh cơ bản. Dịch vụ web của Amazon (AWS) Direct Connect cung cấp kết nối mạng chuyên dụng giữa các trung tâm dữ liệu tại chỗ và AWS. Điều này bỏ qua internet công cộng để mang lại hiệu suất mạng ổn định và đáng tin cậy hơn với độ trễ thấp hơn. Sự giới thiệu của 25 Gbps hosted connections lấp đầy khoảng cách giữa các tùy chọn 10 Gbps (thường không đủ) và 100 Gbps (thường là quá mức), cho phép các tổ chức điều chỉnh kích thước kết nối phù hợp mà không ảnh hưởng đến hiệu suất. Megaport, một nhà cung cấp Mạng lưới dưới dạng Dịch vụ (NaaS) hàng đầu và AWS Marketplace Đối tác của chúng tôi là một trong những đơn vị đầu tiên cung cấp kết nối 25 Gbps này trên nhiều Địa điểm Kết nối Trực tiếp Edge thông qua Mạng lưới Định nghĩa Phần mềm Toàn cầu, trải dài hàng trăm trung tâm dữ liệu trên toàn thế giới. Để biết thông tin mới nhất, vui lòng tham khảo Magaport public network footprint page.\nSử dụng nền tảng tự phục vụ của Megaport, các tổ chức có thể cung cấp, mở rộng quy mô và quản lý kết nối AWS hiệu suất cao chỉ trong vài phút thay vì hàng tuần hoặc hàng tháng. Trong bài viết này, chúng tôi sẽ mô tả cách sự kết hợp mạnh mẽ giữa các dịch vụ AWS và Megaport cho phép các kiến ​​trúc sư đám mây và lãnh đạo CNTT xây dựng các mạng lai thế hệ tiếp theo hỗ trợ các ứng dụng dữ liệu chuyên sâu, tăng cường bảo mật và tối ưu hóa chi phí — đồng thời vẫn duy trì tính linh hoạt để thích ứng với nhu cầu kinh doanh thay đổi.\nĐiều kiện tiên quyết Chúng tôi giả định rằng bạn đã quen thuộc với các cấu trúc mạng cốt lõi trên AWS, đặc biệt là Direct Connect. Mặc dù chúng tôi không đi sâu vào định nghĩa, nhưng chúng tôi sẽ nêu bật vai trò của nó trong việc hỗ trợ các kiến ​​trúc kết nối lai liên quan đến các kết nối được lưu trữ trên Direct Connect. Nếu bạn chưa quen với những khái niệm này, chúng tôi khuyên bạn nên xem lại tài liệu Direct Connect để biết thêm chi tiết choosing between Direct Connect dedicated and hosted connections.\nĐối với kiến ​​thức nền tảng, Getting Started with AWS Direct Connect hướng dẫn cũng là một nguồn tài nguyên hữu ích.\nCác trường hợp sử dụng chính cho Kết nối trực tiếp 25 Gbps Các phần sau đây sẽ trình bày chi tiết các trường hợp sử dụng chính của Direct Connect 25 Gbps.\n1. Di chuyển đám mây Di chuyển dữ liệu doanh nghiệp quy mô lớn liên quan đến việc chuyển các tập dữ liệu khổng lồ. Kết nối lưu trữ 25 Gbps cho phép các tổ chức rút ngắn thời gian di chuyển từ vài ngày xuống còn vài giờ mà vẫn duy trì hiệu suất ổn định và an toàn. Việc di chuyển cơ sở dữ liệu 100 TB, vốn mất hơn 22 giờ với kết nối 10 Gbps, có thể hoàn thành trong khoảng 9 giờ, giúp rút ngắn đáng kể thời gian đưa vào sản xuất.\nConnection Speed Data volume Estimated Migration Time Performance Gain 10 Gbps 100 TB ~22 hours Baseline 25 Gbps 100 TB ~9 hours ~59% faster Table 1: Bandwidth effects on large-scale data migration\n2. Di chuyển dữ liệu Các tổ chức thu thập dữ liệu từ các vị trí biên hoặc môi trường tại chỗ được hưởng lợi từ các kết nối có thông lượng cao, có thể dự đoán trước cho các khối lượng công việc phân tích, sao lưu và lưu trữ. Các công ty truyền thông có thể chuyển các tệp video lớn một cách hiệu quả giữa các bộ biên tập và AWS, trong khi các tổ chức chăm sóc sức khỏe có thể di chuyển các tập dữ liệu hình ảnh lên đám mây để phân tích AI mà vẫn duy trì tính tuân thủ thông qua kết nối riêng tư. Cấp độ 25 Gbps đặc biệt hữu ích cho các triển khai Internet vạn vật (IoT) tạo ra khối lượng lớn dữ liệu cảm biến, các hoạt động sao lưu quy mô lớn với các yêu cầu Mục tiêu Điểm Phục hồi (RPO) khắt khe, và các tổ chức đào tạo mô hình học máy (ML) với các tập dữ liệu tại chỗ đáng kể.\n3. Hỗ trợ đám mây lai Khi kiến ​​trúc lai ngày càng phổ biến, việc kết nối đáng tin cậy giữa các hệ thống tại chỗ và AWS là điều cần thiết. Kết nối lưu trữ 25 Gbps của Megaport cung cấp dung lượng cần thiết cho cơ sở dữ liệu phân tán, giải pháp lưu trữ lai và các dịch vụ vi mô trải rộng trên nhiều môi trường. Các tổ chức có thể triển khai các chính sách bảo mật nhất quán và trải nghiệm ứng dụng liền mạch trên toàn bộ ngăn xếp công nghệ của mình, đồng thời duy trì khoảng trống hiệu suất cần thiết cho các giai đoạn khối lượng công việc cao điểm và tăng trưởng trong tương lai.\n4. Ứng dụng nhạy cảm với độ trễ Các ứng dụng như nền tảng giao dịch tài chính, hệ thống tự động và công cụ cộng tác thời gian thực đều yêu cầu độ trễ tối thiểu. Kết nối chuyên dụng 25 Gbps duy trì hiệu suất ổn định, độ trễ thấp bằng cách bỏ qua internet công cộng, đồng thời cung cấp đủ băng thông để ngăn ngừa tắc nghẽn trong giờ cao điểm. Đối với các ngành công nghiệp đòi hỏi tốc độ tính bằng mili giây — chẳng hạn như giao dịch tần suất cao, trò chơi trực tuyến hoặc y tế từ xa — hiệu suất dự đoán được của Direct Connect mang lại lợi thế cạnh tranh đồng thời duy trì tính bảo mật thông qua kết nối riêng tư.\nLợi ích cho các ngành như: giao dịch tần suất cao, trò chơi trực tuyến, y tế từ xa.\n5. Kiểm soát chi phí Gói 25 Gbps mang đến một giải pháp tiết kiệm chi phí để mở rộng dung lượng mạng mà không cần cung cấp quá mức. Các tổ chức trước đây buộc phải lựa chọn giữa kết nối 10 Gbps không đủ hoặc kết nối 100 Gbps quá mức giờ đây có thể chọn điểm cân bằng tối ưu, thường tiết kiệm 50-60% so với tùy chọn 100 Gbps. Nền tảng linh hoạt của Megaport cũng cho phép doanh nghiệp điều chỉnh băng thông khi nhu cầu thay đổi, hỗ trợ tối ưu hóa chi phí trong suốt vòng đời ứng dụng mà vẫn đảm bảo hiệu suất cần thiết cho khối lượng công việc đám mây hiện đại.\nLợi ích triển khai AWS Direct Connect 25 Gbps với Megaport Các phần sau đây sẽ hướng dẫn chi tiết về những lợi ích khi triển khai Direct Connect 25 Gbps với Megaport.\n1. Chuyển dữ liệu riêng tư, an toàn Các kết nối lưu trữ của Megaport cung cấp một đường dẫn riêng tư đến AWS, bỏ qua internet công cộng, giúp tăng cường quyền riêng tư dữ liệu, giảm thiểu nguy cơ bị tấn công bởi các mối đe dọa bảo mật phổ biến và đảm bảo tuân thủ cho các khối lượng công việc nhạy cảm. Kết nối riêng tư này ngày càng quan trọng khi các quy định như Quy định Bảo vệ Dữ liệu Chung (GDPR), Đạo luật Khả năng Chuyển đổi và Trách nhiệm Giải trình Bảo hiểm Y tế (HIPAA) và các yêu cầu cụ thể của ngành áp đặt các biện pháp kiểm soát chặt chẽ hơn đối với việc di chuyển và bảo vệ dữ liệu. Cấp độ 25 Gbps mang lại khả năng bảo mật này mà không ảnh hưởng đến hiệu suất cần thiết cho các ứng dụng dữ liệu chuyên sâu hiện đại.\n2. Dễ sử dụng Cổng thông tin tự phục vụ của Megaport cho phép khách hàng cung cấp, mở rộng và quản lý kết nối Direct Connect chỉ trong vài phút. Tính linh hoạt này giúp các nhóm thích ứng nhanh chóng với nhu cầu dự án thay đổi mà không phải chịu chi phí quản lý thủ công. Các tổ chức có thể thiết lập kết nối với AWS Regions gần như theo thời gian thực thay vì phải chờ hàng tuần hoặc hàng tháng cho các mạch viễn thông truyền thống, do đó đẩy nhanh các sáng kiến ​​đám mây và giảm thời gian tạo ra giá trị cho các dự án mới.\n3. Khả năng tiếp cận toàn cầu Sự hiện diện của Megaport tại hơn 975 trung tâm dữ liệu trên hơn 26 quốc gia cho phép nó cung cấp quyền truy cập gần như phổ biến vào Direct Connect locations. Các tổ chức có dấu chân phân tán có thể chuẩn hóa phương pháp kết nối nhất quán trên khắp các Vùng AWS, tinh giản kiến ​​trúc và vận hành đồng thời duy trì hiệu suất cao. Phạm vi phủ sóng toàn cầu này đặc biệt có giá trị đối với các doanh nghiệp đa quốc gia triển khai hoạt động theo mặt trời hoặc các tổ chức có yêu cầu nghiêm ngặt về chủ quyền dữ liệu.\n4. Tính linh hoạt và khả năng mở rộng Khi nhu cầu tăng lên, khách hàng có thể điều chỉnh băng thông linh hoạt thông qua cổng Megaport. Tính linh hoạt này cho phép các nhóm CNTT mở rộng quy mô một cách hiệu quả về chi phí mà vẫn duy trì hiệu suất tối ưu cho các khối lượng công việc quan trọng. Cấp 25 Gbps cung cấp một giải pháp trung gian lý tưởng, có thể được triển khai như một giải pháp dài hạn hoặc làm bước đệm cho chiến lược mạng lưới đám mây rộng lớn hơn.\nBắt đầu với AWS và Megaport 25 Gbps Các phần sau đây sẽ hướng dẫn bạn cách sử dụng AWS và Megaport với kết nối lưu trữ 25 Gbps.\nĐiều kiện tiên quyết Tài khoản Megaport đang hoạt động và có chức năng thanh toán. Tài khoản AWS có quyền truy cập Direct Connect. Bước 1: Tạo MCR Megaport Đăng nhập vào Megaport Portal. Lựa chọn +Add Service và chọn MCR (Bộ định tuyến đám mây Megaport) như thể hiện trong Hình 1. Đảm bảo rằng MCR hỗ trợ dung lượng tối thiểu là 25 Gbps, vì điều này sẽ quyết định tốc độ kết nối tối đa khả dụng cho kết nối lưu trữ của bạn. Làm theo hướng dẫn trên màn hình để hoàn tất thiết lập. Bạn có thể tìm thêm thông tin chi tiết trong Creating MCR Documentation. Bước 2: Tạo kết nối lưu trữ từ Megaport đến AWS Trong Cổng thông tin Megaport, hãy chọn MCR của bạn và nhấp vào + Add Connection. Chọn AWS Direct Connect từ các tùy chọn Đám mây. Cung cấp thông tin cần thiết và làm theo hướng dẫn: Creating a Hosted Connection Connection Name: tên mô tả cho kết nối của bạn. Service Level Reference: cung cấp mã định danh duy nhất cho mục đích thanh toán hoặc theo dõi. Rate Limit: đặt thành 25.000 Mbps để cung cấp kết nối 25 Gbps. Gửi và triển khai kết nối. Bạn cũng có thể tạo VIF lưu trữ và các loại kết nối khác (ví dụ: VIF công cộng, VIF trung chuyển), tùy thuộc vào trường hợp sử dụng của bạn.\nBước 3: Chấp nhận kết nối được lưu trữ trong AWS Đăng nhập vào AWS Console và đi đến AWS Direct Connect. Trong ngăn điều hướng, chọn Connections. Chọn kết nối được lưu trữ và chọn View details. Select the confirmation check box and choose Accept. Bước 4: Tạo Giao diện ảo cho kết nối được lưu trữ: Sau khi chấp nhận kết nối, hãy chọn nó và chọn Create Virtual Interface như thể hiện trong Hình 3. Chọn loại giao diện – thông thường Private để truy cập vào VPC. Cấu hình như sau: Tên giao diện ảo. ID VLAN (phải khớp với VLAN được sử dụng trong cấu hình Megaport). BGP ASN (mặc định của bạn hoặc AWS). Địa chỉ IP ngang hàng BGP (AWS cung cấp một bên; bạn chỉ định bên của mình). Hiệp hội Cổng kết nối: Chọn Cổng kết nối riêng ảo hoặc AWS Transit Gateway được đính kèm vào VPC của bạn. Chọn Create. Bước 5: Cấu hình BGP trên Megaport MCR Quay lại Cổng Megaport. Chỉnh sửa Virtual Cross Connect (VXC) để khớp với thông tin chi tiết BGP do AWS cung cấp. Hiển thị thông tin bạn cần nhập: Địa chỉ IP ngang hàng BGP (của bạn và của AWS). ASN của bạn (hoặc ASN do AWS chỉ định). Lưu và áp dụng cấu hình. Kết luận Trong bài viết này, chúng tôi đã khám phá cách các kết nối lưu trữ 25 Gbps của AWS Direct Connect thông qua Megaport có thể chuyển đổi chiến lược kết nối đám mây của bạn. Chúng tôi đã đề cập đến các trường hợp sử dụng thiết yếu như di chuyển lên đám mây quy mô lớn, ứng dụng dữ liệu chuyên sâu, triển khai đám mây lai và khối lượng công việc nhạy cảm với độ trễ. Bạn đã tìm hiểu cách giải pháp này mang lại khả năng truyền dữ liệu riêng tư, an toàn với khả năng mở rộng linh hoạt, đồng thời tiết kiệm chi phí đáng kể so với các giải pháp thay thế 100 Gbps. Chúng tôi cũng hướng dẫn từng bước thiết lập kết nối lưu trữ 25 Gbps bằng nền tảng tự phục vụ của Megaport.\nKêu gọi hành động Đánh giá yêu cầu về thông lượng mạng hiện tại và tương lai của bạn. Khám phá các tùy chọn Kết nối trực tiếp được lưu trữ 25 Gbps trên AWS Direct Connect Partners page. Di chuyển đến Megaport’s AWS solution page để tìm hiểu thêm hoặc bắt đầu cung cấp dịch vụ tự phục vụ. Về các tác giả Mokshith Kumar\nKiến trúc sư Giải pháp Chuyên gia GTM Cấp cao về Mạng Lõi tại AWS, hỗ trợ ISV và FSI Bắc Mỹ.\nVai trò: phát triển chiến lược GTM, dẫn dắt sáng kiến chiến lược, thúc đẩy áp dụng dịch vụ mạng AWS. Sở thích: bơi lội, âm nhạc. Miranda Li\nKiến trúc sư Giải pháp Cấp cao tại AWS, chuyên ISV và kiến trúc đám mây gốc.\n4 năm kinh nghiệm hỗ trợ ISV đổi mới, mở rộng trên AWS. Chuyên môn: IaaS, kiến trúc mạng, bảo mật, phân tích dữ liệu. Sở thích: cầu lông, chạy bộ, các hoạt động ngoài trời. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/5-workshop/5.2-prerequisite/",
	"title": "Chuẩn bị &amp; Yêu cầu",
	"tags": [],
	"description": "",
	"content": "Yêu cầu Hệ thống 1. Tài khoản AWS Tài khoản AWS đang hoạt động Quyền Administrator hoặc các quyền sau: CloudFormation: Full access EC2: Full access VPC: Full access RDS: Full access S3: Full access CloudFront: Full access IAM: Create roles and policies CloudWatch: Full access 2. AWS CLI Cài đặt và cấu hình AWS CLI:\nWindows:\n# Download và cài đặt từ: https://aws.amazon.com/cli/ # Hoặc sử dụng chocolatey: choco install awscli # Kiểm tra cài đặt aws --version Linux/Mac:\n# Sử dụng pip pip install awscli # Hoặc sử dụng package manager # Ubuntu/Debian sudo apt-get install awscli # MacOS brew install awscli # Kiểm tra cài đặt aws --version Cấu hình AWS CLI:\naws configure # AWS Access Key ID: \u0026lt;your-access-key\u0026gt; # AWS Secret Access Key: \u0026lt;your-secret-key\u0026gt; # Default region name: ap-southeast-1 # Default output format: json 3. EC2 Key Pair Tạo EC2 Key Pair để SSH vào instances:\nQua AWS Console:\nMở EC2 Console Chọn region ap-southeast-1 (Singapore) Vào Network \u0026amp; Security → Key Pairs Click Create key pair Nhập tên: workshop-aws-key Key pair type: RSA Private key file format: .pem (Linux/Mac) hoặc .ppk (Windows/PuTTY) Click Create key pair Lưu file .pem vào thư mục an toàn Qua AWS CLI:\n# Tạo key pair aws ec2 create-key-pair \\ --key-name workshop-aws-key \\ --query \u0026#39;KeyMaterial\u0026#39; \\ --output text \\ --region ap-southeast-1 \u0026gt; workshop-aws-key.pem # Set permissions (Linux/Mac only) chmod 400 workshop-aws-key.pem 4. Development Tools Java Development Kit (JDK) 17:\n# Windows (chocolatey) choco install openjdk17 # Linux (Ubuntu/Debian) sudo apt-get install openjdk-17-jdk # MacOS brew install openjdk@17 # Kiểm tra java -version Maven:\n# Windows choco install maven # Linux sudo apt-get install maven # MacOS brew install maven # Kiểm tra mvn -version Node.js và npm:\n# Windows choco install nodejs # Linux curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash - sudo apt-get install -y nodejs # MacOS brew install node # Kiểm tra node --version npm --version Chuẩn bị Project Files 1. Clone hoặc Download Project # Nếu có Git repository git clone \u0026lt;your-repo-url\u0026gt; cd aws_project # Hoặc download và extract ZIP file 2. Cấu trúc Project aws_project/\r├── aws/\r│ ├── infrastructure.yaml # CloudFormation template chính\r│ ├── cicd-pipeline.yaml # CI/CD pipeline (optional)\r│ ├── parameters.json # Parameters cho stack\r│ ├── deploy.bat # Deploy script (Windows)\r│ ├── deploy.sh # Deploy script (Linux/Mac)\r│ └── README.md # Hướng dẫn chi tiết\r├── BE/\r│ └── workshop_BE/\r│ ├── src/ # Backend source code\r│ ├── pom.xml # Maven configuration\r│ └── README.md\r└── FE/\r├── src/ # Frontend source code\r├── package.json # npm dependencies\r└── README.md 3. Cấu hình Parameters Mở file aws/parameters.json và cập nhật các giá trị:\n[ { \u0026#34;ParameterKey\u0026#34;: \u0026#34;ProjectName\u0026#34;, \u0026#34;ParameterValue\u0026#34;: \u0026#34;workshop-aws\u0026#34; }, { \u0026#34;ParameterKey\u0026#34;: \u0026#34;Environment\u0026#34;, \u0026#34;ParameterValue\u0026#34;: \u0026#34;dev\u0026#34; }, { \u0026#34;ParameterKey\u0026#34;: \u0026#34;KeyPairName\u0026#34;, \u0026#34;ParameterValue\u0026#34;: \u0026#34;workshop-aws-key\u0026#34; // ⚠️ Thay bằng tên key pair của bạn }, { \u0026#34;ParameterKey\u0026#34;: \u0026#34;DBPassword\u0026#34;, \u0026#34;ParameterValue\u0026#34;: \u0026#34;YourStrongPassword123!\u0026#34; // ⚠️ Đổi mật khẩu mạnh }, { \u0026#34;ParameterKey\u0026#34;: \u0026#34;InstanceType\u0026#34;, \u0026#34;ParameterValue\u0026#34;: \u0026#34;t3.micro\u0026#34; }, { \u0026#34;ParameterKey\u0026#34;: \u0026#34;DBInstanceClass\u0026#34;, \u0026#34;ParameterValue\u0026#34;: \u0026#34;db.t3.micro\u0026#34; } ] Lưu ý quan trọng:\nKeyPairName: Phải khớp với tên key pair đã tạo DBPassword: Tối thiểu 8 ký tự, bao gồm chữ hoa, chữ thường, số và ký tự đặc biệt Không commit file này với mật khẩu thật vào Git 4. Cập nhật AMI ID CloudFormation template sử dụng AMI ID mặc định. Bạn cần cập nhật cho region của mình:\nTìm AMI ID:\n# Tìm Amazon Linux 2023 AMI cho region ap-southeast-1 aws ec2 describe-images \\ --owners amazon \\ --filters \u0026#34;Name=name,Values=al2023-ami-*-x86_64\u0026#34; \\ --query \u0026#39;Images | sort_by(@, \u0026amp;CreationDate) | [-1].[ImageId,Name,CreationDate]\u0026#39; \\ --region ap-southeast-1 \\ --output table Cập nhật trong infrastructure.yaml:\nTìm dòng ~530:\nLaunchTemplate: Properties: LaunchTemplateData: ImageId: ami-0c55b159cbfafe1f0 # ⚠️ Thay bằng AMI ID của bạn Kiểm tra Chuẩn bị Checklist Đảm bảo bạn đã hoàn thành tất cả các bước sau:\nTài khoản AWS đã được cấu hình AWS CLI đã cài đặt và cấu hình (aws configure) EC2 Key Pair đã được tạo Java 17 đã cài đặt Maven đã cài đặt Node.js và npm đã cài đặt Project files đã được download File parameters.json đã được cập nhật AMI ID đã được cập nhật trong infrastructure.yaml Validate AWS Credentials # Kiểm tra AWS credentials aws sts get-caller-identity # Kết quả mong đợi: # { # \u0026#34;UserId\u0026#34;: \u0026#34;AIDAXXXXXXXXXXXXXXXXX\u0026#34;, # \u0026#34;Account\u0026#34;: \u0026#34;123456789012\u0026#34;, # \u0026#34;Arn\u0026#34;: \u0026#34;arn:aws:iam::123456789012:user/your-username\u0026#34; # } Validate CloudFormation Template cd aws aws cloudformation validate-template \\ --template-body file://infrastructure.yaml \\ --region ap-southeast-1 Nếu thành công, bạn sẽ thấy output với thông tin về template parameters và outputs.\nƯớc tính Chi phí Trước khi triển khai, hãy hiểu rõ chi phí:\nDịch vụ Instance Type Chi phí/tháng (USD) EC2 t3.nano $3.50 RDS MySQL db.t3.micro $2.80 API Gateway - $0.50 S3 + CloudFront - $0.80 Route 53 - $0.50 Cognito - $0.10 CloudWatch - $0.30 CI/CD (CodePipeline) - $0.40 Tổng $8.90 Cho workshop (2-3 giờ): ~$0.50-1.00\nLưu ý:\nChi phí trên áp dụng cho region ap-southeast-1 Sử dụng AWS Free Tier nếu tài khoản đủ điều kiện NAT Gateway (~$32/tháng) có thể tắt để tiết kiệm chi phí Tiếp theo Sau khi hoàn thành tất cả các bước chuẩn bị, bạn đã sẵn sàng để:\n➡️ Triển khai Infrastructure với CloudFormation\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/4-eventparticipated/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “AWS Cloud Club – First Cloud AI Journey Workshop” Mục Đích Của Sự Kiện Sự kiện “AWS Cloud Club – First Cloud AI Journey” được tổ chức nhằm:\nCung cấp định hướng cho sinh viên bước đầu tiếp cận điện toán đám mây và AI. Giới thiệu cộng đồng AWS Cloud Clubs và vai trò của họ trong việc lan tỏa kiến thức cloud. Trang bị kiến thức nền tảng để học viên chuẩn bị tham gia các hành trình cloud/AI chuyên sâu. Kết nối các bạn trẻ yêu thích công nghệ với cộng đồng AWS tại Việt Nam. Tạo môi trường trao đổi, chia sẻ kinh nghiệm giữa các thành viên Cloud Club của nhiều trường đại học. Danh Sách Diễn Giả Le Vu Xuan An – AWS Cloud Club Captain HCMUTE Tran Duc Anh – AWS Cloud Club Captain SGU Tran Doan Cong Ly – AWS Cloud Captain PTIT Danh Hoang Hieu Nghi – AWS CLoud Captain HUFLIT Nội Dung Nổi Bật 1. Giới thiệu AWS Cloud Club Cloud Club là cộng đồng do AWS hỗ trợ, dành cho sinh viên quan tâm đến Cloud Computing, AI/ML và DevOps. Mỗi trường đại học có Cloud Club Captain – người dẫn dắt hoạt động học thuật. Cộng đồng mang mục tiêu tạo ra: Không gian học tập chủ động. Nơi chia sẻ kinh nghiệm chuẩn bị certification. Các workshop thực hành từ cơ bản đến nâng cao. 2. First Cloud AI Journey – Lộ trình học Cloud + AI cho sinh viên Trong sự kiện, diễn giả trình bày:\nTổng quan chương trình First Cloud AI Journey. Lộ trình tiếp cận từ AWS Cloud fundamentals → hands-on labs → AI/ML foundation → project thực tế. Giới thiệu các chủ đề trọng tâm: Điện toán đám mây (EC2, S3, Lambda…) AI cơ bản Kiến thức cần có cho GenAI (dữ liệu, vector DB, prompt engineering…) Các công cụ AWS định hướng AI như Bedrock, Q Developer (ở các session tiếp theo) 3. Chia sẻ về hành trình học Cloud của các Cloud Club Captains Nội dung chia sẻ xoay quanh:\nCách bắt đầu học AWS từ con số 0 mà không bị “ngợp”. Quy trình chuẩn bị thi các chứng chỉ: Cloud Practitioner Solutions Architect – Associate Cách tham gia hoạt động trong cộng đồng để học nhanh hơn. Những sai lầm phổ biến của người mới học cloud: Không thực hành. Không đọc Well-Architected. Không quản lý thời gian học tập. Kinh nghiệm tìm cơ hội trong ngành: Làm dự án cá nhân (pet projects). Viết note, blog, chia sẻ kiến thức. Tạo portfolio cloud/AI chuyên nghiệp. 4. Hoạt động giao lưu \u0026amp; tương tác Trong sự kiện có các phần:\nQ\u0026amp;A mở giữa diễn giả và người tham dự. Chia sẻ thật về: Thói quen học cloud hiệu quả. Các nguồn tài liệu miễn phí. Lộ trình thi chứng chỉ. Giao lưu networking giữa các bạn đến từ nhiều trường. Những Gì Học Được 1. Tư duy định hướng Cloud \u0026amp; AI Hiểu được sự quan trọng của nền tảng cloud trước khi học AI/GenAI. Biết cách xây dựng lộ trình học phù hợp với bản thân. Tư duy “learn by doing” — thực hành mới là điểm quan trọng nhất. 2. Kiến thức cộng đồng và cơ hội phát triển Cộng đồng AWS Cloud Club đóng vai trò quan trọng giúp sinh viên: Học nhanh hơn. Có người dẫn dắt. Có cơ hội tham gia các dự án/hackathon. Học được cách tận dụng networking để phát triển sự nghiệp. 3. Kỹ năng học tập và chuẩn bị chứng chỉ Cách tiếp cận exam AWS thực tế. Những công cụ hỗ trợ học: AWS Skill Builder Cloud Quest Digital Training miễn phí Chiến lược hạn chế “burn-out” trong hành trình học cloud dài hạn. 4. Tư duy AI thời đại mới Cloud là nền tảng bắt buộc để triển khai AI/ML và GenAI. AI không bắt đầu từ mô hình — mà từ dữ liệu, cơ sở hạ tầng, và business understanding. Ứng Dụng Vào Công Việc Xây dựng roadmap học Cloud Practitioner để có kiến thức nền. Tham gia hoạt động Cloud Club để mở rộng network. Bắt đầu thực hiện mini-project: Deploy website lên S3/CloudFront. Tạo API serverless bằng AWS Lambda. Trải nghiệm các dịch vụ AI cơ bản trong AWS ở các workshop tiếp theo. Ghi chép và chia sẻ lại kiến thức đã học để củng cố. Trải Nghiệm Trong Event Tham gia “AWS Cloud Club – First Cloud AI Journey” mang đến nhiều trải nghiệm thú vị:\nHọc hỏi từ người đi trước Được nghe chia sẻ thực tế về hành trình học AWS. Học được mindset tự học hiệu quả, giúp tránh mất thời gian. Không khí sự kiện Không gian mở, nhiều bạn sinh viên đam mê cloud. Giảng trình trực quan, slide rõ ràng và hiện đại. Networking Kết nối được với nhiều bạn từ các trường khác nhau. Có thêm góc nhìn mới về phát triển sự nghiệp trong ngành cloud. Động lực học tập Buổi workshop giúp mình định hướng rõ ràng hơn. Tạo thêm động lực để theo đuổi lộ trình cloud \u0026amp; AI nghiêm túc. Một số hình ảnh trong sự kiện Tổng thể, sự kiện không chỉ truyền cảm hứng mạnh mẽ mà còn giúp tôi định hình rõ ràng con đường học tập về Cloud và AI, đồng thời xây dựng được kết nối với cộng đồng công nghệ đầy nhiệt huyết.\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/1-worklog/1.12-week12/",
	"title": "Worklog Tuần 12",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 12: Trình bày dự án của nhóm trước các mentor và giảng viên hướng dẫn. Ghi nhận phản hồi để cải thiện kiến trúc, nội dung triển khai và chất lượng phần thuyết trình. Xác định các phần cần chỉnh sửa trước khi nộp báo cáo cuối kỳ. Tổng hợp toàn bộ góp ý và lập danh sách công việc cần thực hiện ở tuần tiếp theo. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Chuẩn bị slide thuyết trình cuối cùng - Rà soát phân công nhiệm vụ và phần trình bày của từng thành viên 24/11/2025 24/11/2025 Slide deck 3 - Thực hiện buổi rehearsal nội bộ - Điều chỉnh thời gian và chuyển đoạn giữa các thành viên 25/11/2025 25/11/2025 Ghi chú nội bộ 4 - Trình bày dự án chính thức trước các mentor - Trình bày kiến trúc hệ thống, CI/CD pipeline, cost estimate và demo 26/11/2025 26/11/2025 Tài liệu thuyết trình 5 - Ghi nhận phản hồi từ mentor về kiến trúc, bảo mật, thiết kế hệ thống và cách trình bày - Tổng hợp toàn bộ góp ý 27/11/2025 27/11/2025 Mentor feedback 6 - Phân tích phản hồi đã nhận được - Xác định những phần cần chỉnh sửa về kiến trúc, lưu đồ, nội dung slide 28/11/2025 28/11/2025 Góp ý tổng hợp 7 - Chỉnh sửa tài liệu và slide theo phản hồi của mentor - Chuẩn bị danh sách action items cho tuần tiếp theo 29–30/11/2025 30/11/2025 Proposal, Slide deck Kết quả đạt được tuần 12: Trình bày dự án thành công trước mentor và nhận được phản hồi chi tiết về kiến trúc, nội dung triển khai và phong cách thuyết trình. Ghi nhận đầy đủ góp ý liên quan đến: Cải thiện kiến trúc hệ thống Làm rõ data flow và lớp mạng Giải thích CI/CD pipeline mạch lạc hơn Tối ưu chi phí AWS Tăng cường bảo mật trong thiết kế hệ thống Hoàn thiện lại slide deck và tài liệu dự án dựa trên góp ý từ mentor. Xác định các đầu mục quan trọng cần chỉnh sửa cho giai đoạn cuối trước khi nộp bài. Hoàn thành rehearsal và buổi trình bày giữa kỳ đúng tiến độ. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/1-worklog/1.11-week11/",
	"title": "Worklog Tuần 11",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 11: Tổng hợp nội dung từ 2 proposal hiện có của nhóm. Chuẩn bị tài liệu để làm slide thuyết trình báo cáo cuối kỳ. Chuẩn hóa nội dung, xác định phần trình bày chính và phần bổ sung. Đảm bảo tính nhất quán giữa kiến trúc hệ thống và kế hoạch triển khai. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Rà soát toàn bộ nội dung Proposal.docx - Liệt kê các mục quan trọng cần đưa vào slide 17/11/2025 17/11/2025 Proposal.docx 3 - Tổng hợp nội dung Executive Summary, Problem Statement, Solution Overview - Chỉnh sửa nội dung cho ngắn gọn, phù hợp trình chiếu 18/11/2025 18/11/2025 Proposal.docx 4 - Tách và chuẩn hóa phần Solution Architecture + Networking layer + Application layer + CI/CD + Security \u0026amp; Monitoring 19/11/2025 19/11/2025 Proposal Template.docx 5 - Tổng hợp bảng AWS Cost Estimate - Rà lại Risk Assessment và Timeline - Chuyển nội dung sang dạng bullet ngắn gọn để đưa vào slide 20/11/2025 20/11/2025 Proposal.docx 6 - Xây dựng outline slide thuyết trình: + Summary + Problem + Architecture + Cost + Risk + Roadmap 21/11/2025 21/11/2025 Tổng hợp nội dung 7 - Chuẩn hóa toàn bộ nội dung sang tiếng Anh - Kiểm tra tính logic giữa các phần - Chuẩn bị tài liệu bàn giao cho nhóm thiết kế slide 22/11/2025 23/11/2025 Proposal.docx, Proposal Template Kết quả đạt được tuần 11: Hoàn tất tổng hợp nội dung từ 2 proposal (đầy đủ các phần Executive Summary, Problem, Solution, Architecture, Risk, Cost…). Xây dựng outline slide trình bày, chia rõ các phần chính và phần mở rộng. Chuẩn hóa toàn bộ nội dung sang tiếng Anh để triển khai slide báo cáo cuối kỳ. Đảm bảo tính nhất quán giữa kiến trúc hệ thống, kế hoạch triển khai và nội dung trình bày. Sẵn sàng chuyển sang giai đoạn thiết kế slide và chuẩn bị cho buổi báo cáo. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/1-worklog/1.10-week10/",
	"title": "Worklog Tuần 10",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 10: Xây dựng workshop dựa trên nội dung của Proposal và Proposal Template. Xác định các phần sẽ được trình bày trong workshop: Overview, Architecture, CI/CD, Cost, Security… Chuẩn hóa nội dung workshop theo cấu trúc AWS. Chuẩn bị tài liệu để nhóm có thể trình bày hiệu quả trong buổi workshop. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Đọc lại proposal nhóm BDSS - Nghiên cứu Proposal Template - Xác định phạm vi workshop cần xây dựng 10/11/2025 10/11/2025 proposal.docx Proposal Template.docx 3 - Phân tích cấu trúc workshop dựa trên template - Chọn các phần phù hợp từ hai proposal để đưa vào workshop 11/11/2025 11/11/2025 Proposal Template.docx 4 - Viết nội dung cho các mục: Introduction, Background, Objectives của workshop - Chuẩn hóa flow và wording theo format AWS 12/11/2025 12/11/2025 proposal.docx 5 - Xây dựng phần Workshop Content chính: + System Architecture + Data Flow + CI/CD Pipeline + Security Model 13/11/2025 14/11/2025 proposal.docx 6 - Tổng hợp AWS Cost Estimate, Risk Assessment để đưa vào workshop - Điều chỉnh nội dung theo bố cục workshop 14/11/2025 15/11/2025 Proposal Template.docx 7 - Hoàn thiện bản Workshop Draft - Chỉnh sửa định dạng, heading, flow trình bày - Gửi tài liệu workshop cho nhóm review 16/11/2025 16/11/2025 — Kết quả đạt được tuần 10: Đã xây dựng xong bản Workshop Draft dựa vào Proposal \u0026amp; Proposal Template. Chuẩn hóa nội dung workshop gồm: Introduction, Background, Architecture, CI/CD, Cost, Security, Roadmap. Kiến trúc BDSS được mô tả theo cấu trúc workshop rõ ràng và dễ trình bày. Tổng hợp đầy đủ phần chi phí, rủi ro và kế hoạch triển khai để đưa vào workshop. Tài liệu workshop đã sẵn sàng để nhóm duyệt và chuẩn bị cho buổi trình bày. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/2-proposal/",
	"title": "Đề xuất dự án",
	"tags": [],
	"description": "",
	"content": "Blood Donation Support System (BDSS) 📄 Tải xuống toàn bộ tài liệu đề xuất (Word)\n1. Tóm tắt điều hành Blood Donation Support System (BDSS) là nền tảng web hỗ trợ quản lý và kết nối người hiến máu với cơ sở y tế. Dự án được phát triển bởi nhóm sinh viên tại TP. Hồ Chí Minh nhằm tối ưu quy trình hiến máu, giảm tải khâu tìm kiếm người hiến và nâng cao hiệu quả truyền thông y tế.\nHệ thống được xây dựng trên kiến trúc AWS Cloud, sử dụng Amazon EC2, Amazon RDS, API Gateway, Cognito và CI/CD Pipeline (GitLab + CodePipeline) để tự động triển khai. BDSS hỗ trợ bốn nhóm người dùng (Guest, Member, Staff, Admin), cung cấp tính năng tra cứu, đăng ký hiến máu, quản lý kho máu, theo dõi quy trình hiến máu và báo cáo trực quan.\n2. Tuyên bố vấn đề Vấn đề hiện tại: Các cơ sở y tế hiện đang quản lý quy trình hiến máu thủ công hoặc thông qua các công cụ rời rạc. Việc tìm kiếm người hiến máu phù hợp nhóm máu hoặc theo khu vực gặp khó khăn, đặc biệt trong tình huống khẩn cấp. Ngoài ra, hệ thống lưu trữ dữ liệu chưa đồng bộ, gây khó khăn trong việc phân tích, báo cáo và tối ưu chiến dịch hiến máu.\nGiải pháp đề xuất: Phát triển nền tảng hỗ trợ hiến máu toàn diện trên AWS Cloud, với các chức năng quản lý hiến máu, tìm kiếm người hiến và người cần máu theo nhóm máu hoặc vị trí địa lý, tích hợp xác thực người dùng qua Amazon Cognito và quản trị dữ liệu trên Amazon RDS.\nFrontend được triển khai qua Route 53 + CloudFront, backend thông qua API Gateway – EC2, cơ sở dữ liệu MySQL trên Amazon RDS, và pipeline tự động CI/CD bằng GitLab – CodePipeline.\nLợi ích và ROI: Giảm 60–70% thời gian tìm kiếm người hiến máu phù hợp. Tăng độ chính xác thông tin nhóm máu và vị trí. Tối ưu chi phí vận hành với kiến trúc cloud linh hoạt, trả phí theo mức sử dụng. Cải thiện khả năng phản hồi trong các trường hợp máu khẩn cấp. 3. Kiến trúc giải pháp Nền tảng áp dụng kiến trúc AWS Serverless để quản lý dữ liệu từ 5 trạm dựa trên Raspberry Pi, có thể mở rộng lên 15 trạm. Dữ liệu được tiếp nhận qua AWS IoT Core, lưu trữ trong S3 data lake và xử lý bởi AWS Glue Crawlers và ETL jobs để chuyển đổi và tải vào một S3 bucket khác cho mục đích phân tích. Lambda và API Gateway xử lý bổ sung, trong khi Amplify với Next.js cung cấp bảng điều khiển được bảo mật bởi Cognito.\nHệ thống được thiết kế theo kiến trúc 3-tier trên AWS Cloud với các thành phần chính:\n1. Frontend \u0026amp; Content Delivery Layer: Users: Người dùng truy cập hệ thống qua trình duyệt web hoặc mobile. Route 53: Dịch vụ DNS quản lý domain name và routing traffic đến CloudFront. CloudFront: CDN phân phối nội dung tĩnh với độ trễ thấp, cache tại edge locations. Amazon S3: Lưu trữ static assets (HTML, CSS, JS, images) cho frontend application. 2. Application \u0026amp; Compute Layer: API Gateway: REST API endpoint, xử lý request/response giữa frontend và backend. VPC (Virtual Private Cloud): Mạng riêng ảo cô lập với cấu hình: Internet Gateway: Cho phép public subnet kết nối Internet. Public Subnet: Chứa EC2 instances xử lý business logic. Private Subnet: Chứa RDS database, không truy cập trực tiếp từ Internet. NAT Gateway: Cho phép private subnet truy cập Internet một chiều (outbound). Amazon EC2: Compute instances chạy backend API (Node.js/Express). Amazon RDS (MySQL): Relational database lưu trữ dữ liệu người hiến máu, nhóm máu, lịch sử hiến máu. 3. CI/CD \u0026amp; DevOps Pipeline: GitLab: Source code repository và version control. AWS CodePipeline: Orchestrate CI/CD workflow tự động. AWS CodeBuild: Build và test code trước khi deploy. Automated Deployment: Tự động deploy lên EC2 khi có code changes. 4. Monitoring, Security \u0026amp; Management Layer: Amazon Cognito: User authentication và authorization (Guest, Member, Staff, Admin roles). AWS IAM: Quản lý quyền truy cập cho users và services. AWS Secrets Manager: Lưu trữ an toàn database credentials và API keys. Amazon CloudWatch: Giám sát metrics, logs, và tạo alarms. AWS CloudTrail: Audit logs cho tất cả API calls và user activities. Amazon Athena: Query và phân tích logs từ S3. Amazon SNS: Gửi notifications (email/SMS) khi có sự kiện quan trọng (máu khẩn cấp, người hiến phù hợp). Luồng hoạt động của hệ thống: User Access: Users → Route 53 → CloudFront → S3 (Frontend) API Requests: Frontend → API Gateway → EC2 (Backend) → RDS (Database) Data Flow: EC2 instances trong public subnet kết nối với RDS trong private subnet Outbound Traffic: Private subnet → NAT Gateway → Internet Gateway CI/CD Flow: GitLab → CodePipeline → CodeBuild → EC2 deployment Monitoring: CloudWatch thu thập metrics → SNS gửi alerts → Athena phân tích logs 4. Triển khai kỹ thuật Các giai đoạn triển khai: 1. Phân tích \u0026amp; thiết kế (Tháng 1) Thu thập yêu cầu, xác định use case, thiết kế ERD và kiến trúc AWS. 2. Thiết lập hạ tầng \u0026amp; pipeline (Tháng 2) Cấu hình Route 53, CloudFront, EC2, RDS và CI/CD trên AWS. 3. Phát triển \u0026amp; kiểm thử (Tháng 3–4) Xây dựng các module chính: đăng ký hiến máu, tìm kiếm, quản lý kho máu. Tích hợp Cognito và hệ thống cảnh báo SNS. 4. Triển khai \u0026amp; vận hành (Tháng 5) Triển khai sản phẩm chính thức và giám sát bằng CloudWatch. Yêu cầu kỹ thuật chính: Frontend: React/Next.js hoặc Angular (deploy qua S3/CloudFront). Backend: Node.js/Express trên EC2, giao tiếp qua REST API Gateway. Database: Amazon RDS MySQL, tối ưu query và backup định kỳ. CI/CD: GitLab → CodeBuild → CodePipeline → EC2. Auth: Cognito (4 vai trò: Guest, Member, Staff, Admin). Alert \u0026amp; Logs: SNS + CloudWatch + CloudTrail. 5. Lộ trình \u0026amp; Mốc triển khai Thời gian Giai đoạn Kết quả chính Tháng 1 Phân tích yêu cầu \u0026amp; thiết kế Kiến trúc AWS + sơ đồ use case Tháng 2 Thiết lập hạ tầng \u0026amp; pipeline EC2, RDS, API Gateway hoạt động Tháng 3–4 Phát triển \u0026amp; kiểm thử Hoàn thiện các module chính Tháng 5 Triển khai chính thức Hệ thống hoạt động ổn định, có báo cáo Dashboard 6. Ước tính ngân sách Dịch vụ Ước tính chi phí/tháng (USD) Ghi chú EC2 (t3.nano) 3.50 Backend REST API Amazon RDS (MySQL) 2.80 20 GB storage API Gateway 0.50 5.000 request CloudFront + S3 0.80 Website + CDN Route 53 0.50 Domain \u0026amp; DNS Cognito 0.10 \u0026lt;100 người dùng CloudWatch + Logs 0.30 Giám sát và cảnh báo CI/CD (CodePipeline, CodeBuild) 0.40 Triển khai tự động Tổng cộng 8.9 USD/tháng ~106.8 USD/năm Toàn bộ chi phí có thể điều chỉnh dựa trên AWS Free Tier hoặc sử dụng spot instance.\n7. Đánh giá rủi ro Rủi ro Ảnh hưởng Xác suất Biện pháp giảm thiểu Mất kết nối Internet Trung bình Trung bình Dự phòng trên EC2 backup Tấn công DDoS Cao Thấp AWS WAF + CloudFront Lỗi dữ liệu người dùng Cao Thấp RDS backup + IAM hạn chế truy cập Chi phí vượt mức Trung bình Thấp Cảnh báo ngân sách AWS Gián đoạn triển khai CI/CD Thấp Trung bình Kiểm tra pipeline trước khi merge 8. Kết quả kỳ vọng Kỹ thuật: Hệ thống cloud-native, CI/CD tự động, hỗ trợ đa người dùng và bảo mật cao. Ứng dụng: Giúp cơ sở y tế quản lý hiến máu hiệu quả, giảm thiểu quy trình thủ công. Mở rộng: Có thể nhân rộng cho nhiều bệnh viện khác, tích hợp thêm AI phân tích nhu cầu nhóm máu hoặc dự đoán đợt hiến máu sắp tới. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/5-workshop/5.2-prerequiste/",
	"title": "Các bước chuẩn bị",
	"tags": [],
	"description": "",
	"content": "IAM permissions Gắn IAM permission policy sau vào tài khoản aws user của bạn để triển khai và dọn dẹp tài nguyên trong workshop này.\n{\r\u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,\r\u0026#34;Statement\u0026#34;: [\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;cloudformation:*\u0026#34;,\r\u0026#34;cloudwatch:*\u0026#34;,\r\u0026#34;ec2:AcceptTransitGatewayPeeringAttachment\u0026#34;,\r\u0026#34;ec2:AcceptTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:AllocateAddress\u0026#34;,\r\u0026#34;ec2:AssociateAddress\u0026#34;,\r\u0026#34;ec2:AssociateIamInstanceProfile\u0026#34;,\r\u0026#34;ec2:AssociateRouteTable\u0026#34;,\r\u0026#34;ec2:AssociateSubnetCidrBlock\u0026#34;,\r\u0026#34;ec2:AssociateTransitGatewayRouteTable\u0026#34;,\r\u0026#34;ec2:AssociateVpcCidrBlock\u0026#34;,\r\u0026#34;ec2:AttachInternetGateway\u0026#34;,\r\u0026#34;ec2:AttachNetworkInterface\u0026#34;,\r\u0026#34;ec2:AttachVolume\u0026#34;,\r\u0026#34;ec2:AttachVpnGateway\u0026#34;,\r\u0026#34;ec2:AuthorizeSecurityGroupEgress\u0026#34;,\r\u0026#34;ec2:AuthorizeSecurityGroupIngress\u0026#34;,\r\u0026#34;ec2:CreateClientVpnEndpoint\u0026#34;,\r\u0026#34;ec2:CreateClientVpnRoute\u0026#34;,\r\u0026#34;ec2:CreateCustomerGateway\u0026#34;,\r\u0026#34;ec2:CreateDhcpOptions\u0026#34;,\r\u0026#34;ec2:CreateFlowLogs\u0026#34;,\r\u0026#34;ec2:CreateInternetGateway\u0026#34;,\r\u0026#34;ec2:CreateLaunchTemplate\u0026#34;,\r\u0026#34;ec2:CreateNetworkAcl\u0026#34;,\r\u0026#34;ec2:CreateNetworkInterface\u0026#34;,\r\u0026#34;ec2:CreateNetworkInterfacePermission\u0026#34;,\r\u0026#34;ec2:CreateRoute\u0026#34;,\r\u0026#34;ec2:CreateRouteTable\u0026#34;,\r\u0026#34;ec2:CreateSecurityGroup\u0026#34;,\r\u0026#34;ec2:CreateSubnet\u0026#34;,\r\u0026#34;ec2:CreateSubnetCidrReservation\u0026#34;,\r\u0026#34;ec2:CreateTags\u0026#34;,\r\u0026#34;ec2:CreateTransitGateway\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayPeeringAttachment\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayPrefixListReference\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayRoute\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayRouteTable\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:CreateVpc\u0026#34;,\r\u0026#34;ec2:CreateVpcEndpoint\u0026#34;,\r\u0026#34;ec2:CreateVpcEndpointConnectionNotification\u0026#34;,\r\u0026#34;ec2:CreateVpcEndpointServiceConfiguration\u0026#34;,\r\u0026#34;ec2:CreateVpnConnection\u0026#34;,\r\u0026#34;ec2:CreateVpnConnectionRoute\u0026#34;,\r\u0026#34;ec2:CreateVpnGateway\u0026#34;,\r\u0026#34;ec2:DeleteCustomerGateway\u0026#34;,\r\u0026#34;ec2:DeleteFlowLogs\u0026#34;,\r\u0026#34;ec2:DeleteInternetGateway\u0026#34;,\r\u0026#34;ec2:DeleteNetworkInterface\u0026#34;,\r\u0026#34;ec2:DeleteNetworkInterfacePermission\u0026#34;,\r\u0026#34;ec2:DeleteRoute\u0026#34;,\r\u0026#34;ec2:DeleteRouteTable\u0026#34;,\r\u0026#34;ec2:DeleteSecurityGroup\u0026#34;,\r\u0026#34;ec2:DeleteSubnet\u0026#34;,\r\u0026#34;ec2:DeleteSubnetCidrReservation\u0026#34;,\r\u0026#34;ec2:DeleteTags\u0026#34;,\r\u0026#34;ec2:DeleteTransitGateway\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayPeeringAttachment\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayPrefixListReference\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayRoute\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayRouteTable\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:DeleteVpc\u0026#34;,\r\u0026#34;ec2:DeleteVpcEndpoints\u0026#34;,\r\u0026#34;ec2:DeleteVpcEndpointServiceConfigurations\u0026#34;,\r\u0026#34;ec2:DeleteVpnConnection\u0026#34;,\r\u0026#34;ec2:DeleteVpnConnectionRoute\u0026#34;,\r\u0026#34;ec2:Describe*\u0026#34;,\r\u0026#34;ec2:DetachInternetGateway\u0026#34;,\r\u0026#34;ec2:DisassociateAddress\u0026#34;,\r\u0026#34;ec2:DisassociateRouteTable\u0026#34;,\r\u0026#34;ec2:GetLaunchTemplateData\u0026#34;,\r\u0026#34;ec2:GetTransitGatewayAttachmentPropagations\u0026#34;,\r\u0026#34;ec2:ModifyInstanceAttribute\u0026#34;,\r\u0026#34;ec2:ModifySecurityGroupRules\u0026#34;,\r\u0026#34;ec2:ModifyTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:ModifyVpcAttribute\u0026#34;,\r\u0026#34;ec2:ModifyVpcEndpoint\u0026#34;,\r\u0026#34;ec2:ReleaseAddress\u0026#34;,\r\u0026#34;ec2:ReplaceRoute\u0026#34;,\r\u0026#34;ec2:RevokeSecurityGroupEgress\u0026#34;,\r\u0026#34;ec2:RevokeSecurityGroupIngress\u0026#34;,\r\u0026#34;ec2:RunInstances\u0026#34;,\r\u0026#34;ec2:StartInstances\u0026#34;,\r\u0026#34;ec2:StopInstances\u0026#34;,\r\u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsEgress\u0026#34;,\r\u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsIngress\u0026#34;,\r\u0026#34;iam:AddRoleToInstanceProfile\u0026#34;,\r\u0026#34;iam:AttachRolePolicy\u0026#34;,\r\u0026#34;iam:CreateInstanceProfile\u0026#34;,\r\u0026#34;iam:CreatePolicy\u0026#34;,\r\u0026#34;iam:CreateRole\u0026#34;,\r\u0026#34;iam:DeleteInstanceProfile\u0026#34;,\r\u0026#34;iam:DeletePolicy\u0026#34;,\r\u0026#34;iam:DeleteRole\u0026#34;,\r\u0026#34;iam:DeleteRolePolicy\u0026#34;,\r\u0026#34;iam:DetachRolePolicy\u0026#34;,\r\u0026#34;iam:GetInstanceProfile\u0026#34;,\r\u0026#34;iam:GetPolicy\u0026#34;,\r\u0026#34;iam:GetRole\u0026#34;,\r\u0026#34;iam:GetRolePolicy\u0026#34;,\r\u0026#34;iam:ListPolicyVersions\u0026#34;,\r\u0026#34;iam:ListRoles\u0026#34;,\r\u0026#34;iam:PassRole\u0026#34;,\r\u0026#34;iam:PutRolePolicy\u0026#34;,\r\u0026#34;iam:RemoveRoleFromInstanceProfile\u0026#34;,\r\u0026#34;lambda:CreateFunction\u0026#34;,\r\u0026#34;lambda:DeleteFunction\u0026#34;,\r\u0026#34;lambda:DeleteLayerVersion\u0026#34;,\r\u0026#34;lambda:GetFunction\u0026#34;,\r\u0026#34;lambda:GetLayerVersion\u0026#34;,\r\u0026#34;lambda:InvokeFunction\u0026#34;,\r\u0026#34;lambda:PublishLayerVersion\u0026#34;,\r\u0026#34;logs:CreateLogGroup\u0026#34;,\r\u0026#34;logs:DeleteLogGroup\u0026#34;,\r\u0026#34;logs:DescribeLogGroups\u0026#34;,\r\u0026#34;logs:PutRetentionPolicy\u0026#34;,\r\u0026#34;route53:ChangeTagsForResource\u0026#34;,\r\u0026#34;route53:CreateHealthCheck\u0026#34;,\r\u0026#34;route53:CreateHostedZone\u0026#34;,\r\u0026#34;route53:CreateTrafficPolicy\u0026#34;,\r\u0026#34;route53:DeleteHostedZone\u0026#34;,\r\u0026#34;route53:DisassociateVPCFromHostedZone\u0026#34;,\r\u0026#34;route53:GetHostedZone\u0026#34;,\r\u0026#34;route53:ListHostedZones\u0026#34;,\r\u0026#34;route53domains:ListDomains\u0026#34;,\r\u0026#34;route53domains:ListOperations\u0026#34;,\r\u0026#34;route53domains:ListTagsForDomain\u0026#34;,\r\u0026#34;route53resolver:AssociateResolverEndpointIpAddress\u0026#34;,\r\u0026#34;route53resolver:AssociateResolverRule\u0026#34;,\r\u0026#34;route53resolver:CreateResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:CreateResolverRule\u0026#34;,\r\u0026#34;route53resolver:DeleteResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:DeleteResolverRule\u0026#34;,\r\u0026#34;route53resolver:DisassociateResolverEndpointIpAddress\u0026#34;,\r\u0026#34;route53resolver:DisassociateResolverRule\u0026#34;,\r\u0026#34;route53resolver:GetResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:GetResolverRule\u0026#34;,\r\u0026#34;route53resolver:ListResolverEndpointIpAddresses\u0026#34;,\r\u0026#34;route53resolver:ListResolverEndpoints\u0026#34;,\r\u0026#34;route53resolver:ListResolverRuleAssociations\u0026#34;,\r\u0026#34;route53resolver:ListResolverRules\u0026#34;,\r\u0026#34;route53resolver:ListTagsForResource\u0026#34;,\r\u0026#34;route53resolver:UpdateResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:UpdateResolverRule\u0026#34;,\r\u0026#34;s3:AbortMultipartUpload\u0026#34;,\r\u0026#34;s3:CreateBucket\u0026#34;,\r\u0026#34;s3:DeleteBucket\u0026#34;,\r\u0026#34;s3:DeleteObject\u0026#34;,\r\u0026#34;s3:GetAccountPublicAccessBlock\u0026#34;,\r\u0026#34;s3:GetBucketAcl\u0026#34;,\r\u0026#34;s3:GetBucketOwnershipControls\u0026#34;,\r\u0026#34;s3:GetBucketPolicy\u0026#34;,\r\u0026#34;s3:GetBucketPolicyStatus\u0026#34;,\r\u0026#34;s3:GetBucketPublicAccessBlock\u0026#34;,\r\u0026#34;s3:GetObject\u0026#34;,\r\u0026#34;s3:GetObjectVersion\u0026#34;,\r\u0026#34;s3:GetBucketVersioning\u0026#34;,\r\u0026#34;s3:ListAccessPoints\u0026#34;,\r\u0026#34;s3:ListAccessPointsForObjectLambda\u0026#34;,\r\u0026#34;s3:ListAllMyBuckets\u0026#34;,\r\u0026#34;s3:ListBucket\u0026#34;,\r\u0026#34;s3:ListBucketMultipartUploads\u0026#34;,\r\u0026#34;s3:ListBucketVersions\u0026#34;,\r\u0026#34;s3:ListJobs\u0026#34;,\r\u0026#34;s3:ListMultipartUploadParts\u0026#34;,\r\u0026#34;s3:ListMultiRegionAccessPoints\u0026#34;,\r\u0026#34;s3:ListStorageLensConfigurations\u0026#34;,\r\u0026#34;s3:PutAccountPublicAccessBlock\u0026#34;,\r\u0026#34;s3:PutBucketAcl\u0026#34;,\r\u0026#34;s3:PutBucketPolicy\u0026#34;,\r\u0026#34;s3:PutBucketPublicAccessBlock\u0026#34;,\r\u0026#34;s3:PutObject\u0026#34;,\r\u0026#34;secretsmanager:CreateSecret\u0026#34;,\r\u0026#34;secretsmanager:DeleteSecret\u0026#34;,\r\u0026#34;secretsmanager:DescribeSecret\u0026#34;,\r\u0026#34;secretsmanager:GetSecretValue\u0026#34;,\r\u0026#34;secretsmanager:ListSecrets\u0026#34;,\r\u0026#34;secretsmanager:ListSecretVersionIds\u0026#34;,\r\u0026#34;secretsmanager:PutResourcePolicy\u0026#34;,\r\u0026#34;secretsmanager:TagResource\u0026#34;,\r\u0026#34;secretsmanager:UpdateSecret\u0026#34;,\r\u0026#34;sns:ListTopics\u0026#34;,\r\u0026#34;ssm:DescribeInstanceProperties\u0026#34;,\r\u0026#34;ssm:DescribeSessions\u0026#34;,\r\u0026#34;ssm:GetConnectionStatus\u0026#34;,\r\u0026#34;ssm:GetParameters\u0026#34;,\r\u0026#34;ssm:ListAssociations\u0026#34;,\r\u0026#34;ssm:ResumeSession\u0026#34;,\r\u0026#34;ssm:StartSession\u0026#34;,\r\u0026#34;ssm:TerminateSession\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;\r}\r]\r} Khởi tạo tài nguyên bằng CloudFormation Trong lab này, chúng ta sẽ dùng N.Virginia region (us-east-1).\nĐể chuẩn bị cho môi trường làm workshop, chúng ta deploy CloudFormation template sau (click link): PrivateLinkWorkshop . Để nguyên các lựa chọn mặc định.\nLựa chọn 2 mục acknowledgement Chọn Create stack Quá trình triển khai CloudFormation cần khoảng 15 phút để hoàn thành.\n2 VPCs đã được tạo 3 EC2s đã được tạo "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/3-blogstranslated/3.2-blog2/",
	"title": "Blog 2",
	"tags": [],
	"description": "",
	"content": "Đơn giản hóa mã hóa đa thuê bao với chiến lược khóa AWS KMS tiết kiệm chi phí Giới thiệu Các tổ chức phải đối mặt diverse challenges when it comes to managing encryption keys. Mặc dù một số kịch bản yêu cầu sự tách biệt nghiêm ngặt, nhưng có những trường hợp sử dụng thiết thực mà phương pháp tập trung có thể hợp lý hóa hoạt động và giảm độ phức tạp. Trong bài viết này, chúng tôi tập trung vào kịch bản nhà cung cấp phần mềm dưới dạng dịch vụ (SaaS), nhưng các nguyên tắc chúng tôi thảo luận có thể được áp dụng bởi các tổ chức lớn đang đối mặt với những thách thức quản lý quan trọng tương tự.\nViệc quản lý mã hóa trên một kiến ​​trúc đa thuê bao, đa dịch vụ đặt ra một thách thức đáng kể. Nhiều tổ chức đang phải vật lộn với sự phức tạp và chi phí liên quan đến việc cung cấp các dịch vụ riêng biệt AWS Key Management Service (AWS KMS) customer managed keys cho từng đối tượng thuê bao và dịch vụ. Cách tiếp cận này, mặc dù an toàn, nhưng thường dẫn đến chi phí vận hành tăng cao và chi phí sử dụng AWS KMS tăng theo thời gian.\nNhưng nếu có cách hiệu quả hơn thì sao?\nTrong bài viết này, chúng tôi sẽ giới thiệu một chiến lược sử dụng một khóa duy nhất do khách hàng quản lý (đối xứng) cho mỗi đối tượng thuê trên các dịch vụ. Sau khi đọc hết bài viết này, bạn sẽ tìm hiểu:\nLàm thế nào để triển khai một mô hình mã hóa có khả năng mở rộng, an toàn và tiết kiệm chi phí Các kỹ thuật sử dụng một khóa do khách hàng quản lý cho mỗi đối tượng thuê trên nhiều dịch vụ và môi trường Phương pháp mã hóa dữ liệu người thuê trong Amazon DynamoDB và các loại lưu trữ khác trong khi vẫn duy trì sự cô lập của người thuê. Yêu cầu mã hóa đa thuê bao trong SaaS Việc cô lập dữ liệu là nền tảng cơ bản của các kiến ​​trúc SaaS đa thuê bao, đáp ứng cả yêu cầu tuân thủ và sự tin tưởng của khách hàng. Nhiều nhà cung cấp SaaS cần mã hóa thông tin nhạy cảm - từ khóa API và thông tin đăng nhập đến dữ liệu cá nhân - trên các giải pháp lưu trữ như DynamoDB và Amazon Simple Storage Service (Amazon S3).\nMặc dù các dịch vụ lưu trữ này cung cấp mã hóa mặc định khi lưu trữ, nhưng chúng thường sử dụng một khóa chung duy nhất trên các mục dữ liệu. Hãy xem xét DynamoDB in a shared pool model, trong đó một bảng chứa dữ liệu từ nhiều đối tượng thuê. Trong thiết lập này, dữ liệu đối tượng thuê được mã hóa bằng cùng một AWS KMS Key, bất kể quyền sở hữu.\nKhóa KMS đại diện cho một vùng chứa tài liệu khóa cấp cao nhất và được xác định duy nhất trong KMS, để biết thêm thông tin về các khóa khác nhau liên quan khi mã hóa hoặc giải mã dữ liệu bằng KMS, hãy xem AWS KMS key hierarchy.\nPhương pháp khóa chia sẻ này thường tỏ ra không đủ hiệu quả đối với các nhà cung cấp SaaS hoạt động theo khuôn khổ bảo mật và tuân thủ nghiêm ngặt. Một số khách hàng yêu cầu\nKhả năng mang theo chìa khóa riêng (BYOK) Cô lập dữ liệu một cách hợp lý thông qua các khóa mã hóa chuyên dụng Để đáp ứng các yêu cầu này, nhà cung cấp có thể triển khai khóa được quản lý AWS KMS dành riêng cho khách hàng, giúp đảm bảo dữ liệu nhạy cảm của mỗi khách hàng vẫn được tách biệt và không thể truy cập được bởi những người thuê khác.\nNgoài ra, các nhà cung cấp có thể cân nhắc mô hình silo với các bảng riêng biệt cho mỗi khách hàng. Tuy nhiên, cách tiếp cận này cũng đặt ra những thách thức riêng - khi cơ sở khách hàng tăng lên, việc quản lý nhiều bảng riêng lẻ trở nên ngày càng phức tạp và service quota giới hạn có thể trở thành một ràng buộc.\nQuản lý tăng trưởng: Quản lý khóa KMS ở quy mô lớn Khi mở rộng quy mô nền tảng SaaS, việc trao quyền cho các nhóm phát triển dịch vụ một cách độc lập là rất quan trọng. Một cách nhanh chóng để mở rộng quy mô là có each team develop independently using a dedicated account. Điều này thường dẫn đến phương pháp tiếp cận phi tập trung, trong đó mỗi dịch vụ quản lý khóa KMS riêng cho từng khách hàng. Tuy nhiên, tính tự chủ này đi kèm với những chi phí ẩn khi cơ sở khách hàng và danh mục dịch vụ của bạn mở rộng.\nThách thức của sự phổ biến chìa khóa Khi công ty phát triển, số lượng khóa sẽ tăng lên theo mỗi khách hàng và dịch vụ mới được bổ sung. Sự gia tăng này tạo ra một số thách thức cho tổ chức:\nTác động về chi phí: Một khóa AWS KMS có giá 1 đô la mỗi tháng, tăng lên tối đa 3 đô la mỗi tháng với hai hoặc nhiều lần luân chuyển khóa. Độ phức tạp trong vận hành: Việc quản lý nhiều khóa KMS trên nhiều môi trường và tài khoản dễ xảy ra lỗi và khó mở rộng quy mô. Lãng phí tổ chức: Nỗ lực trùng lặp giữa các nhóm vì mỗi nhóm phát triển và duy trì mã riêng để quản lý vòng đời khóa khách hàng. Chi phí quản lý: Việc thực thi các chính sách nhất quán hoặc theo dõi việc sử dụng khóa KMS trên nhiều tài khoản AWS trở nên khó khăn. Một cách tiếp cận hợp lý Giải pháp nằm ở việc thực hiện một centralized key management strategy. Một khóa KMS cho mỗi đối tượng thuê, được lưu trữ trong một tài khoản AWS trung tâm. Phương pháp này giải quyết hiệu quả các thách thức về chi phí, vận hành và quản trị, đồng thời vẫn đảm bảo tính bảo mật.\nTrong các phần sau, chúng tôi sẽ khám phá cách triển khai phương pháp tập trung này và chia sẻ khóa KMS một cách an toàn trên nhiều dịch vụ và tài khoản AWS khác nhau.\nTổng quan về giải pháp: Tập trung quản lý khóa đối tượng thuê Cốt lõi của giải pháp của chúng tôi là dịch vụ quản lý khóa thuê bao tập trung (được hiển thị là Dịch vụ A trong hình sau). Dịch vụ này xử lý mọi khía cạnh của vòng đời khóa KMS của khách hàng—từ việc tạo khóa trong quá trình đăng ký thuê bao đến việc quản lý bí danh, chính sách truy cập và xóa khóa.\nDịch vụ này đạt được khả năng sử dụng khóa an toàn, có thể mở rộng trên toàn tổ chức thông qua quyền truy cập AWS Identity and Access Management (IAM) liên tài khoản. Nó cấp cho các dịch vụ khác (ví dụ: dịch vụ dành cho khách hàng trong Tài khoản B trong hình sau) quyền thực hiện các hoạt động mã hóa cụ thể bằng khóa KMS dành riêng cho đối tượng thuê thông qua phân quyền vai trò. Việc triển khai này tuân thủ các thông lệ tốt nhất của AWS về truy cập liên tài khoản, sử dụng IAM và AWS Security Token Service (AWS STS) giả định vai trò như được mô tả trong the AWS documentation và điều này blog post.\nQuản lý khóa tập trung trong thực tế: Mã hóa dữ liệu khách hàng Chúng ta hãy cùng xem xét cách thức hoạt động này trong thực tế với một kịch bản phổ biến:\nDịch vụ A: Dịch vụ quản lý khóa thuê tập trung của chúng tôi trong Tài khoản A Dịch vụ B: Khối lượng công việc hướng tới khách hàng đang chạy trong Tài khoản B Khi khách hàng tương tác với Dịch vụ B, họ cần lưu trữ thông tin nhạy cảm một cách an toàn, cho dù đó là bí mật, khóa API hay thông tin giấy phép trong bảng DynamoDB. Thay vì dựa vào khóa KMS dùng chung hoặc mã hóa mặc định, Dịch vụ B mã hóa dữ liệu bằng khóa KMS chuyên dụng của khách hàng do Dịch vụ A quản lý. Quy trình này hoạt động thông qua AWS Identity and Access Management (IAM) ủy quyền vai trò. Dịch vụ B tạm thời đảm nhận một vai trò (ServiceARole) trong Tài khoản A, nhận được các quyền chi tiết, được thu hẹp phạm vi cho khóa KMS của đối tượng thuê cụ thể. Với các thông tin xác thực tạm thời này, Dịch vụ B có thể thực hiện các hoạt động mã hóa phía máy khách trên thông tin nhạy cảm bằng AWS SDK hoặc AWS Encryption SDK.\nTrong bài đăng trên blog này, chúng tôi đã sử dụng Boto3. Đối với các trường hợp sử dụng nâng cao hơn yêu cầu data key caching hoặc keyrings, sử dụng AWS Encryption SDK.\nHướng dẫn giải pháp Hãy cùng mở rộng các khía cạnh kỹ thuật của giải pháp được mô tả ở trên. Giả định và định nghĩa:\nCác yêu cầu đến bao gồm một tiêu đề xác thực với JSON Web Token (JWT) bao gồm dữ liệu xác định người thuê OF hiện tại. Các mã thông báo này được ký bởi nhà cung cấp danh tính, đảm bảo JWT không thể bị sửa đổi và danh tính người thuê có thể được tin cậy. Tài khoản A: Dịch vụ quản lý khóa tập trung. Tài khoản B: Dịch vụ kinh doanh phục vụ nhu cầu của khách hàng. alias/customer- là định dạng của các bí danh trong tài khoản A. Mỗi bí danh trỏ đến khóa KMS của khách hàng tương ứng được xác định theo giá trị của . Dịch vụ A tạo các bí danh này trong quá trình đưa người thuê lên hệ thống và xóa chúng trong quá trình đưa người thuê rời khỏi hệ thống. ServiceARole: Một vai trò trong Tài khoản A có thể mã hóa và giải mã khóa KMS có tiền tố bí danh là alias/customer-*. Các quyền được thu hẹp phạm vi hơn nữa bằng cách sử dụng session policies khi ServiceBRole giả định ServiceARole. ServiceBRole:Một vai trò trong Tài khoản B có thể đảm nhận ServiceARole trong Tài khoản A để có quyền truy cập vào khóa KMS của khách hàng. Đây sẽ là AWS Lambda vai trò thực thi của hàm. Lưu ý rằng lớp tính toán của Dịch vụ B trong trường hợp này là một hàm Lambda, nhưng giải pháp này cũng được áp dụng cho các kiến ​​trúc tính toán khác. Hãy cùng xem xét kỹ năng hơn về xử lý luồng:\nSử dụng dịch vụ với JWT Khách hàng thuộc về một đối tượng thuê đăng nhập vào giải pháp SaaS và được cấp JWT để xác định đối tượng thuê của mình bằng ID đối tượng thuê (). Khách hàng thực hiện một hành động trong ServiceB và gửi thông tin nhạy cảm.\nServiceB xử lý yêu cầu (trong hàm Lambda), xác minh mã thông báo JWT và muốn:\nMã hóa dữ liệu nhạy cảm của khách hàng Lưu dữ liệu được mã hóa cùng với dữ liệu khác trong bảng DynamoDB Đảm nhận vai trò Trong ví dụ này, hàm Lambda sử dụng execution role thông tin đăng nhập để đảm nhận vai trò Dịch vụ trong tài khoản Dịch vụ. Một cách khác để cấp quyền truy cập liên tài khoản vào khóa KMS là sử dụng KMS grants,để tìm hiểu thêm, hãy xem Allowing users in other accounts to use a KMS key.\nHãy cùng xem lại chính sách IAM ServiceRoleA:\nCấp quyền mã hóa và giải mã cho khóa KMS bằng cách sử dụng alias/customer-* mẫu. { \u0026ldquo;Version\u0026rdquo;: \u0026ldquo;2012-10-17\u0026rdquo;, \u0026ldquo;Statement\u0026rdquo;: [ { \u0026ldquo;Sid\u0026rdquo;: \u0026ldquo;AllowKMSByAlias\u0026rdquo;, \u0026ldquo;Effect\u0026rdquo;: \u0026ldquo;Allow\u0026rdquo;, \u0026ldquo;Action\u0026rdquo;: [ \u0026ldquo;kms:Encrypt\u0026rdquo;, \u0026ldquo;kms:Decrypt\u0026rdquo;, \u0026ldquo;kms:GenerateDataKey*\u0026rdquo; ], \u0026ldquo;Resource\u0026rdquo;: \u0026ldquo;\u0026rdquo;, \u0026ldquo;Condition\u0026rdquo;: { \u0026ldquo;StringLike\u0026rdquo;: { \u0026ldquo;kms:RequestAlias\u0026rdquo;: \u0026ldquo;alias/customer-\u0026rdquo; } } } ] }\nĐể mã hóa bí mật của người thuê một cách an toàn và trên quy mô lớn, chúng tôi cấp cho các vai trò ứng dụng quyền truy cập liên tài khoản vào khóa KMS—nhưng chỉ thông qua bí danh của họ, bí danh này ánh xạ tới mã định danh người thuê có trong mã thông báo xác thực JWT của họ, thực thi sự cô lập mạnh mẽ.\nBạn có thể kiểm soát quyền truy cập vào khóa KMS dựa trên các bí danh được liên kết với mỗi khóa KMS. Để thực hiện việc này, hãy sử dụng kms:RequestAlias và kms:ResourceAliases các phím điều kiện như được chỉ định trong Use aliases to control access to KMS keys.\nNgoài ra, chính sách quan hệ tin cậy của ServiceARole cho phép ServiceBRole trong tài khoản B đảm nhận: { \u0026ldquo;Version\u0026rdquo;: \u0026ldquo;2012-10-17\u0026rdquo;, \u0026ldquo;Statement\u0026rdquo;: [ { \u0026ldquo;Effect\u0026rdquo;: \u0026ldquo;Allow\u0026rdquo;, \u0026ldquo;Principal\u0026rdquo;: { \u0026ldquo;AWS\u0026rdquo;: \u0026ldquo;arn:aws:iam::\u0026lt;ACCOUNT_B_ID\u0026gt;:role/ServiceBRole\u0026rdquo; }, \u0026ldquo;Action\u0026rdquo;: \u0026ldquo;sts:AssumeRole\u0026rdquo; } ] }\nTùy thuộc vào môi trường của bạn, bạn có thể thêm các điều kiện bổ sung vào chính sách ủy thác này để thu hẹp hơn nữa phạm vi những người có thể đảm nhận vai trò này. Để biết thêm thông tin, hãy xem IAM and AWS STS condition context keys.\nSau đó, mỗi khóa KMS do khách hàng quản lý sẽ có chính sách sau. Ví dụ: khóa KMS cho khách hàng có : 123 sẽ có chính sách hạn chế quyền truy cập vào khóa bằng cách sử dụng bí danh khách hàng cụ thể và chỉ thông qua ServiceRoleA. { \u0026ldquo;Version\u0026rdquo;: \u0026ldquo;2012-10-17\u0026rdquo;, \u0026ldquo;Id\u0026rdquo;: \u0026ldquo;TenantKeyPolicy\u0026rdquo;, \u0026ldquo;Statement\u0026rdquo;: [ { \u0026ldquo;Sid\u0026rdquo;: \u0026ldquo;AllowServiceARoleViaAlias\u0026rdquo;, \u0026ldquo;Effect\u0026rdquo;: \u0026ldquo;Allow\u0026rdquo;, \u0026ldquo;Principal\u0026rdquo;: { \u0026ldquo;AWS\u0026rdquo;: \u0026ldquo;arn:aws:iam::\u0026lt;ACCOUNT_A_ID\u0026gt;:role/ServiceARole\u0026rdquo; }, \u0026ldquo;Action\u0026rdquo;: [ \u0026ldquo;kms:Encrypt\u0026rdquo;, \u0026ldquo;kms:Decrypt\u0026rdquo;, \u0026ldquo;kms:GenerateDataKey*\u0026rdquo; ], \u0026ldquo;Resource\u0026rdquo;: \u0026ldquo;*\u0026rdquo;, \u0026ldquo;Condition\u0026rdquo;: { \u0026ldquo;StringLike\u0026rdquo;: { \u0026ldquo;kms:RequestAlias\u0026rdquo;: \u0026ldquo;alias/customer-123\u0026rdquo; } } } ] }\nSau đây là ví dụ mã Python minh họa cách Dịch vụ B tự động đảm nhận vai trò trong Tài khoản A để mã hóa dữ liệu cho một đối tượng thuê cụ thể bằng chính sách IAM có phạm vi phiên, chính sách này chỉ cho phép truy cập vào bí danh khóa KMS của đối tượng thuê đó.\nMẫu này tuân theo các nguyên tắc tương tự được nêu trong Isolating SaaS Tenants with Dynamically Generated IAM Policies. Ý tưởng là tạo và đính kèm một chính sách IAM dành riêng cho đối tượng thuê trong thời gian chạy, cấp các quyền tối thiểu cần thiết để vận hành trên các tài nguyên do đối tượng thuê sở hữu—trong trường hợp này là một bí danh khóa KMS. Thông tin xác thực sẽ cho phép hàm Lambda chỉ sử dụng khóa KMS thuộc về khách hàng (được xác định bởi tenant_id).\nChúng tôi sẽ gọi assume_role_for_tenant cho mọi người thuê nhà.\nTình trạng của \u0026ldquo;StringEquals\u0026rdquo; - \u0026ldquo;kms:RequestAlias\u0026rdquo;: alias là công thức kỳ diệu của AWS STS, nó hạn chế ServiceB sử dụng bí danh của người thuê hiện tại trong các cuộc gọi SDK mã hóa của nó và dựa vào alias authorization\nimport boto3 def assume_role_for_tenant(tenant_id: str): alias = f\u0026quot;alias/customer-{tenant_id}\u0026quot; # Session policy scoped to only the specific alias session_policy = { \u0026ldquo;Version\u0026rdquo;: \u0026ldquo;2012-10-17\u0026rdquo;, \u0026ldquo;Statement\u0026rdquo;: [ { \u0026ldquo;Effect\u0026rdquo;: \u0026ldquo;Allow\u0026rdquo;, \u0026ldquo;Action\u0026rdquo;: [ \u0026ldquo;kms:Encrypt\u0026rdquo;, \u0026ldquo;kms:Decrypt\u0026rdquo;, \u0026ldquo;kms:GenerateDataKey*\u0026rdquo; ], \u0026ldquo;Resource\u0026rdquo;: \u0026ldquo;*\u0026rdquo;, \u0026ldquo;Condition\u0026rdquo;: { \u0026ldquo;StringEquals\u0026rdquo;: { \u0026ldquo;kms:RequestAlias\u0026rdquo;: alias } } } ] } # Assume ServiceARole in Account A with inline session policy sts = boto3.client(\u0026ldquo;sts\u0026rdquo;) assumed = sts.assume_role( RoleArn=\u0026ldquo;arn:aws:iam::\u0026lt;ACCOUNT_A_ID\u0026gt;:role/ServiceARole\u0026rdquo;, RoleSessionName=f\u0026quot;Tenant{tenant_id}Session\u0026quot;, Policy=json.dumps(session_policy) ) return assumed[\u0026ldquo;Credentials\u0026rdquo;]\nMã hóa dữ liệu và lưu trong DynamoDB Bây giờ, việc còn lại cần làm là sử dụng thông tin xác thực vai trò đã được giả định và sử dụng AWS SDK để mã hóa dữ liệu khách hàng nhạy cảm và lưu trữ dữ liệu đó trong bảng DynamoDB.\nUse temporary credentials to create a KMS client creds = assume_role_for_tenant(tenant_id, plaintext)\rkms = boto3.client(\r\u0026quot;kms\u0026quot;,\rregion_name=\u0026quot;us-east-1\u0026quot;,\raws_access_key_id=creds[\u0026quot;AccessKeyId\u0026quot;],\raws_secret_access_key=creds[\u0026quot;SecretAccessKey\u0026quot;],\raws_session_token=creds[\u0026quot;SessionToken\u0026quot;]\r)\r# Encrypt using the alias\rresponse = kms.encrypt(\rKeyId= f\u0026quot;alias/customer-{tenant_id}\u0026quot;\rPlaintext=plaintext\r)\r# store response[\u0026quot;CiphertextBlob\u0026quot;] in DynamoDB table\rBài viết này không đề cập đến việc cô lập giữa các dịch vụ khác nhau, mà chỉ đề cập đến việc cô lập giữa các đối tượng thuê. Nếu cần cô lập dịch vụ như vậy, bạn có thể sử dụng encryption context, một tập hợp tùy chọn các cặp khóa/giá trị không bí mật có thể chứa thông tin ngữ cảnh bổ sung về dữ liệu, ví dụ như mã định danh dịch vụ. Điều này giúp đảm bảo rằng các dịch vụ chỉ có thể mã hóa hoặc giải mã dữ liệu bằng ngữ cảnh mã hóa dịch vụ tương ứng.\nLợi ích của quản lý khóa tập trung Hãy cùng xem giải pháp này giải quyết những thách thức trước đây của chúng ta như thế nào.\nThiết kế cô lập người thuê nhà Mặc dù giảm tổng số khóa KMS, chúng tôi vẫn duy trì việc cô lập nghiêm ngặt đối với người thuê. Dữ liệu nhạy cảm của mỗi khách hàng vẫn được mã hóa bằng khóa chuyên dụng, được xác định bằng một bí danh duy nhất (alias/customer-). Quyền kiểm soát truy cập vào khóa thuê được quản lý chặt chẽ thông qua việc phân quyền vai trò IAM, tuân theo các nguyên tắc đặc quyền tối thiểu:\nDịch vụ A kiểm soát độc quyền việc quản lý khóa KMS của người thuê. Dịch vụ B chỉ có thể đảm nhận vai trò cấp quyền truy cập mã hóa, giải mã và GenerateDataKey bị hạn chế cho khóa do khách hàng quản lý được chỉ định bởi bí danh: alias/customer-. Quản lý chi phí tối ưu Phương pháp của chúng tôi giúp giảm đáng kể chi phí bằng cách chuyển từ nhiều khóa KMS dành riêng cho từng dịch vụ cho mỗi đối tượng thuê sang một khóa KMS duy nhất cho mỗi đối tượng thuê, được chia sẻ an toàn trên nhiều dịch vụ và môi trường. Cách tiếp cận này giới thiệu một tài khoản tập trung mới (Tài khoản A) cung cấp quyền truy cập vào khóa mã hóa trong những trường hợp phù hợp. Điều quan trọng là phải hiểu AWS STS limits, cụ thể cho các cuộc gọi và xem xét các cơ chế lưu trữ thông tin xác thực IAM tạm thời nếu những giới hạn đó trở thành nút thắt cổ chai. Ngoài ra, nếu KMS limits là một nút thắt cổ chai, hãy cân nhắc sử dụng data key caching bằng cách sử dụng AWS Encryption SDK.\nHoạt động và quản trị hợp lý Bằng cách tập trung quản lý khóa trong Dịch vụ A, bạn có thể đạt được:\nQuản lý vòng đời khóa KMS nhất quán trên toàn tổ chức Cải thiện khả năng kiểm toán bằng cách sử dụng AWS CloudTrail để hiểu rõ hơn về các mẫu truy cập chính theo dịch vụ Giảm chi phí hoạt động Giám sát tuân thủ đơn giản hóa Sự phức tạp bổ sung duy nhất là việc thiết lập phân quyền vai trò liên tài khoản ban đầu giữa Dịch vụ A và các dịch vụ khác. Sau khi được thiết lập, khuôn khổ này có thể được mở rộng để đáp ứng các đối tượng thuê bao và dịch vụ mới.\nTốt nhất là đóng gói logic đảm nhiệm vai trò, tạo chính sách và khởi tạo máy khách AWS SDK trong một SDK dùng chung cho toàn tổ chức. Sự trừu tượng hóa này giúp giảm tải nhận thức cho các nhà phát triển và giảm thiểu rủi ro cấu hình sai. Bạn có thể tiến xa hơn bằng cách cung cấp các hàm tiện ích cấp cao như encrypt_tenant_data() và decrypt_tenant_data(), ẩn đi sự phức tạp tiềm ẩn trong khi thúc đẩy các mô hình sử dụng an toàn và nhất quán trong toàn nhóm.\nPhần kết luận Trong bài viết này, chúng tôi đã khám phá một phương pháp hiệu quả để quản lý khóa mã hóa trong môi trường SaaS đa thuê bao thông qua tập trung hóa. Chúng tôi đã xem xét những thách thức phổ biến mà các nhà cung cấp SaaS đang phát triển phải đối mặt, bao gồm sự gia tăng khóa, chi phí tăng cao và tính phức tạp trong vận hành trên nhiều tài khoản và dịch vụ AWS. Giải pháp tập trung hóa quản lý khóa này sử dụng các phương pháp hay nhất của AWS để phân quyền vai trò IAM và truy cập liên tài khoản, cho phép các tổ chức duy trì bảo mật và tuân thủ đồng thời giảm thiểu chi phí vận hành. Bằng cách triển khai phương pháp này, các nhà cung cấp SaaS hoặc các tổ chức lớn đang gặp phải những thách thức tương tự có thể quản lý hiệu quả cơ sở hạ tầng mã hóa của họ khi mở rộng quy mô, mà không ảnh hưởng đến bảo mật hoặc tăng tính phức tạp.\nVề các tác giả Itay Meller là Kiến trúc sư Giải pháp Chuyên gia Bảo mật tại AWS, với nền tảng vững chắc về Nghiên cứu \u0026amp; Phát triển an ninh mạng và vai trò lãnh đạo tại nhiều công ty tập trung vào bảo mật. Với chuyên môn sâu rộng về bảo mật đám mây, Itay giúp các tổ chức áp dụng và mở rộng môi trường AWS một cách an toàn bằng cách giải quyết các thách thức phức tạp về bảo mật và tuân thủ.\nRan Isenberg là một Anh hùng Không máy chủ của AWS, Kiến trúc sư Phần mềm Chính tại CyberArk, một blogger và diễn giả. Anh duy trì blog RanTheBuilder.cloud, nơi anh chia sẻ kiến ​​thức và kinh nghiệm trong thế giới Không máy chủ.\nYossi Lagstein là Kiến trúc sư Giải pháp Cấp cao tại Amazon Web Services. Yossi có hơn 30 năm kinh nghiệm trong vai trò chuyên gia và quản lý phát triển các thành phần cơ sở hạ tầng cho nhiều dự án và sản phẩm. Yossi hỗ trợ khách hàng AWS phát triển, thiết kế và xây dựng các giải pháp được kiến ​​trúc tốt. Ngoài giờ làm việc, Yossi thích chạy bộ, bơi lội và đi bộ đường dài.\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/5-workshop/5.3-deploy-infrastructure/",
	"title": "Triển khai Infrastructure với CloudFormation",
	"tags": [],
	"description": "",
	"content": "Tổng quan Trong bước này, bạn sẽ triển khai toàn bộ hạ tầng AWS bằng CloudFormation template. Template sẽ tạo VPC, subnets, EC2 instances, RDS database, Load Balancer, S3 buckets, CloudFront distribution và tất cả các tài nguyên cần thiết.\nValidate Template Trước khi triển khai, validate template để đảm bảo không có lỗi cú pháp:\ncd aws aws cloudformation validate-template \\ --template-body file://infrastructure.yaml \\ --region ap-southeast-1 Kết quả mong đợi: Thông tin về parameters, outputs và description của template.\nTriển khai Stack Cách 1: Sử dụng Deploy Script (Khuyên dùng) Windows:\ncd aws deploy.bat create Linux/Mac:\ncd aws chmod +x deploy.sh ./deploy.sh create Script sẽ tự động:\nValidate template Create CloudFormation stack Theo dõi tiến trình deployment Hiển thị outputs khi hoàn thành Cách 2: Sử dụng AWS CLI aws cloudformation create-stack \\ --stack-name workshop-aws-dev \\ --template-body file://infrastructure.yaml \\ --parameters file://parameters.json \\ --capabilities CAPABILITY_NAMED_IAM \\ --region ap-southeast-1 Theo dõi Tiến trình Qua AWS Console Mở CloudFormation Console Chọn stack workshop-aws-dev Tab Events: Xem các resources đang được tạo Tab Resources: Xem danh sách resources Tab Outputs: Xem outputs (sau khi hoàn thành) Qua AWS CLI # Kiểm tra status aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].StackStatus\u0026#39; # Xem events aws cloudformation describe-stack-events \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --max-items 10 Thời gian Deployment Quá trình tạo stack mất khoảng 15-20 phút:\nVPC và Networking: 2-3 phút NAT Gateway: 2-3 phút RDS Database: 5-7 phút EC2 Auto Scaling Group: 3-5 phút Load Balancer: 2-3 phút CloudFront Distribution: 5-10 phút VPC Endpoints: 2-3 phút Xem Outputs Sau khi stack tạo thành công (Status: CREATE_COMPLETE), lấy outputs:\naws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs\u0026#39; \\ --output table Các Outputs quan trọng:\nOutput Key Mô tả Ví dụ VPCId VPC ID vpc-0123456789abcdef0 FrontendBucketName S3 bucket cho frontend workshop-aws-dev-frontend-123456789012-ap-southeast-1 CloudFrontDomainName CloudFront URL d1234567890abc.cloudfront.net ALBDNSName Load Balancer DNS workshop-aws-dev-alb-123456789.ap-southeast-1.elb.amazonaws.com RDSEndpoint Database endpoint workshop-aws-dev-db.xxxxx.ap-southeast-1.rds.amazonaws.com APIGatewayURL API Gateway URL https://xxxxx.execute-api.ap-southeast-1.amazonaws.com/dev CognitoUserPoolId Cognito User Pool ID ap-southeast-1_xxxxxxxxx Lưu các giá trị này - bạn sẽ cần chúng cho các bước tiếp theo!\nKiểm tra Resources đã tạo 1. VPC và Networking # Lấy VPC ID VPC_ID=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`VPCId`].OutputValue\u0026#39; \\ --output text) # Xem VPC details aws ec2 describe-vpcs --vpc-ids $VPC_ID --region ap-southeast-1 # Xem Subnets aws ec2 describe-subnets \\ --filters \u0026#34;Name=vpc-id,Values=$VPC_ID\u0026#34; \\ --region ap-southeast-1 \\ --query \u0026#39;Subnets[*].[SubnetId,CidrBlock,AvailabilityZone,Tags[?Key==`Name`].Value|[0]]\u0026#39; \\ --output table 2. EC2 Instances # Xem EC2 instances trong Auto Scaling Group aws ec2 describe-instances \\ --filters \u0026#34;Name=tag:aws:cloudformation:stack-name,Values=workshop-aws-dev\u0026#34; \\ --region ap-southeast-1 \\ --query \u0026#39;Reservations[*].Instances[*].[InstanceId,State.Name,PrivateIpAddress,PublicIpAddress]\u0026#39; \\ --output table 3. RDS Database # Xem RDS instance aws rds describe-db-instances \\ --db-instance-identifier workshop-aws-dev-db \\ --region ap-southeast-1 \\ --query \u0026#39;DBInstances[0].[DBInstanceIdentifier,DBInstanceStatus,Endpoint.Address,Endpoint.Port]\u0026#39; \\ --output table 4. Load Balancer # Xem ALB aws elbv2 describe-load-balancers \\ --names workshop-aws-dev-alb \\ --region ap-southeast-1 \\ --query \u0026#39;LoadBalancers[0].[LoadBalancerName,DNSName,State.Code]\u0026#39; \\ --output table 5. S3 Buckets # List S3 buckets aws s3 ls | grep workshop-aws-dev 6. CloudFront Distribution # Lấy Distribution ID DIST_ID=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`CloudFrontDistributionId`].OutputValue\u0026#39; \\ --output text) # Xem distribution status aws cloudfront get-distribution --id $DIST_ID \\ --query \u0026#39;Distribution.[Id,Status,DomainName]\u0026#39; \\ --output table Troubleshooting Stack Creation Failed Nếu stack creation bị lỗi:\nXem Events để tìm lỗi: aws cloudformation describe-stack-events \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;StackEvents[?ResourceStatus==`CREATE_FAILED`].[LogicalResourceId,ResourceStatusReason]\u0026#39; \\ --output table Các lỗi thường gặp: Lỗi: \u0026ldquo;Key pair does not exist\u0026rdquo;\nKiểm tra tên key pair trong parameters.json Đảm bảo key pair tồn tại trong region ap-southeast-1 Lỗi: \u0026ldquo;Invalid AMI ID\u0026rdquo;\nCập nhật AMI ID trong infrastructure.yaml Sử dụng AMI ID phù hợp với region Lỗi: \u0026ldquo;Insufficient permissions\u0026rdquo;\nKiểm tra IAM permissions của user Cần quyền CloudFormation, EC2, VPC, RDS, S3, IAM Lỗi: \u0026ldquo;Resource limit exceeded\u0026rdquo;\nKiểm tra service quotas trong AWS account Request tăng limits nếu cần Rollback và thử lại: # Xóa stack bị lỗi aws cloudformation delete-stack \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 # Đợi stack bị xóa hoàn toàn aws cloudformation wait stack-delete-complete \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 # Thử tạo lại aws cloudformation create-stack \\ --stack-name workshop-aws-dev \\ --template-body file://infrastructure.yaml \\ --parameters file://parameters.json \\ --capabilities CAPABILITY_NAMED_IAM \\ --region ap-southeast-1 Xác nhận Deployment thành công Checklist để xác nhận infrastructure đã sẵn sàng:\nStack status là CREATE_COMPLETE VPC và subnets đã được tạo EC2 instances đang chạy (State: running) RDS database status là available Load Balancer status là active S3 buckets đã được tạo CloudFront distribution status là Deployed Tất cả outputs đã có giá trị Tiếp theo Sau khi infrastructure đã sẵn sàng, bạn có thể:\n➡️ Cấu hình và Triển khai Backend Application\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/4-eventparticipated/",
	"title": "Các events đã tham gia",
	"tags": [],
	"description": "",
	"content": " Trong phần này, các bạn cần liệt kê và mô tả chi tiết các sự kiện (event) mà mình đã tham gia trong suốt quá trình thực tập hoặc làm việc.\nMỗi sự kiện nên được trình bày theo định dạng Event 1, Event 2, Event 3…, kèm theo các thông tin:\nTên sự kiện Thời gian tổ chức Địa điểm (nếu có) Vai trò của bạn trong sự kiện Mô tả ngắn gọn nội dung và hoạt động chính trong sự kiện Kết quả hoặc giá trị đạt được Việc liệt kê này giúp thể hiện rõ sự tham gia thực tế của bạn, cũng như các kỹ năng mềm và kinh nghiệm bạn đã tích lũy qua từng sự kiện.\nTrong quá trình thực tập, em đã tham gia 2 events, mỗi sự kiện đều mang lại những kiến thức hữu ích, kinh nghiệm thực tế và những khoảnh khắc vô cùng đáng nhớ.\nEvent 1 Tên sự kiện: AWS Mastery #2 – CloudFormation \u0026amp; CDK Workshop\nThời gian: 17/11/2025\nĐịa điểm: Sự kiện online (AWS Community Vietnam)\nVai trò trong sự kiện: Người tham dự\nMô tả nội dung:\nSự kiện tập trung vào Infrastructure as Code (IaC) với CloudFormation và AWS CDK. Trong workshop, diễn giả trình bày tư duy IaC, phân tích cấu trúc CloudFormation template, demo cdk deploy, cdk diff, hướng dẫn triển khai hạ tầng bằng code, cùng nội dung bổ trợ về Docker, containerization và các dịch vụ như ECS, EKS và App Runner.\nGiá trị đạt được:\n- Hiểu rõ cách vận hành IaC, drift detection và best practices của CloudFormation.\n- Nắm được CDK constructs L1–L3 và quy trình triển khai hạ tầng tự động.\n- Có cái nhìn thực tế về container orchestration trên AWS.\n- Tăng khả năng phân tích – triển khai DevOps pipelines sử dụng IaC.\nEvent 2 Tên sự kiện: AWS Cloud Club – First Cloud AI Journey Workshop\nThời gian: 29/11/2025\nĐịa điểm: Sự kiện offline nội bộ các Cloud Clubs (HCM)\nVai trò trong sự kiện: Người tham dự\nMô tả nội dung:\nWorkshop giới thiệu cộng đồng AWS Cloud Club, lộ trình học Cloud + AI cho sinh viên, cùng chia sẻ hành trình học AWS từ các Cloud Club Captains. Nội dung xoay quanh cloud fundamentals, AI/ML cơ bản, GenAI, tài liệu học, cách thi chứng chỉ và kinh nghiệm tìm cơ hội nghề nghiệp.\nGiá trị đạt được:\n- Hiểu được tầm quan trọng của nền tảng cloud trước khi học AI/GenAI.\n- Xây dựng được roadmap học AWS rõ ràng (Cloud Practitioner → SA Associate).\n- Học phương pháp tự học hiệu quả và tránh các sai lầm của người mới.\n- Mở rộng network với cộng đồng Cloud Club và các bạn đam mê AI/Cloud.\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/3-blogstranslated/",
	"title": "Các bài blogs đã dịch",
	"tags": [],
	"description": "",
	"content": "Blog 1 - Accelerate your Cloud Strategy with Megaport\u0026rsquo;s 25 Gbps Hosted AWS Direct Connect Blog này giới thiệu cách tăng tốc chiến lược đám mây bằng AWS Hosted Direct Connect 25 Gbps từ Megaport. Bạn sẽ tìm hiểu lợi ích về hiệu suất, khả năng mở rộng và kết nối mạng an toàn giữa on-premises và cloud, cách triển khai và quản lý kết nối này để tối ưu hóa chi phí và hiệu quả vận hành.\nBlog 2 - Simplify multi-subscriber encryption with cost-effective AWS KMS key strategies Blog này hướng dẫn cách đơn giản hóa việc mã hóa đa thuê bao bằng chiến lược khóa AWS KMS tiết kiệm chi phí. Bạn sẽ tìm hiểu cách quản lý và phân phối khóa KMS hiệu quả, tối ưu hóa chi phí, đảm bảo bảo mật dữ liệu theo từng tenant mà vẫn duy trì hiệu suất và khả năng mở rộng trong môi trường đa khách hàng.\nBlog 3 - Open Protocol for Agent Interoperability Part 4: A2A Agent Communication Blog này giới thiệu giao thức Agent-to-Agent (A2A) cho phép các tác nhân AI giao tiếp trực tiếp với nhau. Bạn sẽ tìm hiểu cách AWS hỗ trợ A2A thông qua Strands Agents SDK, các tính năng chính như Thẻ Tác nhân, thực hiện nhiệm vụ có cấu trúc, nhiều lựa chọn vận chuyển và bảo mật A2A. Bài viết cũng minh họa ví dụ triển khai agent HR và agent Thông tin Nhân viên sử dụng A2A, cùng phản hồi từ khách hàng về khả năng tương tác đa tác nhân.\nBlog 4 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 5 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 6 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/3-blogstranslated/3.3-blog3/",
	"title": "Blog 3",
	"tags": [],
	"description": "",
	"content": "Giao thức mở cho khả năng tương tác của tác nhân Phần 4: Giao tiếp giữa các tác nhân trên A2A Giới thiệu: Chào mừng đến với Phần 4 của loạt bài viết trên blog của chúng tôi về Open Protocols for Agent Interoperability nơi chúng tôi sẽ đề cập đến giao thức Agent-to-Agent (A2A), sự tham gia của AWS với Linux Foundation-based open standard, và sự hỗ trợ của chúng tôi dành cho A2A trong Strands Agents SDK. Dưới đây là những gì chúng tôi đã đề cập cho đến nay:\nPart 1: Giao thức ngữ cảnh mô hình (MCP) tạo điều kiện thuận lợi cho giao tiếp giữa các tác nhân như thế nào và AWS đã nỗ lực cải tiến thông số kỹ thuật MCP ra sao để hỗ trợ tốt hơn cho giao tiếp giữa các tác nhân. Part 2: Chi tiết về các bản cập nhật thông số kỹ thuật MCP gần đây liên quan đến Xác thực. Part 3: Làm thế nào để xây dựng hệ thống liên tác nhân với cái mới Strands Agents SDK và MCP Giao thức chuẩn là cách chính để kết nối các dịch vụ mạng. Thông thường, có nhiều giao thức khác nhau để giải quyết các cách kết nối mạng khác nhau. Ở tầng mạng, có hai giao thức chính: TCP và UDP. Mỗi giao thức phù hợp với các nhu cầu cụ thể và không giao thức nào mang tính phổ quát. Điều này cũng đúng khi kết nối các tác nhân AI. Trong phần 4 của loạt bài viết về giao tiếp giữa các tác nhân, chúng tôi sẽ giới thiệu về A2A, cách sử dụng nó để giao tiếp giữa các tác nhân và cách AWS hỗ trợ khách hàng xây dựng hệ thống với A2A.\nMCP ban đầu được tạo ra để kết nối các tác nhân với các công cụ, nhưng cũng có thể được sử dụng để kết nối các tác nhân với nhau. A2A được tạo ra để kết nối các tác nhân với nhau và cũng có thể được sử dụng kết hợp với MCP để các tác nhân giao tiếp với các công cụ. Việc sử dụng giao thức nào cho kết nối tác nhân với tác nhân tùy thuộc vào nhu cầu của bạn. AWS hỗ trợ cả hai giao thức, cho phép khách hàng sử dụng MCP, A2A hoặc kết hợp cả hai để triển khai mã của họ trên AWS.\nKhi các giao thức liên tác nhân và các khuôn khổ xung quanh chúng phát triển, nhiều khả năng chúng sẽ trở nên giống như TCP \u0026amp; UDP, nơi hầu hết các nhà phát triển tập trung nhiều hơn vào việc xây dựng các tác nhân của họ thay vì các giao thức nền tảng. Bước đầu tiên hướng tới điều đó là các khuôn khổ tác nhân hỗ trợ các giao thức và xây dựng hệ sinh thái xung quanh chúng. Tại AWS, chúng tôi đã thực hiện bước đầu tiên này bằng cách tham gia cộng đồng tiêu chuẩn A2A và bổ sung hỗ trợ cho A2A trong SDK Strands Agents nguồn mở của mình. Swami Sivasubramanian, Phó Chủ tịch AWS Agentic AI, tóm tắt nỗ lực này:\nTại AWS, chúng tôi tin rằng AI agentic sẽ đóng vai trò quan trọng đối với hầu hết mọi trải nghiệm của khách hàng. Chúng tôi hoan nghênh A2A tham gia Quỹ Linux và kỳ vọng điều này sẽ tạo ra nhiều cơ hội hơn cho bất kỳ ai xây dựng ứng dụng AI. Chúng tôi dự định hỗ trợ cộng đồng bằng các đóng góp dự án và tiếp cận bộ khung, giao thức và dịch vụ agentic rộng lớn và chuyên sâu nhất.\nTương tự như cách chúng tôi đang hỗ trợ phát triển MCP, chúng tôi cũng đang hỗ trợ phát triển A2A để đáp ứng nhu cầu của khách hàng. Chúng tôi dự định sẽ tập trung vào một số lĩnh vực để A2A hoạt động hiệu quả trên AWS, bao gồm hỗ trợ Amazon Bedrock AgentCore, mở rộng giao thức A2A cho lưu trữ tác vụ tạm thời và SigV4, cải thiện quản lý đa tác vụ và cải tiến Java A2A SDK.\nTổng quan về A2A Giao thức A2A giải quyết một thách thức quan trọng trong bối cảnh AI. Nó cho phép các tác nhân AI được xây dựng trên các nền tảng đa dạng, được vận hành bởi các công ty khác nhau trên các máy chủ riêng biệt, giao tiếp và cộng tác hiệu quả — với tư cách là tác nhân, chứ không chỉ là công cụ. A2A đại diện cho một bước tiến đáng kể trong việc tạo ra các hệ thống AI có khả năng tương tác, hoạt động cùng nhau xuyên biên giới tổ chức. Giao thức này được hỗ trợ bởi một hệ sinh thái đối tác đang phát triển, bao gồm hơn 50 công ty công nghệ như Google, Atlassian, Confluent, Salesforce, SAP và MongoDB.\nTrước A2A, các tổ chức phải đối mặt với những thách thức đáng kể trong việc triển khai các hệ thống AI đa tác tử ở quy mô lớn. Nếu không có giao thức chuẩn hóa, mỗi cặp tác tử đều yêu cầu mã tích hợp tùy chỉnh, dẫn đến chi phí phát triển quá mức và độ phức tạp trong bảo trì. Điều này tạo ra các hệ thống AI bị cô lập, nơi các tác tử chuyên biệt không thể dễ dàng chia sẻ năng lực hoặc phối hợp thực hiện các nhiệm vụ phức tạp. Giao thức này cung cấp cho các tác tử một ngôn ngữ chung, cho phép chúng duy trì tính tự chủ và các kỹ năng chuyên biệt trong khi hợp tác - các tác tử giao tiếp với nhau như những người ngang hàng, chứ không chỉ là những công cụ đơn thuần. Sự khác biệt này rất quan trọng vì nó cho phép các tác tử tham gia vào các tương tác qua lại phức tạp, đàm phán các yêu cầu nhiệm vụ và duy trì khả năng ra quyết định độc lập trong khi hướng tới các mục tiêu chung.\nĐối với khách hàng AWS, A2A cung cấp một số tính năng hấp dẫn phù hợp với yêu cầu của doanh nghiệp. Giao thức này cho phép các khả năng của doanh nghiệp bao gồm phát hiện tác nhân an toàn thông qua thẻ tác nhân được chuẩn hóa, cơ chế xác thực và ủy quyền cho quyền truy cập được kiểm soát, hỗ trợ nhiều phương thức giao tiếp (văn bản, biểu mẫu, phương tiện) và khả năng cho phép các tác nhân cộng tác trong các tác vụ dài hạn mà không tiết lộ trạng thái nội bộ hoặc chi tiết triển khai của họ.\nA2A giải quyết những thách thức độc đáo của cộng tác đa tác nhân thông qua các tính năng cho phép quy trình làm việc phức tạp, xử lý các quy trình kinh doanh thực tế phức tạp với khả năng quan sát và kiểm soát mà môi trường sản xuất yêu cầu. Cụ thể, nó hỗ trợ thẻ tác nhân, tác vụ có cấu trúc, nhiều tùy chọn vận chuyển và các nguyên hàm xác thực/ủy quyền.\nThẻ đại lý Giao tiếp đa tác nhân hiệu quả đòi hỏi các tác nhân phải khám phá và hiểu rõ khả năng của nhau. A2A hỗ trợ điều này thông qua Thẻ Tác nhân — các tài liệu siêu dữ liệu nắm bắt ý nghĩa ngữ nghĩa về những gì mỗi tác nhân có thể làm, cách thức hoạt động ưa thích và loại nhiệm vụ mà tác nhân đó giỏi. Thẻ Tác nhân cho phép các tác nhân khác đưa ra quyết định thông minh về thời điểm và cách thức hợp tác. Thẻ Tác nhân cũng mô tả các yêu cầu xác thực/ủy quyền của một tác nhân và hỗ trợ các khả năng được mở rộng dần dần sau khi xác thực, sử dụng Thẻ Tác nhân Mở rộng Đã Xác thực.\nThực hiện nhiệm vụ có cấu trúc Các tác nhân làm việc cùng nhau để giải quyết vấn đề bằng cách tận dụng các tác vụ để cấu trúc giao tiếp; họ sắp xếp thông điệp của mình thành các đơn vị công việc thông minh, mang ngữ cảnh, theo dõi tiến độ và lưu trữ các hiện vật đầu ra. Thông qua các tác vụ, các tác nhân có thể tham chiếu các hiện vật đã tạo trước đó, hiểu được sự phụ thuộc giữa các tác vụ trong quy trình làm việc và đưa ra quyết định sáng suốt dựa trên toàn bộ lịch sử hội thoại. Các tác vụ hỗ trợ cả thực thi tuần tự và song song cho các quy trình làm việc phức tạp. Các tác nhân có thể tạo ra nhiều tác vụ tiếp theo đồng thời và tạo ra các chuỗi hoạt động phụ thuộc. Điều này mang lại cho các nhà phát triển ứng dụng sự linh hoạt để mô hình hóa các quy trình kinh doanh trong thế giới thực.\nBằng cách tận dụng ID tác vụ và ngữ cảnh, các ứng dụng có thể theo dõi nguồn gốc tác vụ, lần theo chuỗi tác vụ đến tận gốc để khôi phục thông tin về cách tạo ra kết quả đầu ra. Điều này cải thiện khả năng quan sát bằng cách cung cấp cho các tác nhân khả năng tạo nhật ký hoạt động phong phú để gỡ lỗi và kiểm tra.\nNhiều lựa chọn vận chuyển A2A hỗ trợ các nhà phát triển ứng dụng bằng cách hỗ trợ ba giao thức cốt lõi có khả năng tương đương: JSON-RPC 2.0, gRPC và REST. Điều này cho phép các nhà phát triển lựa chọn phương thức vận chuyển phù hợp nhất với chuyên môn, cơ sở hạ tầng hiện có và yêu cầu hiệu suất của nhóm. Đối với các hoạt động dài hạn, A2A tăng cường mỗi phương thức vận chuyển với Server-Sent Events (SSE) để phát trực tuyến và gửi thông báo đẩy dựa trên webhook. Các nhà phát triển có các tùy chọn trực quan để xử lý cập nhật tác vụ không đồng bộ và giám sát tiến độ theo thời gian thực mà không cần logic thăm dò phức tạp.\nBảo mật A2A Bảo mật cấp doanh nghiệp là một yêu cầu không thể thương lượng đối với các hệ thống agent. A2A cho phép kiến ​​trúc bảo mật mạnh mẽ bằng cách hỗ trợ một số giao thức xác thực; bao gồm OAuth 2.0, OpenID Connect và mTLS, cho phép các tổ chức tích hợp agent với cơ sở hạ tầng nhận dạng hiện có của họ, trong khi siêu dữ liệu ủy quyền theo kỹ năng cụ thể và hỗ trợ xác thực thứ cấp cho phép các chính sách kiểm soát truy cập chi tiết có thể được thực thi ở cấp ứng dụng.\nQuyết định của A2A trong việc giữ cho các tác nhân không minh bạch với nhau hỗ trợ kiến ​​trúc không tin cậy bằng cách coi mỗi tác nhân là một ranh giới bảo mật độc lập và việc giao thức hỗ trợ kiểm tra tác vụ cung cấp nền tảng cho việc giám sát bảo mật toàn diện và báo cáo tuân thủ.\nInter-Agent với Strands Agents \u0026amp; A2A Các tính năng độc đáo của A2A khiến nó trở nên hoàn hảo cho khả năng tương tác giữa các nền tảng tác nhân. Một số nền tảng tác nhân nguồn mở hiện đã hỗ trợ nó. Bộ SDK Strands Agents nguồn mở gần đây đã bổ sung hỗ trợ cho A2A để các tác nhân có thể dễ dàng communicate with other agents.\nStrands Agents áp dụng phương pháp tiếp cận dựa trên mô hình để xây dựng và vận hành các tác nhân AI chỉ trong vài dòng mã. Strands mở rộng từ các trường hợp sử dụng tác nhân đơn giản đến phức tạp, và từ phát triển cục bộ đến triển khai trong môi trường sản xuất. Nhiều nhóm tại AWS đã sử dụng Strands cho các tác nhân AI trong môi trường sản xuất, bao gồm Amazon Q Developer, AWS Glue và VPC Reachability Analyzer.\nVới hỗ trợ A2A tích hợp sẵn trong Strands Agents, bạn có thể dễ dàng sử dụng một agent như một máy chủ A2A và giao tiếp từ một Agent Strands này đến các agent A2A khác. Để minh họa điều này, hãy xem xét ví dụ về một agent Nhân sự (HR) có thể trả lời các câu hỏi về nhân viên. Để làm điều này, bạn có thể tưởng tượng agent HR giao tiếp với một số agent khác như agent dữ liệu nhân viên, agent Hoạch định Nguồn lực Doanh nghiệp (ERP), agent hiệu suất, agent mục tiêu, v.v. Trong ví dụ này, hãy bắt đầu với một kiến ​​trúc cơ bản, trong đó REST API cung cấp quyền truy cập vào một agent HR kết nối với một agent Thông tin Nhân viên: Kiến trúc của hệ thống liên agent bao gồm hai agent (HR \u0026amp; Employee Info), được kết nối bằng A2A.\nNote: The complete, working version of the following example is available in our Agentic AI samples repo.\nCông cụ thông tin nhân viên của chúng tôi sử dụng Amazon Bedrock và công cụ MCP để lấy dữ liệu nhân viên (xem mã đầy đủ cho các khía cạnh đó): employee_agent = Agent( model=bedrock_model, name=\u0026ldquo;Employee Agent\u0026rdquo;, description=\u0026ldquo;Answers questions about employees\u0026rdquo;, tools=tools, system_prompt=\u0026ldquo;you must abbreviate employee first names and list all their skills\u0026rdquo; )\nĐể hiển thị tác nhân này thông qua A2A, chúng ta chỉ cần tạo máy chủ A2A và khởi động nó khi chương trình chạy: a2a_server = A2AServer(agent=employee_agent, host=urlparse(EMPLOYEE_AGENT_URL).hostname, port=urlparse(EMPLOYEE_AGENT_URL).port)\nif name == \u0026ldquo;main\u0026rdquo;: a2a_server.serve(host=\u0026ldquo;0.0.0.0\u0026rdquo;, port=8001)\nLưu ý rằng chúng tôi vượt qua EMPLOYEE_AGENT_URL thông qua một biến môi trường. Điều này giúp định nghĩa cơ sở hạ tầng của chúng ta biết URL điểm cuối có thể thiết lập máy chủ và cổng được sử dụng trong thẻ tác nhân A2A (được máy khách A2A sử dụng để khám phá tác nhân).\nHiện tại, chúng ta có thể truy cập vào tác nhân Thông tin nhân viên thông qua A2A và chúng ta có thể tạo tác nhân HR: provider = A2AClientToolProvider(known_agent_urls=[EMPLOYEE_AGENT_URL]) agent = Agent(model=bedrock_model, tools=provider.tools)\nTác nhân này giờ đây có thể được gọi theo nhiều cách khác nhau. Trong ví dụ này, chúng tôi gọi nó từ một yêu cầu REST. Xem mã đầy đủ để biết các khía cạnh REST. Sau đây là những gì xảy ra khi yêu cầu REST được thực hiện:\nNgười dùng (có thể thông qua ứng dụng web hoặc ứng dụng di động) gửi truy vấn như \u0026ldquo;liệt kê những nhân viên có kỹ năng liên quan đến AI\u0026rdquo; Nhân viên HR sử dụng mô hình Amazon Nova để hiểu truy vấn của người dùng và quyết định rằng truy vấn đó cần được gửi đến nhân viên thông tin nhân viên. Khi sử dụng A2A, truy vấn sẽ được gửi đến tác nhân Thông tin nhân viên. Tác nhân Thông tin nhân viên sử dụng mô hình Amazon Nova để hiểu truy vấn và quyết định cần gọi máy chủ MCP Dữ liệu nhân viên. Tác nhân Thông tin nhân viên gọi máy chủ MCP Dữ liệu nhân viên để truy vấn cơ sở dữ liệu nhân viên và trả dữ liệu về mô hình Nova. Với yêu cầu của hệ thống là viết tắt tên của nhân viên, mô hình sẽ lấy danh sách nhân viên, định dạng danh sách một cách đẹp mắt, viết tắt tên và trả lại văn bản cho tác nhân Thông tin nhân viên. Tác nhân Thông tin nhân viên trả lại văn bản cho tác nhân HR, tác nhân này trả lại văn bản trong phản hồi REST. Tất nhiên, tất cả những điều này đều có thể chạy trên AWS bằng nhiều môi trường thời gian chạy khác nhau (Amazon Elastic Kubernetes Service (Amazon EKS), Amazon Elastic Container Service (Amazon ECS), Amazon Bedrock AgentCore, AWS Lambda, v.v.). Ví dụ này chứa AWS CloudFormation deployment template triển khai các tác nhân và máy chủ MCP trên Amazon ECS (tất cả trong một VPC) và một Bộ cân bằng tải ứng dụng để công khai dịch vụ REST.\nChúng ta có thể thử nghiệm với curl: curl -X POST \u0026ndash;location \u0026ldquo;http://something.us-east-1.elb.amazonaws.com/inquire\" -H \u0026ldquo;Content-Type: application/json\u0026rdquo; -d \u0026lsquo;{\u0026ldquo;question\u0026rdquo;: \u0026ldquo;list employees that have skills related to AI programming\u0026rdquo;}\u0026rsquo; Và chúng ta quay lại: Here are the employees with skills related to AI programming:\nA. Rosalez - Machine Learning, REST API E. Owusu - DevOps, Machine Learning, Python J. Doe- Machine Learning, JavaScript K. Mensah - REST API, Kubernetes, Machine Learning, Node.js M. Rivera - AWS, Kubernetes, GraphQL, Machine Learning M. Major - MongoDB, Angular, Kotlin, Machine Learning, REST API C. Salazar - React, Machine Learning, SQL, Kotlin N. Wolf - SQL, Machine Learning, Docker, DevOps, Git If you need more detailed information about any of these employees or require further assistance, please let me know!\nLấy the complete source cho ví dụ này.\nVới Strands Agents, chỉ cần vài dòng mã là có thể hiển thị các agent dưới dạng máy chủ A2A và giao tiếp giữa các agent với nhau bằng A2A. Trong các bài viết tiếp theo, chúng tôi sẽ đề cập đến các dạng agent nâng cao hơn như Swarms, Graphs và Workflows.\nQuan điểm của khách hàng Chúng tôi đã nhận được phản hồi từ một số khách hàng và đối tác rất hào hứng với dịch vụ hỗ trợ A2A của chúng tôi. Dưới đây là một số chia sẻ của họ:\n“Tại Autodesk, chúng tôi cam kết thúc đẩy các tiêu chuẩn mở cho AI đại diện và khả năng tương tác khi chúng tôi định hình tương lai của thiết kế và kỹ thuật. Thông qua sự hợp tác với AWS và cộng đồng A2A, chúng tôi rất hào hứng được góp phần xây dựng một hệ sinh thái nơi các đại diện thông minh có thể giao tiếp liền mạch trên các nền tảng Autodesk. Khi chúng tôi tiếp tục cải tiến Dịch vụ Nền tảng Autodesk với các khả năng AI tạo sinh, chúng tôi nhận thấy tiềm năng to lớn trong cách các đại diện AI có khả năng tương tác có thể chuyển đổi quy trình làm việc trong lĩnh vực kiến ​​trúc, kỹ thuật, xây dựng và sản xuất. Hợp tác cùng AWS, chúng tôi cam kết tạo ra các giải pháp cho phép cộng tác đại diện an toàn và hiệu quả, đồng thời duy trì các tiêu chuẩn cấp doanh nghiệp.” – Ritesh Bansal, Phó Chủ tịch Phân tích Dữ liệu, Thông tin chi tiết và Nền tảng AI/ML, Autodesk\n“Cam kết của chúng tôi trong việc phát triển Agentic AI, các giao thức mở và khả năng tương tác là cốt lõi trong tầm nhìn của chúng tôi về các mạng lưới an toàn và thông minh. Bằng cách hợp tác với AWS và cộng đồng A2A, chúng tôi đang thúc đẩy đổi mới để thiết lập các chuẩn mực mới về bảo mật dựa trên AI, cho phép các tổ chức hoạt động với khả năng phục hồi và sự tự tin cao hơn trong kỷ nguyên AI đang phát triển nhanh chóng.” – Raj Chopra, Phó Chủ tịch Cấp cao kiêm Giám đốc Sản phẩm, Bộ phận An ninh, Cisco\n“Khi các tổ chức thiết kế các hệ thống AI agentic ngày càng tinh vi, việc phối hợp giữa các agent và công cụ đang trở nên thiết yếu. Chúng tôi rất vui mừng khi thấy AWS thúc đẩy những nỗ lực như A2A, hỗ trợ các kiến ​​trúc tương tác tốt hơn, giúp các tổ chức và khách hàng của Datadog xây dựng các ứng dụng agent-based dễ quan sát, đáng tin cậy và an toàn hơn.” — Yrieix Garnier, Phó Chủ tịch Sản phẩm, Datadog\n“MongoDB và AWS cùng cam kết xây dựng một hệ sinh thái mở, có khả năng kết hợp, cho phép các nhà phát triển tự do sáng tạo hơn. Việc áp dụng các tiêu chuẩn mở như A2A là một bước quan trọng hướng tới tầm nhìn này, giúp đơn giản hóa cách các tác nhân tương tác với mô hình tài liệu phong phú của MongoDB, khả năng tìm kiếm vector tích hợp và các mô hình AI Voyage.” – Abhinav Mehla, Phó Chủ tịch Chương trình Đối tác Toàn cầu \u0026amp; Hệ sinh thái, MongoDB\n“Khả năng tương tác rất quan trọng để các tác nhân AI hoạt động liền mạch và hiệu quả trên các hệ thống và công cụ doanh nghiệp, đó là lý do tại sao chúng tôi hợp tác với toàn ngành để phát triển tiêu chuẩn A2A, và tại sao chúng tôi sẽ hỗ trợ các tiêu chuẩn mở như A2A và MCP trong Agentforce. Việc AWS hỗ trợ A2A sẽ tiếp tục giúp phá vỡ rào cản giữa các nhà cung cấp, thúc đẩy đổi mới và mang lại giá trị đáng kể cho khách hàng chung của chúng tôi bằng cách cho phép các tác nhân làm việc trên toàn bộ cơ sở hạ tầng và hệ sinh thái công cụ và tác nhân của công ty.” — Gary Lerhaupt, Phó Chủ tịch Kiến trúc Sản phẩm, Salesforce\n“Thật phấn khích khi thấy những công ty hàng đầu trong ngành như AWS ủng hộ giao thức Agent2Agent. Khởi đầu là một ý tưởng táo bạo, giờ đây nó đang nhanh chóng trở thành một tiêu chuẩn chung của ngành – một tiêu chuẩn dựa trên tính mở, bảo mật và khả năng cộng tác đa nền tảng. Với sự hỗ trợ từ AWS và các đối tác khác, hệ sinh thái A2A đang thực sự phát triển mạnh mẽ, và ServiceNow tự hào dẫn đầu xu hướng này bằng cách hiện thực hóa các tác nhân AI cấp doanh nghiệp có khả năng tương tác.” – Joe Davis, Phó Chủ tịch Điều hành Nhóm Kỹ thuật Nền tảng \u0026amp; Công nghệ AI tại ServiceNow.\nSnowflake tin chắc rằng một số cải tiến lớn nhất trong ngành đến từ các giao thức mở và cộng đồng hỗ trợ chúng. Việc tối đa hóa tiềm năng của AI agentic phụ thuộc vào các giao thức mở như A2A, cũng như kiến ​​thức được chia sẻ và các phương pháp hay nhất mà chúng cung cấp. Chúng tôi rất vui mừng khi thấy AWS thể hiện cam kết của họ đối với các giao thức mở cho khả năng tương tác của agent bằng cách bổ sung hỗ trợ A2A vào Strands Agents. Cùng với sự hỗ trợ của cộng đồng công nghệ rộng lớn hơn, ngành công nghiệp sẽ có thể tự động hóa công việc tri thức với các hệ thống agentic an toàn như Strands Agents và Snowflake Cortex Agents. – Dwarak Rajagopal, Phó Chủ tịch Kỹ thuật \u0026amp; Nghiên cứu AI, Snowflake\n“Trong tương lai, một lực lượng lao động phân mảnh gồm con người và các tác nhân AI chắc chắn sẽ cản trở sự phát triển. Chúng tôi tin rằng các giao thức mở, đặc biệt là Giao thức Agent-to-Agent (A2A), đóng vai trò quan trọng trong sự phát triển của lực lượng lao động hỗn hợp này. Chúng cho phép giao tiếp an toàn, hợp tác, đảm bảo khả năng tương tác giữa các hệ sinh thái tác nhân đa dạng. Hệ thống Agent System of Record (ASOR) của Workday mở rộng nền tảng đáng tin cậy của chúng tôi một cách độc đáo để quản lý con người, tài chính và các tác nhân cùng nhau. Hợp tác với AWS và cộng đồng A2A, chúng tôi cam kết thúc đẩy giao tiếp agent an toàn, tương tác. Điều này không chỉ là về công nghệ mới; mà còn là về việc mở khóa một cách an toàn các cấp độ năng suất và đổi mới mới trên toàn doanh nghiệp, đồng thời duy trì khả năng kiểm soát toàn diện.” —Dean Arnold, Phó Chủ tịch Hệ thống Record, Workday\nBắt đầu và cung cấp phản hồi Để bắt đầu xây dựng các tác nhân AI tương tác bằng A2A, hãy xem Strands Agents A2A docs. Chúng tôi rất mong nhận được phản hồi của bạn về việc sử dụng A2A với Strands Agents! Hãy tham gia discussions on the open source Strands Agents Python SDK repo để cho chúng tôi biết bạn cần thêm những gì khi xây dựng hệ thống liên tác nhân.\nNick Aldridge là Kỹ sư Chính tại AWS. Trong 6 năm qua, Nick đã tham gia nhiều sáng kiến ​​AI/ML, bao gồm Amazon Lex và Amazon Bedrock. Gần đây nhất, anh là người lãnh đạo nhóm ra mắt Amazon Bedrock Knowledge Bases. Hiện tại, anh làm việc về AI tạo sinh và cơ sở hạ tầng AI, tập trung vào cộng tác giữa các tác nhân và gọi hàm. Trước khi làm việc tại AWS, Nick đã lấy bằng Thạc sĩ tại Đại học Chicago.\nJames Ward is a Principal Developer Advocate at AWS. James travels the world helping enterprise developers learn how to build reliable systems. His current focus is on helping developers build systems of AI agents using Spring AI, Embabel, Strands Agents, Amazon Bedrock, MCP, and A2A.\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/5-workshop/5.4-deploy-backend/",
	"title": "Triển khai Backend Application",
	"tags": [],
	"description": "",
	"content": "Tổng quan Trong bước này, bạn sẽ build và deploy ứng dụng Spring Boot backend lên EC2 instances. Backend cung cấp RESTful API cho DNA analysis, user authentication, và data management.\nBước 1: Cấu hình Database Connection Lấy RDS endpoint từ CloudFormation outputs:\nRDS_ENDPOINT=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`RDSEndpoint`].OutputValue\u0026#39; \\ --output text) echo \u0026#34;RDS Endpoint: $RDS_ENDPOINT\u0026#34; Cập nhật file BE/workshop_BE/src/main/resources/application.properties:\n# Database Configuration spring.datasource.url=jdbc:mysql://${RDS_ENDPOINT}:3306/workshop_aws?useSSL=true\u0026amp;requireSSL=false\u0026amp;allowPublicKeyRetrieval=true\u0026amp;serverTimezone=Asia/Ho_Chi_Minh spring.datasource.username=admin spring.datasource.password=YourStrongPassword123! spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver # Connection Pool spring.datasource.hikari.maximum-pool-size=10 spring.datasource.hikari.minimum-idle=5 spring.datasource.hikari.connection-timeout=20000 # JPA Configuration spring.jpa.hibernate.ddl-auto=update spring.jpa.show-sql=false spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MySQL8Dialect # Server Configuration server.port=8080 server.servlet.context-path=/dna_service # JWT Configuration jwt.signerKey=2VJ50pdhYm96e4VECp/vsZGVmkSl9xp1rSYAZKsZL7n9Ti1pZYle3k9mheQEKt6+ jwt.expiration=86400000 # CORS Configuration cors.allowed.origins=* # Logging logging.level.root=INFO logging.level.aws_project.workshop=DEBUG logging.file.name=/opt/workshop/application.log Bước 2: Build Backend JAR cd BE/workshop_BE # Clean và build mvn clean package -DskipTests # Hoặc sử dụng Maven Wrapper ./mvnw clean package -DskipTests # Kiểm tra JAR file ls -lh target/workshop-0.0.1-SNAPSHOT.jar Kết quả mong đợi: File JAR khoảng 50-80MB trong thư mục target/\nBước 3: Upload JAR lên S3 Tạo S3 bucket cho backend artifacts (nếu chưa có):\nACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text) BACKEND_BUCKET=\u0026#34;workshop-aws-dev-backend-${ACCOUNT_ID}-ap-southeast-1\u0026#34; # Tạo bucket aws s3 mb s3://${BACKEND_BUCKET} --region ap-southeast-1 # Upload JAR aws s3 cp target/workshop-0.0.1-SNAPSHOT.jar \\ s3://${BACKEND_BUCKET}/jars/ \\ --region ap-southeast-1 # Verify upload aws s3 ls s3://${BACKEND_BUCKET}/jars/ Bước 4: Deploy lên EC2 Lấy EC2 Instance ID INSTANCE_ID=$(aws ec2 describe-instances \\ --filters \u0026#34;Name=tag:aws:cloudformation:stack-name,Values=workshop-aws-dev\u0026#34; \\ \u0026#34;Name=instance-state-name,Values=running\u0026#34; \\ --region ap-southeast-1 \\ --query \u0026#39;Reservations[0].Instances[0].InstanceId\u0026#39; \\ --output text) echo \u0026#34;Instance ID: $INSTANCE_ID\u0026#34; Kết nối vào EC2 qua Session Manager aws ssm start-session --target $INSTANCE_ID --region ap-southeast-1 Trên EC2 Instance, chạy các lệnh sau: # Chuyển sang ec2-user sudo su - ec2-user # Di chuyển vào thư mục application cd /opt/workshop # Download JAR từ S3 ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text) BACKEND_BUCKET=\u0026#34;workshop-aws-dev-backend-${ACCOUNT_ID}-ap-southeast-1\u0026#34; aws s3 cp s3://${BACKEND_BUCKET}/jars/workshop-0.0.1-SNAPSHOT.jar . \\ --region ap-southeast-1 # Kiểm tra file ls -lh workshop-0.0.1-SNAPSHOT.jar Tạo Application Properties cat \u0026gt; application.properties \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; spring.application.name=workshop-aws # Database Configuration spring.datasource.url=jdbc:mysql://REPLACE_WITH_RDS_ENDPOINT:3306/workshop_aws?useSSL=true\u0026amp;requireSSL=false\u0026amp;allowPublicKeyRetrieval=true\u0026amp;serverTimezone=Asia/Ho_Chi_Minh spring.datasource.username=admin spring.datasource.password=YourStrongPassword123! spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver # Connection Pool spring.datasource.hikari.maximum-pool-size=10 spring.datasource.hikari.minimum-idle=5 # JPA Configuration spring.jpa.hibernate.ddl-auto=update spring.jpa.show-sql=false # Server Configuration server.port=8080 server.servlet.context-path=/dna_service # JWT Configuration jwt.signerKey=2VJ50pdhYm96e4VECp/vsZGVmkSl9xp1rSYAZKsZL7n9Ti1pZYle3k9mheQEKt6+ # Logging logging.level.root=INFO logging.level.aws_project.workshop=DEBUG logging.file.name=/opt/workshop/application.log EOF # Thay thế RDS endpoint RDS_ENDPOINT=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`RDSEndpoint`].OutputValue\u0026#39; \\ --output text) sed -i \u0026#34;s/REPLACE_WITH_RDS_ENDPOINT/${RDS_ENDPOINT}/g\u0026#34; application.properties Khởi động Application # Dừng application cũ (nếu có) sudo systemctl stop workshop.service 2\u0026gt;/dev/null || true pkill -f workshop-0.0.1-SNAPSHOT.jar 2\u0026gt;/dev/null || true # Khởi động application nohup java -jar workshop-0.0.1-SNAPSHOT.jar \\ --spring.config.location=file:/opt/workshop/application.properties \\ \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp; # Lưu PID echo $! \u0026gt; application.pid # Đợi application khởi động sleep 10 # Kiểm tra process ps aux | grep java Bước 5: Kiểm tra Application Test Health Endpoint # Trên EC2 curl http://localhost:8080/dna_service/actuator/health # Kết quả mong đợi: # {\u0026#34;status\u0026#34;:\u0026#34;UP\u0026#34;} Test qua Load Balancer # Trên máy local ALB_DNS=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`ALBDNSName`].OutputValue\u0026#39; \\ --output text) curl http://${ALB_DNS}/dna_service/actuator/health Test qua API Gateway API_URL=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`APIGatewayURL`].OutputValue\u0026#39; \\ --output text) curl ${API_URL}/dna_service/actuator/health Bước 6: Cấu hình Systemd Service Để application tự động khởi động khi EC2 restart:\n# Trên EC2 sudo tee /etc/systemd/system/workshop.service \u0026gt; /dev/null \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; [Unit] Description=Workshop DNA Analysis Backend After=network.target [Service] Type=simple User=ec2-user Group=ec2-user WorkingDirectory=/opt/workshop ExecStart=/usr/bin/java -jar /opt/workshop/workshop-0.0.1-SNAPSHOT.jar --spring.config.location=file:/opt/workshop/application.properties Restart=always RestartSec=10 StandardOutput=append:/opt/workshop/application.log StandardError=append:/opt/workshop/application.log [Install] WantedBy=multi-user.target EOF # Reload systemd sudo systemctl daemon-reload # Enable service sudo systemctl enable workshop.service # Start service sudo systemctl start workshop.service # Check status sudo systemctl status workshop.service Bước 7: Xem Logs # Xem application logs tail -f /opt/workshop/application.log # Xem systemd logs sudo journalctl -u workshop.service -f # Xem CloudWatch Logs (trên máy local) aws logs tail /aws/workshop-aws/dev/application \\ --follow \\ --region ap-southeast-1 Troubleshooting Application không khởi động Kiểm tra logs:\ntail -100 /opt/workshop/application.log Các lỗi thường gặp:\nDatabase connection failed\nKiểm tra RDS endpoint trong application.properties Kiểm tra Security Group cho phép EC2 connect đến RDS Verify database credentials Port 8080 already in use\n# Kill process đang dùng port 8080 sudo lsof -ti:8080 | xargs kill -9 Out of memory\n# Tăng heap size java -Xmx512m -jar workshop-0.0.1-SNAPSHOT.jar Health check failed # Kiểm tra application đang chạy ps aux | grep java # Kiểm tra port listening sudo netstat -tulpn | grep 8080 # Test local curl -v http://localhost:8080/dna_service/actuator/health Load Balancer health check failed # Kiểm tra Target Group health aws elbv2 describe-target-health \\ --target-group-arn \u0026lt;target-group-arn\u0026gt; \\ --region ap-southeast-1 # Kiểm tra Security Group # EC2 SG phải cho phép traffic từ ALB SG trên port 8080 Xác nhận Deployment thành công Checklist:\nJAR file đã build thành công JAR đã upload lên S3 Application đang chạy trên EC2 Health endpoint trả về {\u0026quot;status\u0026quot;:\u0026quot;UP\u0026quot;} Có thể access qua Load Balancer Có thể access qua API Gateway Systemd service đã được enable Logs đang được ghi vào CloudWatch Tiếp theo Sau khi backend đã sẵn sàng:\n➡️ Triển khai Frontend lên S3 và CloudFront\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/5-workshop/5.5-deploy-frontend/",
	"title": "Triển khai Frontend",
	"tags": [],
	"description": "",
	"content": "Tổng quan Trong bước này, bạn sẽ build React frontend và deploy lên S3, sau đó phân phối qua CloudFront CDN để đảm bảo hiệu suất cao và độ trễ thấp cho người dùng toàn cầu.\nBước 1: Cấu hình API Endpoint Lấy API Gateway URL từ CloudFormation outputs:\nAPI_URL=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`APIGatewayURL`].OutputValue\u0026#39; \\ --output text) echo \u0026#34;API URL: $API_URL\u0026#34; Cập nhật file FE/.env:\ncd FE cat \u0026gt; .env \u0026lt;\u0026lt;EOF VITE_API_URL=${API_URL}/dna_service VITE_APP_NAME=DNA Analysis Workshop VITE_APP_VERSION=1.0.0 EOF Hoặc cập nhật file config trực tiếp FE/src/config/api.ts:\nexport const API_BASE_URL = process.env.VITE_API_URL || \u0026#39;http://localhost:8080/dna_service\u0026#39;; export const API_TIMEOUT = 30000; export const API_ENDPOINTS = { AUTH: { LOGIN: \u0026#39;/auth/login\u0026#39;, REGISTER: \u0026#39;/auth/register\u0026#39;, LOGOUT: \u0026#39;/auth/logout\u0026#39;, REFRESH: \u0026#39;/auth/refresh\u0026#39;, }, DNA: { ANALYZE: \u0026#39;/dna/analyze\u0026#39;, HISTORY: \u0026#39;/dna/history\u0026#39;, RESULT: \u0026#39;/dna/result\u0026#39;, }, USER: { PROFILE: \u0026#39;/user/profile\u0026#39;, UPDATE: \u0026#39;/user/update\u0026#39;, }, }; Bước 2: Install Dependencies cd FE # Install npm packages npm install # Verify installation npm list --depth=0 Bước 3: Build Frontend # Build production bundle npm run build # Kiểm tra build output ls -lh dist/ # Xem cấu trúc files tree dist/ -L 2 Kết quả mong đợi:\ndist/\r├── index.html\r├── assets/\r│ ├── index-[hash].js\r│ ├── index-[hash].css\r│ └── [other assets]\r└── vite.svg Bước 4: Upload lên S3 Lấy S3 bucket name từ outputs:\nFRONTEND_BUCKET=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`FrontendBucketName`].OutputValue\u0026#39; \\ --output text) echo \u0026#34;Frontend Bucket: $FRONTEND_BUCKET\u0026#34; Upload files lên S3:\n# Sync tất cả files aws s3 sync dist/ s3://${FRONTEND_BUCKET}/ \\ --delete \\ --region ap-southeast-1 # Set cache control cho static assets aws s3 cp dist/assets/ s3://${FRONTEND_BUCKET}/assets/ \\ --recursive \\ --cache-control \u0026#34;max-age=31536000\u0026#34; \\ --region ap-southeast-1 # Set no-cache cho index.html aws s3 cp dist/index.html s3://${FRONTEND_BUCKET}/ \\ --cache-control \u0026#34;no-cache,no-store,must-revalidate\u0026#34; \\ --region ap-southeast-1 # Verify upload aws s3 ls s3://${FRONTEND_BUCKET}/ --recursive Bước 5: Invalidate CloudFront Cache Sau khi upload, cần invalidate CloudFront cache để users nhận được phiên bản mới:\n# Lấy CloudFront Distribution ID DIST_ID=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`CloudFrontDistributionId`].OutputValue\u0026#39; \\ --output text) echo \u0026#34;Distribution ID: $DIST_ID\u0026#34; # Tạo invalidation aws cloudfront create-invalidation \\ --distribution-id $DIST_ID \\ --paths \u0026#34;/*\u0026#34; \\ --region ap-southeast-1 # Theo dõi invalidation status aws cloudfront get-invalidation \\ --distribution-id $DIST_ID \\ --id \u0026lt;invalidation-id\u0026gt; Lưu ý: Invalidation mất 5-10 phút để hoàn thành.\nBước 6: Truy cập Frontend Lấy CloudFront domain name:\nCLOUDFRONT_URL=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`CloudFrontDomainName`].OutputValue\u0026#39; \\ --output text) echo \u0026#34;Frontend URL: https://${CLOUDFRONT_URL}\u0026#34; Mở trình duyệt và truy cập URL trên.\nBước 7: Kiểm tra Frontend Test Basic Functionality Trang chủ: Kiểm tra trang load đúng Navigation: Test các menu và routing API Connection: Mở Developer Tools → Network tab Console Errors: Kiểm tra không có lỗi JavaScript Test Authentication # Test login endpoint curl -X POST https://${CLOUDFRONT_URL}/api/auth/login \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;username\u0026#34;:\u0026#34;test\u0026#34;,\u0026#34;password\u0026#34;:\u0026#34;test123\u0026#34;}\u0026#39; Test CORS Mở Developer Tools → Console và chạy:\nfetch(\u0026#39;${API_URL}/dna_service/actuator/health\u0026#39;) .then(res =\u0026gt; res.json()) .then(data =\u0026gt; console.log(\u0026#39;API Response:\u0026#39;, data)) .catch(err =\u0026gt; console.error(\u0026#39;CORS Error:\u0026#39;, err)); Bước 8: Cấu hình Custom Domain (Optional) Nếu bạn có domain name:\n1. Tạo SSL Certificate trong ACM # Certificate phải tạo trong us-east-1 cho CloudFront aws acm request-certificate \\ --domain-name yourdomain.com \\ --subject-alternative-names www.yourdomain.com \\ --validation-method DNS \\ --region us-east-1 2. Validate Certificate Thêm CNAME records vào DNS theo hướng dẫn từ ACM.\n3. Cập nhật CloudFront Distribution aws cloudfront update-distribution \\ --id $DIST_ID \\ --distribution-config file://cloudfront-config.json 4. Cập nhật Route 53 # Tạo A record alias đến CloudFront aws route53 change-resource-record-sets \\ --hosted-zone-id \u0026lt;zone-id\u0026gt; \\ --change-batch file://route53-changes.json Deployment Script Tạo script tự động hóa deployment:\ncat \u0026gt; deploy-frontend.sh \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; #!/bin/bash set -e echo \u0026#34;Building frontend...\u0026#34; cd FE npm run build echo \u0026#34;Getting S3 bucket name...\u0026#34; FRONTEND_BUCKET=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`FrontendBucketName`].OutputValue\u0026#39; \\ --output text) echo \u0026#34;Uploading to S3...\u0026#34; aws s3 sync dist/ s3://${FRONTEND_BUCKET}/ --delete --region ap-southeast-1 echo \u0026#34;Invalidating CloudFront cache...\u0026#34; DIST_ID=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`CloudFrontDistributionId`].OutputValue\u0026#39; \\ --output text) aws cloudfront create-invalidation \\ --distribution-id $DIST_ID \\ --paths \u0026#34;/*\u0026#34; \\ --region ap-southeast-1 echo \u0026#34;Deployment complete!\u0026#34; echo \u0026#34;Frontend URL: https://$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`CloudFrontDomainName`].OutputValue\u0026#39; \\ --output text)\u0026#34; EOF chmod +x deploy-frontend.sh Sử dụng script:\n./deploy-frontend.sh Troubleshooting Build Failed Lỗi: \u0026ldquo;Module not found\u0026rdquo;\n# Xóa node_modules và reinstall rm -rf node_modules package-lock.json npm install Lỗi: \u0026ldquo;Out of memory\u0026rdquo;\n# Tăng memory cho Node.js export NODE_OPTIONS=\u0026#34;--max-old-space-size=4096\u0026#34; npm run build Upload Failed Lỗi: \u0026ldquo;Access Denied\u0026rdquo;\nKiểm tra AWS credentials Verify IAM permissions cho S3 Lỗi: \u0026ldquo;Bucket does not exist\u0026rdquo;\nKiểm tra bucket name Verify CloudFormation stack đã tạo bucket CloudFront Issues Trang không load:\nĐợi CloudFront distribution deploy (5-10 phút) Check distribution status: Deployed Nhận được phiên bản cũ:\nTạo invalidation mới Clear browser cache (Ctrl+Shift+R) CORS errors:\nKiểm tra API Gateway CORS configuration Verify backend CORS settings API Connection Failed # Test API từ browser console fetch(\u0026#39;${API_URL}/dna_service/actuator/health\u0026#39;) .then(res =\u0026gt; res.text()) .then(data =\u0026gt; console.log(data)) Nếu lỗi:\nKiểm tra API Gateway URL đúng Verify backend đang chạy Check Security Groups Xác nhận Deployment thành công Checklist:\nFrontend build thành công Files đã upload lên S3 CloudFront invalidation hoàn thành Trang web load đúng qua CloudFront URL Không có lỗi trong browser console API calls hoạt động (check Network tab) Authentication flow hoạt động Routing giữa các pages hoạt động Tiếp theo Sau khi frontend đã sẵn sàng:\n➡️ Kiểm tra và Xác thực\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "Triển khai Ứng dụng Phân tích DNA trên AWS Tổng quan Trong workshop này, bạn sẽ học cách triển khai một ứng dụng phân tích DNA full-stack sẵn sàng cho production trên AWS sử dụng Infrastructure as Code (IaC) với CloudFormation. Ứng dụng bao gồm frontend React, backend Spring Boot, và cơ sở dữ liệu MySQL, tất cả được triển khai theo các best practices của AWS về bảo mật, khả năng mở rộng và tối ưu chi phí.\nCác dịch vụ AWS được sử dụng:\nVPC \u0026amp; Networking: VPC, Subnets, Internet Gateway, NAT Gateway, VPC Endpoints Compute: EC2 Auto Scaling Group, Application Load Balancer Storage \u0026amp; CDN: S3 để lưu trữ frontend, CloudFront để phân phối nội dung toàn cầu Database: RDS MySQL để lưu trữ dữ liệu với sao lưu tự động Security: Security Groups, IAM Roles, AWS Cognito cho xác thực người dùng Monitoring: CloudWatch Logs, Alarms, và thông báo SNS API Management: API Gateway để expose backend API một cách an toàn Bạn sẽ học được gì Infrastructure as Code: Triển khai toàn bộ hạ tầng AWS bằng CloudFormation templates Thiết kế VPC: Tạo VPC an toàn với public và private subnets trên nhiều availability zones Tối ưu chi phí: Sử dụng VPC Endpoints để giảm chi phí NAT Gateway (~$20-25/tháng) Auto Scaling: Cấu hình EC2 Auto Scaling dựa trên CPU metrics để đảm bảo high availability Quản lý Database: Triển khai và cấu hình RDS MySQL với các best practices về bảo mật Triển khai Frontend: Host static React website trên S3 với CloudFront CDN Triển khai Backend: Deploy ứng dụng Spring Boot trên EC2 với systemd service Best Practices về Security: Triển khai security groups, IAM roles, và Cognito authentication Monitoring \u0026amp; Logging: Thiết lập CloudWatch để giám sát và cảnh báo ứng dụng Sơ đồ Kiến trúc Internet\r│\r├─── CloudFront (CDN) ──\u0026gt; S3 (Frontend)\r│\r└─── API Gateway ──\u0026gt; ALB ──\u0026gt; EC2 (Backend) ──\u0026gt; RDS MySQL\r│\r└─── VPC Endpoints (S3, CloudWatch, SSM) Yêu cầu trước khi bắt đầu Tài khoản AWS với quyền phù hợp (Administrator hoặc tương đương) AWS CLI đã cài đặt và cấu hình (aws configure) EC2 Key Pair đã được tạo trong AWS region của bạn (ap-southeast-1) Hiểu biết cơ bản về các dịch vụ AWS và command line interface Quen thuộc với các khái niệm CloudFormation Chi phí ước tính Chạy hạ tầng workshop này sẽ tốn khoảng $8.90/tháng (nếu chạy 24/7):\nDịch vụ Instance Type Chi phí/tháng (USD) EC2 t3.nano $3.50 RDS MySQL db.t3.micro $2.80 API Gateway - $0.50 S3 + CloudFront - $0.80 Route 53 - $0.50 Cognito - $0.10 CloudWatch - $0.30 CI/CD (CodePipeline) - $0.40 Tổng $8.90 Cho workshop (2-3 giờ): ~$0.50-1.00\n💡 Mẹo tiết kiệm chi phí:\nXóa stack ngay sau khi hoàn thành workshop Sử dụng Free Tier cho các dịch vụ đủ điều kiện Tắt NAT Gateway khi không sử dụng (tiết kiệm ~$32/tháng) Sử dụng VPC Endpoints thay vì NAT Gateway cho production Thời gian Workshop Tổng thời gian: 2-3 giờ Triển khai Infrastructure: 15-20 phút Cấu hình Application: 30-45 phút Testing \u0026amp; Validation: 15-30 phút Cleanup: 5-10 phút Nội dung Tổng quan Workshop Chuẩn bị \u0026amp; Yêu cầu Triển khai Infrastructure với CloudFormation Cấu hình và Triển khai Backend Application Triển khai Frontend lên S3 và CloudFront Kiểm tra và Xác thực Giám sát và Xử lý sự cố Thiết lập CI/CD Pipeline Dọn dẹp tài nguyên "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/5-workshop/5.6-testing/",
	"title": "Kiểm tra và Xác thực",
	"tags": [],
	"description": "",
	"content": "Tổng quan Trong bước này, bạn sẽ thực hiện các test cases để xác nhận ứng dụng hoạt động đúng end-to-end, từ frontend qua API Gateway, Load Balancer, đến backend và database.\nBước 1: Kiểm tra Infrastructure Verify All Services Running # Check CloudFormation stack status aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].StackStatus\u0026#39; # Expected: CREATE_COMPLETE # Check EC2 instances aws ec2 describe-instances \\ --filters \u0026#34;Name=tag:aws:cloudformation:stack-name,Values=workshop-aws-dev\u0026#34; \\ \u0026#34;Name=instance-state-name,Values=running\u0026#34; \\ --region ap-southeast-1 \\ --query \u0026#39;Reservations[*].Instances[*].[InstanceId,State.Name,PrivateIpAddress]\u0026#39; \\ --output table # Check RDS status aws rds describe-db-instances \\ --db-instance-identifier workshop-aws-dev-db \\ --region ap-southeast-1 \\ --query \u0026#39;DBInstances[0].[DBInstanceIdentifier,DBInstanceStatus]\u0026#39; \\ --output table # Expected: available # Check Load Balancer aws elbv2 describe-load-balancers \\ --names workshop-aws-dev-alb \\ --region ap-southeast-1 \\ --query \u0026#39;LoadBalancers[0].[LoadBalancerName,State.Code]\u0026#39; \\ --output table # Expected: active Bước 2: Test Backend API Get API URLs ALB_DNS=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`ALBDNSName`].OutputValue\u0026#39; \\ --output text) API_URL=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`APIGatewayURL`].OutputValue\u0026#39; \\ --output text) echo \u0026#34;ALB DNS: $ALB_DNS\u0026#34; echo \u0026#34;API Gateway URL: $API_URL\u0026#34; Test Health Endpoint # Test qua ALB curl -v http://${ALB_DNS}/dna_service/actuator/health # Test qua API Gateway curl -v ${API_URL}/dna_service/actuator/health # Expected response: # {\u0026#34;status\u0026#34;:\u0026#34;UP\u0026#34;} Test User Registration # Register new user curl -X POST ${API_URL}/dna_service/auth/register \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;username\u0026#34;: \u0026#34;testuser\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;test@example.com\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;Test123!@#\u0026#34;, \u0026#34;fullName\u0026#34;: \u0026#34;Test User\u0026#34; }\u0026#39; # Expected: 200 OK with user data Test User Login # Login curl -X POST ${API_URL}/dna_service/auth/login \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;username\u0026#34;: \u0026#34;testuser\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;Test123!@#\u0026#34; }\u0026#39; # Expected: 200 OK with JWT token # Save token for next requests TOKEN=\u0026#34;\u0026lt;jwt-token-from-response\u0026gt;\u0026#34; Test Protected Endpoints # Get user profile curl -X GET ${API_URL}/dna_service/user/profile \\ -H \u0026#34;Authorization: Bearer ${TOKEN}\u0026#34; # Expected: 200 OK with user profile data Bước 3: Test Frontend Access Frontend CLOUDFRONT_URL=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`CloudFrontDomainName`].OutputValue\u0026#39; \\ --output text) echo \u0026#34;Frontend URL: https://${CLOUDFRONT_URL}\u0026#34; Mở trình duyệt và truy cập URL trên.\nManual Testing Checklist 1. Trang chủ (Home Page)\nTrang load thành công Logo và branding hiển thị đúng Navigation menu hoạt động Không có lỗi trong Console 2. User Registration\nForm validation hoạt động Có thể đăng ký user mới Hiển thị thông báo thành công Redirect đến login page 3. User Login\nCó thể đăng nhập với credentials vừa tạo JWT token được lưu trong localStorage Redirect đến dashboard sau login User menu hiển thị username 4. DNA Analysis\nCó thể upload DNA sequence file File validation hoạt động Analysis progress được hiển thị Kết quả analysis hiển thị đúng Có thể xem history 5. User Profile\nHiển thị thông tin user Có thể update profile Avatar upload hoạt động (nếu có) Logout hoạt động đúng 6. Responsive Design\nMobile view hoạt động tốt Tablet view hoạt động tốt Desktop view hoạt động tốt Bước 4: Test Database Connection Connect to RDS # Get RDS endpoint RDS_ENDPOINT=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`RDSEndpoint`].OutputValue\u0026#39; \\ --output text) # Connect via MySQL client (từ EC2 hoặc local nếu có public access) mysql -h ${RDS_ENDPOINT} -u admin -p workshop_aws Verify Tables Created -- Show all tables SHOW TABLES; -- Expected tables: -- users, dna_sequences, analysis_results, etc. -- Check user data SELECT id, username, email, created_at FROM users; -- Check DNA analysis data SELECT id, user_id, sequence_name, status, created_at FROM dna_sequences; -- Exit EXIT; Bước 5: Load Testing (Optional) Install Apache Bench # Ubuntu/Debian sudo apt-get install apache2-utils # MacOS brew install httpd # Windows # Download from Apache website Run Load Test # Test health endpoint ab -n 1000 -c 10 http://${ALB_DNS}/dna_service/actuator/health # Test login endpoint ab -n 100 -c 5 -p login-data.json -T application/json \\ ${API_URL}/dna_service/auth/login Monitor During Load Test # Watch CloudWatch metrics aws cloudwatch get-metric-statistics \\ --namespace AWS/EC2 \\ --metric-name CPUUtilization \\ --dimensions Name=AutoScalingGroupName,Value=workshop-aws-dev-asg \\ --start-time $(date -u -d \u0026#39;5 minutes ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 60 \\ --statistics Average \\ --region ap-southeast-1 Bước 6: Security Testing Test HTTPS Enforcement # CloudFront should redirect HTTP to HTTPS curl -I http://${CLOUDFRONT_URL} # Expected: 301 redirect to https:// Test CORS # Test preflight request curl -X OPTIONS ${API_URL}/dna_service/auth/login \\ -H \u0026#34;Origin: https://${CLOUDFRONT_URL}\u0026#34; \\ -H \u0026#34;Access-Control-Request-Method: POST\u0026#34; \\ -H \u0026#34;Access-Control-Request-Headers: Content-Type\u0026#34; \\ -v # Expected: CORS headers in response Test SQL Injection Protection # Try SQL injection in login curl -X POST ${API_URL}/dna_service/auth/login \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;username\u0026#34;: \u0026#34;admin\u0026#39;\\\u0026#39;\u0026#39; OR \u0026#39;\\\u0026#39;\u0026#39;1\u0026#39;\\\u0026#39;\u0026#39;=\u0026#39;\\\u0026#39;\u0026#39;1\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;anything\u0026#34; }\u0026#39; # Expected: 401 Unauthorized (not SQL error) Test XSS Protection Trong browser console:\n// Try XSS in input fields document.querySelector(\u0026#39;input[name=\u0026#34;username\u0026#34;]\u0026#39;).value = \u0026#39;\u0026lt;script\u0026gt;alert(\u0026#34;XSS\u0026#34;)\u0026lt;/script\u0026gt;\u0026#39;; Expected: Script không được execute, được escape hoặc sanitize.\nBước 7: Performance Testing Measure Page Load Time Mở Chrome DevTools → Network tab:\nFirst Contentful Paint (FCP): \u0026lt; 1.5s Largest Contentful Paint (LCP): \u0026lt; 2.5s Time to Interactive (TTI): \u0026lt; 3.5s Total Page Size: \u0026lt; 2MB Test API Response Time # Measure API response time time curl -s ${API_URL}/dna_service/actuator/health \u0026gt; /dev/null # Expected: \u0026lt; 200ms Test CloudFront Caching # First request (MISS) curl -I https://${CLOUDFRONT_URL}/assets/index.js # Second request (HIT) curl -I https://${CLOUDFRONT_URL}/assets/index.js # Check X-Cache header: Hit from cloudfront Troubleshooting Common Issues API Returns 502 Bad Gateway # Check backend health curl http://${ALB_DNS}/dna_service/actuator/health # Check target group health aws elbv2 describe-target-health \\ --target-group-arn \u0026lt;arn\u0026gt; \\ --region ap-southeast-1 # Check EC2 logs aws ssm start-session --target \u0026lt;instance-id\u0026gt; tail -f /opt/workshop/application.log Frontend Shows CORS Error Verify API Gateway CORS configuration Check backend CORS settings in application.properties Ensure CloudFront origin is whitelisted Database Connection Timeout Check RDS Security Group allows EC2 traffic Verify RDS endpoint in application.properties Test connection from EC2: telnet ${RDS_ENDPOINT} 3306 Slow Page Load Check CloudFront cache hit ratio Optimize images and assets Enable gzip compression Review CloudWatch metrics Test Results Documentation Tạo file test-results.md:\n# Workshop Test Results ## Date: 2025-12-08 ## Tester: [Your Name] ### Infrastructure Tests - [x] CloudFormation stack: CREATE_COMPLETE - [x] EC2 instances: Running - [x] RDS database: Available - [x] Load Balancer: Active ### Backend API Tests - [x] Health endpoint: OK - [x] User registration: OK - [x] User login: OK - [x] Protected endpoints: OK ### Frontend Tests - [x] Page load: OK - [x] User registration: OK - [x] User login: OK - [x] DNA analysis: OK - [x] Responsive design: OK ### Performance Tests - [x] Page load time: 1.2s - [x] API response time: 150ms - [x] CloudFront cache: Working ### Security Tests - [x] HTTPS enforcement: OK - [x] CORS: OK - [x] SQL injection protection: OK - [x] XSS protection: OK ## Issues Found None ## Recommendations - Enable CloudFront compression - Add more CloudWatch alarms - Implement rate limiting Xác nhận Testing hoàn thành Checklist:\nTất cả infrastructure services đang chạy Backend API endpoints hoạt động Frontend load và hoạt động đúng Database connection hoạt động User authentication flow hoạt động DNA analysis features hoạt động Performance đạt yêu cầu Security tests pass Test results được document Tiếp theo Sau khi testing hoàn thành:\n➡️ Giám sát và Xử lý sự cố\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/6-self-evaluation/",
	"title": "Tự đánh giá",
	"tags": [],
	"description": "",
	"content": "Trong thời gian thực tập tại [First Cloud AI Journey Office] từ [08/09/2025] đến [30/12/2025], tôi đã có cơ hội tham gia vào [mô tả dự án hoặc công việc chính].\nQuá trình này giúp tôi nâng cao khả năng [liệt kê kỹ năng: phân tích dữ liệu, lập trình, lập kế hoạch, thuyết trình, hợp tác nhóm…].\nTôi luôn duy trì tinh thần học hỏi, chủ động trong công việc và phối hợp hiệu quả với đồng nghiệp nhằm đạt được mục tiêu chung của nhóm.\nDưới đây là phần tự đánh giá chi tiết theo các tiêu chí đã định:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về công việc, vận dụng kiến thức vào thực tế, sử dụng công cụ phù hợp ✅ ☐ ☐ 2 Khả năng học hỏi Nhanh chóng tiếp thu kiến thức mới, chủ động học hỏi từ các tình huống thực tế ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mới mà không cần nhắc nhở ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành nhiệm vụ đúng hạn, đảm bảo chất lượng công việc ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, quy trình làm việc và nội quy của tổ chức ☐ ✅ ☐ 6 Tính cầu tiến Sẵn sàng nhận phản hồi và cải thiện bản thân ✅ ☐ ☐ 7 Giao tiếp Trình bày ý tưởng rõ ràng, dễ hiểu, phản hồi hiệu quả ☐ ✅ ☐ 8 Hợp tác nhóm Phối hợp hiệu quả với đồng nghiệp, tham gia đóng góp vào nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Giữ thái độ tôn trọng với đồng nghiệp và môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Phân tích vấn đề, đưa ra giải pháp khả thi và sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Mức độ hoàn thành nhiệm vụ và đóng góp tích cực vào tiến độ chung ☐ ✅ ☐ 12 Tổng thể Đánh giá chung về nỗ lực, khả năng thích nghi và tiến bộ trong suốt quá trình thực tập ✅ ☐ ☐ Cần cải thiện Tăng cường quản lý thời gian để hoàn thành công việc hiệu quả hơn Rèn luyện kỹ năng phân tích và giải quyết vấn đề phức tạp Chủ động hơn trong giao tiếp nội bộ để nâng cao hiệu quả phối hợp nhóm "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/5-workshop/5.7-monitoring/",
	"title": "Giám sát và Xử lý sự cố",
	"tags": [],
	"description": "",
	"content": "Tổng quan Trong bước này, bạn sẽ học cách giám sát ứng dụng, xem logs, và xử lý các sự cố thường gặp sử dụng CloudWatch, CloudWatch Logs, và các công cụ AWS khác.\nCloudWatch Metrics EC2 Metrics # CPU Utilization aws cloudwatch get-metric-statistics \\ --namespace AWS/EC2 \\ --metric-name CPUUtilization \\ --dimensions Name=AutoScalingGroupName,Value=workshop-aws-dev-asg \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 300 \\ --statistics Average,Maximum \\ --region ap-southeast-1 # Memory Utilization (nếu có CloudWatch Agent) aws cloudwatch get-metric-statistics \\ --namespace CWAgent \\ --metric-name mem_used_percent \\ --dimensions Name=AutoScalingGroupName,Value=workshop-aws-dev-asg \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 300 \\ --statistics Average \\ --region ap-southeast-1 RDS Metrics # Database Connections aws cloudwatch get-metric-statistics \\ --namespace AWS/RDS \\ --metric-name DatabaseConnections \\ --dimensions Name=DBInstanceIdentifier,Value=workshop-aws-dev-db \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 300 \\ --statistics Average,Maximum \\ --region ap-southeast-1 # CPU Utilization aws cloudwatch get-metric-statistics \\ --namespace AWS/RDS \\ --metric-name CPUUtilization \\ --dimensions Name=DBInstanceIdentifier,Value=workshop-aws-dev-db \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 300 \\ --statistics Average \\ --region ap-southeast-1 Application Load Balancer Metrics # Request Count aws cloudwatch get-metric-statistics \\ --namespace AWS/ApplicationELB \\ --metric-name RequestCount \\ --dimensions Name=LoadBalancer,Value=app/workshop-aws-dev-alb/xxxxx \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 300 \\ --statistics Sum \\ --region ap-southeast-1 # Target Response Time aws cloudwatch get-metric-statistics \\ --namespace AWS/ApplicationELB \\ --metric-name TargetResponseTime \\ --dimensions Name=LoadBalancer,Value=app/workshop-aws-dev-alb/xxxxx \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 300 \\ --statistics Average \\ --region ap-southeast-1 CloudWatch Logs Xem Application Logs # List log streams aws logs describe-log-streams \\ --log-group-name /aws/workshop-aws/dev/application \\ --order-by LastEventTime \\ --descending \\ --max-items 5 \\ --region ap-southeast-1 # Tail logs (real-time) aws logs tail /aws/workshop-aws/dev/application \\ --follow \\ --region ap-southeast-1 # Filter logs by pattern aws logs filter-log-events \\ --log-group-name /aws/workshop-aws/dev/application \\ --filter-pattern \u0026#34;ERROR\u0026#34; \\ --start-time $(date -d \u0026#39;1 hour ago\u0026#39; +%s)000 \\ --region ap-southeast-1 # Search for specific errors aws logs filter-log-events \\ --log-group-name /aws/workshop-aws/dev/application \\ --filter-pattern \u0026#34;NullPointerException\u0026#34; \\ --start-time $(date -d \u0026#39;1 hour ago\u0026#39; +%s)000 \\ --region ap-southeast-1 Xem EC2 System Logs # Get instance ID INSTANCE_ID=$(aws ec2 describe-instances \\ --filters \u0026#34;Name=tag:aws:cloudformation:stack-name,Values=workshop-aws-dev\u0026#34; \\ \u0026#34;Name=instance-state-name,Values=running\u0026#34; \\ --region ap-southeast-1 \\ --query \u0026#39;Reservations[0].Instances[0].InstanceId\u0026#39; \\ --output text) # Get console output aws ec2 get-console-output \\ --instance-id $INSTANCE_ID \\ --region ap-southeast-1 \\ --output text CloudWatch Alarms Xem Existing Alarms # List all alarms aws cloudwatch describe-alarms \\ --alarm-name-prefix workshop-aws-dev \\ --region ap-southeast-1 # Get alarm history aws cloudwatch describe-alarm-history \\ --alarm-name workshop-aws-dev-cpu-high \\ --max-records 10 \\ --region ap-southeast-1 Tạo Custom Alarms # Alarm cho High Error Rate aws cloudwatch put-metric-alarm \\ --alarm-name workshop-aws-dev-high-error-rate \\ --alarm-description \u0026#34;Alert when error rate exceeds 5%\u0026#34; \\ --metric-name 5XXError \\ --namespace AWS/ApplicationELB \\ --statistic Sum \\ --period 300 \\ --evaluation-periods 2 \\ --threshold 10 \\ --comparison-operator GreaterThanThreshold \\ --dimensions Name=LoadBalancer,Value=app/workshop-aws-dev-alb/xxxxx \\ --alarm-actions arn:aws:sns:ap-southeast-1:123456789012:workshop-aws-dev-alarms \\ --region ap-southeast-1 # Alarm cho Database Connections aws cloudwatch put-metric-alarm \\ --alarm-name workshop-aws-dev-high-db-connections \\ --alarm-description \u0026#34;Alert when DB connections exceed 80\u0026#34; \\ --metric-name DatabaseConnections \\ --namespace AWS/RDS \\ --statistic Average \\ --period 300 \\ --evaluation-periods 2 \\ --threshold 80 \\ --comparison-operator GreaterThanThreshold \\ --dimensions Name=DBInstanceIdentifier,Value=workshop-aws-dev-db \\ --alarm-actions arn:aws:sns:ap-southeast-1:123456789012:workshop-aws-dev-alarms \\ --region ap-southeast-1 CloudWatch Dashboards Tạo Dashboard # Tạo dashboard JSON cat \u0026gt; dashboard.json \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; { \u0026#34;widgets\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;metric\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;metrics\u0026#34;: [ [\u0026#34;AWS/EC2\u0026#34;, \u0026#34;CPUUtilization\u0026#34;, {\u0026#34;stat\u0026#34;: \u0026#34;Average\u0026#34;}] ], \u0026#34;period\u0026#34;: 300, \u0026#34;stat\u0026#34;: \u0026#34;Average\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;ap-southeast-1\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;EC2 CPU Utilization\u0026#34; } }, { \u0026#34;type\u0026#34;: \u0026#34;metric\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;metrics\u0026#34;: [ [\u0026#34;AWS/RDS\u0026#34;, \u0026#34;DatabaseConnections\u0026#34;, {\u0026#34;stat\u0026#34;: \u0026#34;Average\u0026#34;}] ], \u0026#34;period\u0026#34;: 300, \u0026#34;stat\u0026#34;: \u0026#34;Average\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;ap-southeast-1\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;RDS Connections\u0026#34; } }, { \u0026#34;type\u0026#34;: \u0026#34;metric\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;metrics\u0026#34;: [ [\u0026#34;AWS/ApplicationELB\u0026#34;, \u0026#34;RequestCount\u0026#34;, {\u0026#34;stat\u0026#34;: \u0026#34;Sum\u0026#34;}] ], \u0026#34;period\u0026#34;: 300, \u0026#34;stat\u0026#34;: \u0026#34;Sum\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;ap-southeast-1\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;ALB Request Count\u0026#34; } } ] } EOF # Create dashboard aws cloudwatch put-dashboard \\ --dashboard-name workshop-aws-dev-dashboard \\ --dashboard-body file://dashboard.json \\ --region ap-southeast-1 Xem Dashboard Mở CloudWatch Console → Dashboards → workshop-aws-dev-dashboard\nTroubleshooting Common Issues Issue 1: High CPU Usage Symptoms:\nEC2 CPU \u0026gt; 80% Slow response times CloudWatch alarm triggered Diagnosis:\n# Check CPU metrics aws cloudwatch get-metric-statistics \\ --namespace AWS/EC2 \\ --metric-name CPUUtilization \\ --dimensions Name=AutoScalingGroupName,Value=workshop-aws-dev-asg \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 60 \\ --statistics Average,Maximum \\ --region ap-southeast-1 # SSH vào EC2 và check processes aws ssm start-session --target $INSTANCE_ID top -bn1 | head -20 Solutions:\nScale up: Tăng instance type Scale out: Tăng số lượng instances Optimize code: Profile và optimize application Add caching: Implement Redis/ElastiCache Issue 2: Database Connection Pool Exhausted Symptoms:\n\u0026ldquo;Too many connections\u0026rdquo; errors Slow database queries Application timeouts Diagnosis:\n# Check DB connections aws cloudwatch get-metric-statistics \\ --namespace AWS/RDS \\ --metric-name DatabaseConnections \\ --dimensions Name=DBInstanceIdentifier,Value=workshop-aws-dev-db \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 60 \\ --statistics Average,Maximum \\ --region ap-southeast-1 # Connect to DB and check mysql -h $RDS_ENDPOINT -u admin -p SHOW PROCESSLIST; SHOW STATUS LIKE \u0026#39;Threads_connected\u0026#39;; Solutions:\nIncrease connection pool size trong application.properties Fix connection leaks trong code Scale up RDS instance Implement connection pooling best practices Issue 3: High Memory Usage Symptoms:\nOut of memory errors Application crashes Slow performance Diagnosis:\n# Check memory on EC2 aws ssm start-session --target $INSTANCE_ID free -h ps aux --sort=-%mem | head -10 # Check Java heap usage jstat -gc \u0026lt;java-pid\u0026gt; Solutions:\nIncrease JVM heap size: -Xmx1024m Fix memory leaks Scale up instance type Implement proper garbage collection tuning Issue 4: 502 Bad Gateway Symptoms:\nUsers receive 502 errors ALB cannot reach backend Health checks failing Diagnosis:\n# Check target health aws elbv2 describe-target-health \\ --target-group-arn \u0026lt;arn\u0026gt; \\ --region ap-southeast-1 # Check backend logs aws logs tail /aws/workshop-aws/dev/application --follow # Check Security Groups aws ec2 describe-security-groups \\ --group-ids \u0026lt;ec2-sg-id\u0026gt; \\ --region ap-southeast-1 Solutions:\nVerify backend is running: systemctl status workshop Check Security Group allows ALB traffic Verify health check path is correct Check application logs for errors Issue 5: Slow Page Load Symptoms:\nFrontend takes \u0026gt; 3s to load Poor user experience High bounce rate Diagnosis:\n# Check CloudFront metrics aws cloudwatch get-metric-statistics \\ --namespace AWS/CloudFront \\ --metric-name BytesDownloaded \\ --dimensions Name=DistributionId,Value=$DIST_ID \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 300 \\ --statistics Sum \\ --region us-east-1 # Check cache hit ratio curl -I https://$CLOUDFRONT_URL/assets/index.js | grep X-Cache Solutions:\nEnable CloudFront compression Optimize images and assets Implement lazy loading Increase cache TTL Use CDN for static assets Performance Monitoring Application Performance Monitoring (APM) Thêm Spring Boot Actuator metrics:\n# application.properties management.endpoints.web.exposure.include=health,info,metrics,prometheus management.metrics.export.cloudwatch.enabled=true management.metrics.export.cloudwatch.namespace=WorkshopApp management.metrics.export.cloudwatch.step=1m Custom Metrics Publish custom metrics từ application:\n@Autowired private MeterRegistry meterRegistry; public void recordDNAAnalysis() { Counter.builder(\u0026#34;dna.analysis.count\u0026#34;) .tag(\u0026#34;type\u0026#34;, \u0026#34;sequence\u0026#34;) .register(meterRegistry) .increment(); } Query Custom Metrics aws cloudwatch get-metric-statistics \\ --namespace WorkshopApp \\ --metric-name dna.analysis.count \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 300 \\ --statistics Sum \\ --region ap-southeast-1 Log Analysis CloudWatch Logs Insights # Query error logs aws logs start-query \\ --log-group-name /aws/workshop-aws/dev/application \\ --start-time $(date -d \u0026#39;1 hour ago\u0026#39; +%s) \\ --end-time $(date +%s) \\ --query-string \u0026#39;fields @timestamp, @message | filter @message like /ERROR/ | sort @timestamp desc | limit 20\u0026#39; \\ --region ap-southeast-1 # Get query results aws logs get-query-results \\ --query-id \u0026lt;query-id\u0026gt; \\ --region ap-southeast-1 Common Log Queries 1. Top 10 errors:\nfields @timestamp, @message\r| filter @message like /ERROR/\r| stats count() by @message\r| sort count desc\r| limit 10 2. Slow queries:\nfields @timestamp, @message\r| filter @message like /Hibernate/\r| filter @message like /ms/\r| parse @message /(?\u0026lt;duration\u0026gt;\\d+)ms/\r| filter duration \u0026gt; 1000\r| sort @timestamp desc 3. API response times:\nfields @timestamp, @message\r| filter @message like /Request processed/\r| parse @message /in (?\u0026lt;duration\u0026gt;\\d+)ms/\r| stats avg(duration), max(duration), min(duration) Best Practices 1. Set Up Alerts CPU \u0026gt; 80% for 5 minutes Memory \u0026gt; 85% for 5 minutes Disk \u0026gt; 90% 5XX errors \u0026gt; 10 in 5 minutes Database connections \u0026gt; 80% of max 2. Regular Health Checks # Daily health check script #!/bin/bash echo \u0026#34;=== Daily Health Check ===\u0026#34; echo \u0026#34;Date: $(date)\u0026#34; # Check stack status echo \u0026#34;CloudFormation Stack:\u0026#34; aws cloudformation describe-stacks --stack-name workshop-aws-dev --query \u0026#39;Stacks[0].StackStatus\u0026#39; # Check EC2 echo \u0026#34;EC2 Instances:\u0026#34; aws ec2 describe-instances --filters \u0026#34;Name=tag:aws:cloudformation:stack-name,Values=workshop-aws-dev\u0026#34; --query \u0026#39;Reservations[*].Instances[*].[InstanceId,State.Name]\u0026#39; # Check RDS echo \u0026#34;RDS Database:\u0026#34; aws rds describe-db-instances --db-instance-identifier workshop-aws-dev-db --query \u0026#39;DBInstances[0].DBInstanceStatus\u0026#39; # Check API echo \u0026#34;API Health:\u0026#34; curl -s $API_URL/dna_service/actuator/health | jq . 3. Log Retention Development: 3-7 days Production: 30-90 days Compliance: 1-7 years 4. Cost Monitoring # Check CloudWatch costs aws ce get-cost-and-usage \\ --time-period Start=2025-12-01,End=2025-12-08 \\ --granularity DAILY \\ --metrics BlendedCost \\ --filter file://filter.json Monitoring Checklist CloudWatch metrics được thu thập CloudWatch Logs được cấu hình Alarms được thiết lập SNS notifications hoạt động Dashboard được tạo Log retention được cấu hình Custom metrics được publish Health checks hoạt động Performance baseline được thiết lập Tiếp theo Sau khi thiết lập monitoring:\n➡️ Dọn dẹp tài nguyên\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/7-feedback/",
	"title": "Chia sẻ, đóng góp ý kiến",
	"tags": [],
	"description": "",
	"content": "Đánh giá chung 1. Môi trường làm việc\nTrong thời gian training tại AWS, mình cảm nhận môi trường làm việc rất chuyên nghiệp và năng động. Mọi người giao tiếp thẳng thắn, rõ ràng và luôn tạo cảm giác thoải mái khi trao đổi. Điều mình thích nhất là văn hóa “learning by doing” – khuyến khích thực hành nhiều hơn lý thuyết. Tuy nhiên, mình nghĩ AWS có thể tổ chức thêm một số buổi chia sẻ nội bộ để thực tập sinh hiểu sâu hơn về các team khác.\n2. Sự hỗ trợ của mentor / team admin\nMentor hỗ trợ rất tận tâm, luôn đưa ra định hướng rõ ràng trước mỗi nhiệm vụ. Khi gặp khó khăn, mentor không giải quyết thay mà gợi mở để mình tự tìm ra hướng giải quyết – điều này giúp mình tiến bộ rất nhanh. Team điều phối cũng phản hồi nhanh, hỗ trợ tài khoản, tài liệu và quyền truy cập… rất kịp thời.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nNhững nội dung training liên quan chặt chẽ với chuyên ngành An toàn thông tin của mình, đặc biệt là phần về IAM, kiến trúc bảo mật và quy trình quản trị tài nguyên AWS. Mình cũng được tiếp cận thêm những công nghệ mà chương trình học ở trường chưa đề cập đến, giúp kiến thức được mở rộng đáng kể.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như phân tích log, triển khai hạ tầng theo best practice, xử lý tình huống giả lập và quản lý tài nguyên AWS. Ngoài kỹ năng kỹ thuật, mình còn nâng cao khả năng giao tiếp, planning và quản lý thời gian nhờ việc làm việc theo sprint và deadline rõ ràng.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nTinh thần đồng đội trong team rất tốt. Mọi người chủ động hỗ trợ nhau, chia sẻ kinh nghiệm mà không ngần ngại. Môi trường nghiêm túc nhưng vẫn thoải mái, dễ tương tác. Nhờ vậy, mình nhanh chóng hòa nhập và tự tin hơn khi tham gia vào các buổi thảo luận kỹ thuật.\n6. Chính sách / phúc lợi cho thực tập sinh\nChính sách dành cho thực tập sinh rõ ràng và linh hoạt. Thời gian làm việc phù hợp với lịch học, tạo điều kiện để mình cân bằng giữa việc học và training. Ngoài ra, việc được tham dự các workshop nội bộ và buổi đào tạo chuyên môn là một điểm cộng lớn.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập?\n→ Việc được tiếp xúc trực tiếp với hệ thống AWS thật và luôn có mentor hỗ trợ đúng lúc.\nNếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao?\n→ Có. Vì môi trường đào tạo chuyên nghiệp, định hướng rõ ràng và mang lại kỹ năng thực tế mà ít nơi khác có.\nĐề xuất \u0026amp; mong muốn Mong muốn có thêm các mini-project theo nhóm để tăng trải nghiệm. Nếu có cơ hội, mình muốn tiếp tục chương trình ở cấp độ cao hơn như AWS Internship / Cloud Engineer Trainee. Hy vọng sẽ có thêm nội dung chuyên sâu liên quan đến bảo mật cloud và ứng dụng AI trong giám sát hệ thống. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/5-workshop/5.9-cleanup/",
	"title": "Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "Tổng quan Sau khi hoàn thành workshop, bạn cần xóa tất cả tài nguyên để tránh phát sinh chi phí không mong muốn. CloudFormation sẽ tự động xóa hầu hết các tài nguyên, nhưng một số cần xóa thủ công.\nBước 1: Xóa S3 Bucket Contents CloudFormation không thể xóa S3 buckets có chứa objects. Bạn cần xóa contents trước:\n# Lấy bucket names từ outputs FRONTEND_BUCKET=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`FrontendBucketName`].OutputValue\u0026#39; \\ --output text) # Xóa tất cả objects trong frontend bucket aws s3 rm s3://$FRONTEND_BUCKET --recursive --region ap-southeast-1 # Nếu có backend bucket BACKEND_BUCKET=\u0026#34;workshop-aws-dev-backend-$(aws sts get-caller-identity --query Account --output text)-ap-southeast-1\u0026#34; aws s3 rm s3://$BACKEND_BUCKET --recursive --region ap-southeast-1 2\u0026gt;/dev/null || true Bước 2: Xóa CloudFormation Stack Cách 1: Sử dụng Deploy Script Windows:\ncd aws deploy.bat delete Linux/Mac:\ncd aws ./deploy.sh delete Cách 2: Sử dụng AWS CLI aws cloudformation delete-stack \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 Bước 3: Theo dõi Quá trình Xóa # Kiểm tra status aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].StackStatus\u0026#39; # Đợi stack bị xóa hoàn toàn (có thể mất 10-15 phút) aws cloudformation wait stack-delete-complete \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 Qua AWS Console:\nMở CloudFormation Console Chọn stack workshop-aws-dev Tab Events: Xem resources đang bị xóa Stack sẽ biến mất khỏi danh sách khi xóa hoàn tất Bước 4: Xác nhận Tài nguyên đã bị Xóa Kiểm tra VPC # Không nên thấy VPC của workshop aws ec2 describe-vpcs \\ --filters \u0026#34;Name=tag:aws:cloudformation:stack-name,Values=workshop-aws-dev\u0026#34; \\ --region ap-southeast-1 Kiểm tra EC2 Instances # Không nên thấy instances của workshop aws ec2 describe-instances \\ --filters \u0026#34;Name=tag:aws:cloudformation:stack-name,Values=workshop-aws-dev\u0026#34; \\ --region ap-southeast-1 \\ --query \u0026#39;Reservations[*].Instances[*].[InstanceId,State.Name]\u0026#39; Kiểm tra RDS # Không nên thấy RDS instance (có thể có snapshot) aws rds describe-db-instances \\ --region ap-southeast-1 \\ --query \u0026#39;DBInstances[?DBInstanceIdentifier==`workshop-aws-dev-db`]\u0026#39; Kiểm tra S3 Buckets # Buckets nên đã bị xóa aws s3 ls | grep workshop-aws-dev Bước 5: Xóa RDS Snapshots (Optional) CloudFormation tạo snapshot trước khi xóa RDS. Nếu không cần, xóa để tránh phí lưu trữ:\n# List snapshots aws rds describe-db-snapshots \\ --region ap-southeast-1 \\ --query \u0026#39;DBSnapshots[?contains(DBSnapshotIdentifier,`workshop-aws-dev`)].DBSnapshotIdentifier\u0026#39; # Xóa snapshot aws rds delete-db-snapshot \\ --db-snapshot-identifier \u0026lt;snapshot-id\u0026gt; \\ --region ap-southeast-1 Bước 6: Xóa CloudWatch Logs (Optional) Log groups không tự động bị xóa:\n# List log groups aws logs describe-log-groups \\ --log-group-name-prefix \u0026#34;/aws/workshop-aws\u0026#34; \\ --region ap-southeast-1 # Xóa log groups aws logs delete-log-group \\ --log-group-name \u0026#34;/aws/workshop-aws/dev/application\u0026#34; \\ --region ap-southeast-1 Bước 7: Xóa EC2 Key Pair (Optional) Nếu không cần key pair nữa:\naws ec2 delete-key-pair \\ --key-name workshop-aws-key \\ --region ap-southeast-1 # Xóa file .pem local rm workshop-aws-key.pem Troubleshooting Stack Deletion Failed Nếu stack deletion bị lỗi:\nXem lỗi: aws cloudformation describe-stack-events \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;StackEvents[?ResourceStatus==`DELETE_FAILED`].[LogicalResourceId,ResourceStatusReason]\u0026#39; \\ --output table Các lỗi thường gặp: Lỗi: \u0026ldquo;S3 bucket is not empty\u0026rdquo;\nXóa tất cả objects trong bucket Thử delete stack lại Lỗi: \u0026ldquo;Network interface is in use\u0026rdquo;\nĐợi vài phút để ENIs được release Thử delete stack lại Lỗi: \u0026ldquo;Resource being used by another resource\u0026rdquo;\nXác định resource dependencies Xóa dependent resources trước Force delete: # Retain problematic resources và xóa stack aws cloudformation delete-stack \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --retain-resources \u0026lt;ResourceLogicalId\u0026gt; # Sau đó xóa resources thủ công Checklist Cleanup Đảm bảo tất cả tài nguyên đã bị xóa:\nCloudFormation stack đã bị xóa S3 buckets đã bị xóa EC2 instances đã terminated RDS database đã bị xóa Load Balancer đã bị xóa VPC và subnets đã bị xóa CloudFront distribution đã bị disabled và xóa NAT Gateway đã bị xóa Elastic IPs đã bị released RDS snapshots đã bị xóa (optional) CloudWatch log groups đã bị xóa (optional) EC2 Key Pair đã bị xóa (optional) Xác nhận Không còn Chi phí Sau 24-48 giờ, kiểm tra AWS Cost Explorer để đảm bảo không còn chi phí phát sinh từ workshop.\nKết luận Bạn đã hoàn thành workshop và dọn dẹp tất cả tài nguyên thành công!\nNhững gì bạn đã học: ✅ Triển khai full-stack application trên AWS ✅ Infrastructure as Code với CloudFormation ✅ AWS networking và security best practices ✅ Cost optimization strategies ✅ Monitoring và troubleshooting\nTài nguyên tiếp theo:\nAWS Well-Architected Framework AWS Solutions Library AWS Workshops Cảm ơn bạn đã tham gia workshop! 🎉\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/5-workshop/5.8-cicd-pipeline/",
	"title": "Thiết lập CI/CD Pipeline",
	"tags": [],
	"description": "",
	"content": "Tổng quan Trong phần này, bạn sẽ thiết lập một CI/CD pipeline hoàn chỉnh sử dụng AWS CodePipeline, CodeBuild và GitLab CI/CD để tự động hóa quá trình build và deploy cho cả backend và frontend.\nKiến trúc GitLab → S3 (Artifacts) → CodePipeline → CodeBuild (Backend) → EC2\r↓\rCodeBuild (Frontend) → S3/CloudFront Các thành phần CI/CD 1. GitLab CI/CD Tự động build và đóng gói source code Upload artifacts lên S3 Kích hoạt AWS CodePipeline 2. AWS CodePipeline Điều phối toàn bộ quy trình deployment Giám sát S3 để phát hiện artifacts mới Kích hoạt các CodeBuild projects 3. AWS CodeBuild Backend Build: Biên dịch ứng dụng Spring Boot thành JAR Frontend Build: Build ứng dụng React với Vite Deploy lên các dịch vụ AWS tương ứng Bước 1: Cấu hình GitLab CI/CD 1.1. Thiết lập GitLab CI/CD Variables Trong GitLab project, vào Settings → CI/CD → Variables và thêm:\nVariable Value Protected Masked AWS_ACCESS_KEY_ID AWS Access Key của bạn ✅ ✅ AWS_SECRET_ACCESS_KEY AWS Secret Key của bạn ✅ ✅ 1.2. Xem lại cấu hình GitLab CI File .gitlab-ci.yml trong thư mục gốc project:\nstages: - deploy deploy-to-aws: stage: deploy image: amazon/aws-cli:latest before_script: - | aws configure set aws_access_key_id $AWS_ACCESS_KEY_ID aws configure set aws_secret_access_key $AWS_SECRET_ACCESS_KEY aws configure set region ap-southeast-1 script: - echo \u0026#34;📦 Đang tạo source.zip...\u0026#34; - | apk add zip zip -r source.zip . \\ -x \u0026#34;*.git*\u0026#34; \\ -x \u0026#34;node_modules/*\u0026#34; \\ -x \u0026#34;.idea/*\u0026#34; \\ -x \u0026#34;target/*\u0026#34; \\ -x \u0026#34;*.zip\u0026#34; - echo \u0026#34;📤 Đang upload lên S3...\u0026#34; - | aws s3 cp source.zip \\ s3://workshop-aws-dev-artifacts-502310717700-ap-southeast-1/source.zip - echo \u0026#34;✅ Upload hoàn tất! CodePipeline sẽ tự động kích hoạt.\u0026#34; only: - main when: on_success Chức năng:\nĐóng gói toàn bộ project thành source.zip Upload lên S3 artifacts bucket Tự động kích hoạt CodePipeline Bước 2: Deploy CodePipeline với CloudFormation 2.1. Xem lại Pipeline Template Template CloudFormation cicd-pipeline.yaml tạo:\nCodePipeline với S3 source CodeBuild project cho backend CodeBuild project cho frontend IAM roles và permissions 2.2. Deploy Pipeline Stack aws cloudformation create-stack \\ --stack-name workshop-aws-dev-cicd \\ --template-body file://aws/cicd-pipeline.yaml \\ --parameters \\ ParameterKey=ProjectName,ParameterValue=workshop-aws \\ ParameterKey=Environment,ParameterValue=dev \\ ParameterKey=SourceProvider,ParameterValue=S3 \\ ParameterKey=ArtifactBucketName,ParameterValue=workshop-aws-dev-artifacts-502310717700-ap-southeast-1 \\ --capabilities CAPABILITY_NAMED_IAM \\ --region ap-southeast-1 2.3. Chờ Stack tạo xong aws cloudformation wait stack-create-complete \\ --stack-name workshop-aws-dev-cicd \\ --region ap-southeast-1 Thời gian dự kiến: 3-5 phút\nBước 3: Cấu hình CodeBuild Projects 3.1. Backend BuildSpec CodeBuild sử dụng buildspec-backend.yml:\nversion: 0.2 phases: pre_build: commands: - echo \u0026#34;Đang cài đặt Maven...\u0026#34; - yum install -y maven build: commands: - echo \u0026#34;Đang build Backend JAR...\u0026#34; - cd BE/workshop_BE - mvn clean package -DskipTests post_build: commands: - echo \u0026#34;Đang upload JAR lên S3...\u0026#34; - aws s3 cp target/workshop-0.0.1-SNAPSHOT.jar \\ s3://workshop-aws-dev-backend-502310717700-ap-southeast-1/jars/ - echo \u0026#34;Đang deploy lên EC2...\u0026#34; - aws ssm send-command \\ --instance-ids i-09fdbf7739ee37b32 \\ --document-name \u0026#34;AWS-RunShellScript\u0026#34; \\ --parameters commands=[ \u0026#34;cd /opt/workshop\u0026#34;, \u0026#34;aws s3 cp s3://workshop-aws-dev-backend-502310717700-ap-southeast-1/jars/workshop-0.0.1-SNAPSHOT.jar .\u0026#34;, \u0026#34;sudo systemctl restart workshop.service\u0026#34; ] artifacts: files: - \u0026#39;**/*\u0026#39; 3.2. Frontend BuildSpec CodeBuild sử dụng buildspec-frontend.yml:\nversion: 0.2 phases: pre_build: commands: - echo \u0026#34;Đang cài đặt Node.js...\u0026#34; - curl -sL https://rpm.nodesource.com/setup_18.x | bash - - yum install -y nodejs build: commands: - echo \u0026#34;Đang build Frontend...\u0026#34; - cd FE - npm install - npm run build post_build: commands: - echo \u0026#34;Đang deploy lên S3...\u0026#34; - aws s3 sync dist/ \\ s3://workshop-aws-dev-frontend-502310717700-ap-southeast-1/ \\ --delete - echo \u0026#34;Đang invalidate CloudFront...\u0026#34; - aws cloudfront create-invalidation \\ --distribution-id E3K48K7CPOOLHZ \\ --paths \u0026#34;/*\u0026#34; artifacts: files: - \u0026#39;FE/dist/**/*\u0026#39; Bước 4: Test CI/CD Pipeline 4.1. Kích hoạt Pipeline từ GitLab Thực hiện thay đổi code và push lên branch main:\ngit add . git commit -m \u0026#34;Test CI/CD pipeline\u0026#34; git push origin main 4.2. Theo dõi GitLab Pipeline Vào GitLab → CI/CD → Pipelines Xem job deploy-to-aws Xác nhận upload lên S3 thành công 4.3. Theo dõi AWS CodePipeline Vào AWS Console → CodePipeline Chọn workshop-aws-dev-pipeline Xem các giai đoạn pipeline: Source: Phát hiện source.zip mới trong S3 Build-Backend: Build JAR và deploy lên EC2 Build-Frontend: Build React app và deploy lên S3/CloudFront 4.4. Kiểm tra Build Logs Để xem logs chi tiết:\nClick vào Details ở bất kỳ stage nào Xem Build logs trong CodeBuild Kiểm tra lỗi hoặc cảnh báo Bước 5: Xác nhận Deployment 5.1. Test Backend API curl https://98385v3jef.execute-api.ap-southeast-1.amazonaws.com/dev/dna_service/actuator/health Kết quả mong đợi:\n{\u0026#34;status\u0026#34;:\u0026#34;UP\u0026#34;} 5.2. Test Frontend Mở trình duyệt và truy cập:\nhttps://d3gmmg22uirq0t.cloudfront.net Xác nhận ứng dụng load với các thay đổi mới nhất.\nSơ đồ luồng Pipeline ┌─────────────┐\r│ GitLab │\r│ Commit │\r└──────┬──────┘\r│\r▼\r┌─────────────┐\r│ GitLab CI │\r│ Build \u0026amp; Zip │\r└──────┬──────┘\r│\r▼\r┌─────────────┐\r│ S3 Bucket │\r│ source.zip │\r└──────┬──────┘\r│\r▼\r┌─────────────────────┐\r│ CodePipeline │\r│ Phát hiện thay đổi│\r└──────┬──────────────┘\r│\r├─────────────────┬─────────────────┐\r▼ ▼ ▼\r┌─────────────┐ ┌─────────────┐ ┌─────────────┐\r│ CodeBuild │ │ CodeBuild │ │ CloudWatch │\r│ Backend │ │ Frontend │ │ Logs │\r└──────┬──────┘ └──────┬──────┘ └─────────────┘\r│ │\r▼ ▼\r┌─────────────┐ ┌─────────────┐\r│ EC2 │ │ S3 + CDN │\r│ Backend │ │ Frontend │\r└─────────────┘ └─────────────┘ Xử lý sự cố Pipeline không kích hoạt Vấn đề: CodePipeline không chạy sau khi push GitLab\nGiải pháp:\nKiểm tra S3 bucket có file source.zip Xác minh cấu hình source của CodePipeline Kiểm tra IAM permissions cho CodePipeline Backend Build thất bại Vấn đề: CodeBuild backend lỗi Maven\nGiải pháp:\nKiểm tra cú pháp buildspec-backend.yml Xác minh Maven dependencies trong pom.xml Xem CodeBuild logs để tìm lỗi cụ thể Đảm bảo EC2 instance có SSM Agent đang chạy Frontend Build thất bại Vấn đề: CodeBuild frontend lỗi npm\nGiải pháp:\nKiểm tra cú pháp buildspec-frontend.yml Xác minh dependencies trong package.json Kiểm tra tương thích phiên bản Node.js Đảm bảo S3 bucket permissions đúng Deployment thất bại Vấn đề: Build thành công nhưng deployment lỗi\nGiải pháp:\nKiểm tra EC2 Security Groups cho phép SSM Xác minh tên S3 bucket đúng Kiểm tra CloudFront distribution ID Xem lại IAM role permissions Best Practices 1. Environment Variables Lưu dữ liệu nhạy cảm trong GitLab CI/CD variables Dùng AWS Systems Manager Parameter Store cho application configs Không bao giờ commit credentials vào Git 2. Tối ưu Build Cache dependencies (Maven .m2, npm node_modules) Dùng Docker images nhỏ hơn để build nhanh hơn Chạy song song các build stages độc lập 3. Chiến lược Deployment Dùng blue-green deployment cho zero downtime Implement health checks trước khi route traffic Giữ khả năng rollback sẵn sàng 4. Monitoring Bật CloudWatch Logs cho tất cả CodeBuild projects Thiết lập SNS notifications cho pipeline failures Theo dõi build times và tối ưu bottlenecks Tối ưu Chi phí Giá CodeBuild Build minutes: $0.005 mỗi phút (general1.small) Build thông thường: 5-10 phút Chi phí mỗi build: ~$0.025-0.05 Giá CodePipeline Active pipeline: $1.00 mỗi tháng Free tier: 1 active pipeline mỗi tháng Ước tính Chi phí Hàng tháng 10 deployments/ngày: ~$15-20/tháng Bao gồm: CodePipeline + CodeBuild + S3 storage Tóm tắt Bạn đã thiết lập thành công một CI/CD pipeline hoàn chỉnh:\n✅ Tự động build và đóng gói code từ GitLab\n✅ Upload artifacts lên S3\n✅ Kích hoạt AWS CodePipeline khi có thay đổi\n✅ Build backend JAR với Maven\n✅ Build frontend với Vite\n✅ Deploy backend lên EC2\n✅ Deploy frontend lên S3/CloudFront\n✅ Cung cấp monitoring và logging\nTiếp theo: Dọn dẹp Tài nguyên\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://phuong721.github.io/learning-aws/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]