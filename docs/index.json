[
{
	"uri": "https://phuong721.github.io/learning-aws/5-workshop/5.1-workshop-overview/",
	"title": "Workshop Overview",
	"tags": [],
	"description": "",
	"content": "Introduction This workshop guides you through deploying a full-stack DNA Analysis application on AWS. The application allows users to analyze DNA sequences, manage results, and visualize biological data.\nApplication Architecture Frontend (React + Vite) Framework: React 18 with TypeScript UI Libraries: Material-UI, TailwindCSS, Recharts State Management: React Context API Routing: React Router v6 Form Handling: React Hook Form with Zod validation HTTP Client: Axios Hosting: S3 + CloudFront CDN Backend (Spring Boot) Framework: Spring Boot 3.x Language: Java 17 Database: MySQL 8.0 with Spring Data JPA Security: Spring Security with JWT authentication API: RESTful API with proper error handling Hosting: EC2 instances with Auto Scaling Database (RDS MySQL) Engine: MySQL 8.0.40 Instance: db.t3.micro (scalable) Storage: 20GB gp3 with encryption Backup: Automated backups with 3-7 days retention High Availability: Multi-AZ deployment (optional) AWS Architecture Network Layer VPC (10.0.0.0/16)\r‚îú‚îÄ‚îÄ Public Subnets (10.0.1.0/24, 10.0.3.0/24)\r‚îÇ ‚îú‚îÄ‚îÄ Internet Gateway\r‚îÇ ‚îú‚îÄ‚îÄ NAT Gateway\r‚îÇ ‚îî‚îÄ‚îÄ Application Load Balancer\r‚îÇ\r‚îî‚îÄ‚îÄ Private Subnets (10.0.2.0/24, 10.0.4.0/24)\r‚îú‚îÄ‚îÄ EC2 Instances (Auto Scaling Group)\r‚îú‚îÄ‚îÄ RDS MySQL (Multi-AZ)\r‚îî‚îÄ‚îÄ VPC Endpoints (S3, CloudWatch, SSM, Cognito) Application Flow User Browser\r‚îÇ\r‚îú‚îÄ‚îÄ‚îÄ HTTPS ‚îÄ‚îÄ\u0026gt; CloudFront ‚îÄ‚îÄ\u0026gt; S3 (Static Frontend)\r‚îÇ\r‚îî‚îÄ‚îÄ‚îÄ HTTPS ‚îÄ‚îÄ\u0026gt; API Gateway ‚îÄ‚îÄ\u0026gt; ALB ‚îÄ‚îÄ\u0026gt; EC2 (Backend API)\r‚îÇ\r‚îî‚îÄ‚îÄ\u0026gt; RDS MySQL Security Architecture Internet\r‚îÇ\r‚îú‚îÄ‚îÄ‚îÄ CloudFront (HTTPS only)\r‚îÇ ‚îî‚îÄ‚îÄ‚îÄ S3 Bucket Policy (CloudFront OAI)\r‚îÇ\r‚îî‚îÄ‚îÄ‚îÄ API Gateway (Resource Policy)\r‚îî‚îÄ‚îÄ‚îÄ ALB Security Group (Port 80/443)\r‚îî‚îÄ‚îÄ‚îÄ EC2 Security Group (Port 8080 from ALB only)\r‚îî‚îÄ‚îÄ‚îÄ RDS Security Group (Port 3306 from EC2 only) Key Features 1. User Authentication User registration and login JWT token-based authentication AWS Cognito integration (optional) Session management 2. DNA Analysis Upload and analyze DNA sequences Support multiple file formats Batch processing capability Store analysis results 3. Data Visualization DNA analysis charts Dashboard with metrics Export results in multiple formats 4. User Management User profile management Analysis history Role-based access control Infrastructure as Code CloudFormation Template The infrastructure.yaml template includes:\nNetworking (Lines 1-400)\nVPC with DNS support 2 Public Subnets (Multi-AZ) 2 Private Subnets (Multi-AZ) Internet Gateway NAT Gateway (can be disabled for cost savings) Route Tables VPC Endpoints (S3, CloudWatch, SSM, Cognito) Compute (Lines 400-700)\nLaunch Template with User Data script Auto Scaling Group (1-4 instances) Application Load Balancer Target Group with health checks Scaling Policies (CPU-based) Storage \u0026amp; CDN (Lines 700-900)\nS3 Bucket for Frontend S3 Bucket Policy CloudFront Distribution CloudFront Origin Access Identity Database (Lines 900-1000)\nRDS MySQL Instance DB Subnet Group Automated Backups Encryption at rest Security (Lines 1000-1200)\nSecurity Groups (ALB, EC2, RDS, VPC Endpoints) IAM Roles (EC2, CloudWatch, S3) IAM Instance Profile Cognito User Pool (optional) Secrets Manager (optional) Monitoring (Lines 1200-1393)\nCloudWatch Log Groups CloudWatch Alarms (CPU, Memory) SNS Topic for alerts API Gateway with CORS Cost Optimization 1. VPC Endpoints instead of NAT Gateway Savings: ~$20-25/month\nS3 Gateway Endpoint: FREE Interface Endpoints: $7.20/endpoint/month Total: ~$28/month vs NAT Gateway $32/month + data transfer 2. Instance Sizing Development: t3.micro ($7-10/month) Production: t3.small or t3.medium\n3. RDS Optimization Single-AZ for development Multi-AZ for production Automated backups with appropriate retention 4. CloudFront Caching Reduce requests to S3 Lower latency for users Free tier: 1TB data transfer/month Best Practices Applied 1. Security ‚úÖ Private subnets for EC2 and RDS ‚úÖ Security Groups with least privilege ‚úÖ IAM Roles instead of hardcoded credentials ‚úÖ Encryption at rest and in transit ‚úÖ VPC Endpoints for private connectivity ‚úÖ CloudTrail for audit logging (optional)\n2. High Availability ‚úÖ Multi-AZ deployment ‚úÖ Auto Scaling Group ‚úÖ Application Load Balancer ‚úÖ RDS automated backups ‚úÖ CloudFront global CDN\n3. Monitoring \u0026amp; Logging ‚úÖ CloudWatch Logs for application logs ‚úÖ CloudWatch Alarms for metrics ‚úÖ SNS notifications ‚úÖ Health checks on ALB and ASG\n4. Automation ‚úÖ Infrastructure as Code with CloudFormation ‚úÖ User Data scripts for EC2 initialization ‚úÖ Systemd service for application management ‚úÖ Automated deployments with scripts\nDeployment Steps Preparation (10 minutes)\nInstall AWS CLI Create EC2 Key Pair Configure parameters Deploy Infrastructure (15-20 minutes)\nValidate CloudFormation template Create stack Wait for resources to be created Deploy Backend (20-30 minutes)\nBuild JAR file Upload to S3 Deploy to EC2 Configure database connection Deploy Frontend (10-15 minutes)\nBuild React application Upload to S3 Invalidate CloudFront cache Testing (15-30 minutes)\nTest authentication Test DNA analysis features Verify monitoring Cleanup (5-10 minutes)\nDelete CloudFormation stack Verify all resources deleted Expected Outcomes After completing this workshop, you will have:\n‚úÖ A working full-stack application on AWS ‚úÖ Deep understanding of AWS networking and security ‚úÖ Experience with Infrastructure as Code ‚úÖ Knowledge of cost optimization ‚úÖ Best practices for production deployment\nReference Resources AWS CloudFormation Documentation AWS VPC Best Practices AWS Well-Architected Framework Spring Boot on AWS React Deployment Best Practices "
},
{
	"uri": "https://phuong721.github.io/learning-aws/4-eventparticipated/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": "Reflection Report ‚Äì ‚ÄúAWS Mastery #2 ‚Äì CloudFormation \u0026amp; CDK Workshop‚Äù Purpose of the Event The ‚ÄúAWS Mastery #2 ‚Äì CloudFormation \u0026amp; CDK‚Äù workshop was designed to help participants:\nUnderstand the concepts and mindset behind Infrastructure as Code (IaC). Learn how AWS automates and manages infrastructure using CloudFormation and the AWS Cloud Development Kit (CDK). Gain a clearer picture of container technologies including Docker, Amazon ECS, Amazon EKS, and AWS App Runner. Strengthen DevOps thinking through automated deployments, reproducible environments, and scalable infrastructure. Observe hands-on demos to reinforce practical IaC implementation skills. The workshop was extremely valuable for developers, cloud engineers, and DevOps professionals who want to automate and standardize AWS infrastructure.\nSpeakers Bao Huynh Thinh Nguyen ‚Äì AWS Community Builder Vi Tran ‚Äì AWS Community Builder Both speakers have strong practical experience deploying real-world AWS systems, which made the workshop highly engaging and easy to follow.\nKey Content 1. Infrastructure as Code (IaC) Mindset The workshop began by analyzing why ClickOps (manually clicking on the AWS console) has significant drawbacks:\nHighly error-prone due to manual operations. Difficult to reproduce environments across teams. No unified change tracking or version control. Limited auditability and challenging rollbacks. IaC was introduced as a modern DevOps foundation:\nAutomation: Infrastructure is fully created and updated via code. Reproducibility: Identical environments can be provisioned consistently. Scalability: Infrastructure can be scaled quickly through versioned code. Collaboration: All changes can be tracked, reviewed, and audited via Git. 2. AWS CloudFormation ‚Äì AWS Native IaC Tool What is CloudFormation? CloudFormation allows teams to define entire infrastructure stacks using YAML or JSON templates, and AWS will automatically build them.\nCloudFormation Template Anatomy Parameters\nInputs used to customize deployments without changing the template. Mappings\nRegion-specific configurations such as AMI IDs. Conditions\nCreate resources only when certain conditions are met (e.g., only create EC2 for production). Resources\nThe core of every template. Defines S3, EC2, IAM roles, VPC components, etc. Outputs\nProvide values for cross-stack referencing or sharing with other teams. Drift Detection Detects whether resources have been modified outside of CloudFormation. Helps ensure that the actual environment matches the defined template. The speakers provided clear visual examples of state mismatch, helping me understand the importance of drift management.\n3. AWS CDK ‚Äì Infrastructure Using Real Programming Languages CDK was introduced as a higher-level, developer-friendly IaC framework:\nSupports TypeScript, Python, Java, Go, C#/.NET. CDK code is synthesized into CloudFormation templates (cdk synth). Enables abstraction, reuse, and scalable architectures. Core Concepts Constructs L1: Direct 1:1 mapping to CloudFormation resources. L2: Higher-level APIs with recommended default configurations. L3: Prebuilt architecture patterns, providing out-of-the-box solutions. Stack \u0026amp; App Structure Stack: The unit of deployment. App: A collection of multiple stacks. CDK CLI Commands cdk init ‚Äì Initialize a new project cdk bootstrap ‚Äì Prepare AWS environment cdk synth ‚Äì Generate CloudFormation template cdk deploy ‚Äì Deploy resources cdk destroy ‚Äì Remove stacks cdk diff ‚Äì Preview changes cdk drift ‚Äì Detect configuration drift CDK significantly reduces manual configuration and improves infrastructure maintainability.\n4. Docker \u0026amp; AWS Container Services Docker Fundamentals Containers are lightweight and start much faster than VMs. Dockerfile defines the environment, dependencies, and build steps. Docker images act as blueprints for creating reproducible containers. Amazon ECR A secure, fully managed container registry that supports:\nImage scanning Immutable tags Lifecycle policies IAM-based access control 5. Orchestration with ECS, EKS, and App Runner Amazon ECS A fully managed, AWS-native orchestration service.\nSupported launch types:\nEC2 launch type ‚Äì More control, good for long-running workloads. Fargate launch type ‚Äì Serverless compute, no server management. Key components:\nCluster Task Definition Service Amazon EKS Managed Kubernetes for complex or multi-cloud workloads.\nAutomates Kubernetes control plane. Works with EC2, Fargate, or on-prem via Outposts. AWS App Runner A simple service to run web applications or APIs:\nAutomatically builds from GitHub or ECR. No servers to manage. Ideal for small teams and rapid deployments. What I Learned 1. Modern Infrastructure Thinking IaC is more than a tool‚Äîit is a standardized operational approach. Drift detection is essential in maintaining infrastructure reliability. Version-controlled infrastructure dramatically reduces risk. 2. Deep Understanding of IaC Tools I can now confidently read and write CloudFormation templates with all major components. CDK‚Äôs L2 and L3 constructs help reduce boilerplate and enforce best practices. Understanding the conversion process from CDK ‚Üí CloudFormation is extremely valuable. 3. Container Architecture Clear distinction of when to use ECS, Fargate, or EKS. Improved ability to evaluate compute models based on cost, performance, and operational needs. 4. Practical DevOps Experience cdk diff is a powerful safety tool before deploying to production. IaC ensures that environments across teams remain consistent and reviewable. I now understand how CI/CD pipelines integrate with IaC and containers. Application to My Work Begin migrating small infrastructure components to IaC using CloudFormation or CDK. Build practice templates for S3, IAM roles, and VPC components. Deploy a sample application using ECS Fargate to understand end-to-end workflows. Use CDK to design reusable infrastructure for internal projects. Recommend using ECR as the standard registry for container pipelines. Create internal documentation on using cdk diff to enforce safe deployments. Event Experience The workshop was well-structured, informative, and highly practical. Live demos gave me a clear understanding of how IaC works in real AWS environments. I particularly enjoyed the comparison between ECS and EKS‚Äîvery helpful for architectural decisions. Networking with other participants expanded my understanding of real-world DevOps problems. The content has significantly increased my confidence in applying IaC and container orchestration in actual projects. Event Photos Event Photos Overall, the workshop provided not only deep technical knowledge but also shaped my mindset toward modern cloud infrastructure, helping me approach future projects with more clarity and confidence.\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/",
	"title": "Internship Report",
	"tags": [],
	"description": "",
	"content": "Internship Report Student Information: Full Name: Do Doan Duy Phuong\nPhone Number: 0983394370\nEmail: phuongdddse180235@fpt.edu.vn\nUniversity: FPT University Ho Chi Minh City\nMajor: Information Security\nClass: AWS082025\nInternship Company: Amazon Web Services Vietnam Co., Ltd.\nInternship Position: FCJ Cloud Intern\nInternship Duration: From 08/09/2025 to 30/12/2025\nReport Content Worklog Proposal Translated Blogs Events Participated Workshop Self-evaluation Sharing and Feedback "
},
{
	"uri": "https://phuong721.github.io/learning-aws/1-worklog/",
	"title": "Worklog Summary",
	"tags": [],
	"description": "",
	"content": "Overview: This section introduces your worklog. It summarizes the tasks completed, the number of weeks, and the activities performed.\nI completed the internship program over 12 weeks, focusing on learning and practicing core AWS services, data management, security, serverless applications, data analysis, and visualization. Below is a summary of weekly tasks:\nWeek 1: Getting started with AWS, creating a Free Tier account, security setup, IAM management, basic Budget creation\nWeek 2: VPC setup, subnets, Internet Gateway, NAT Gateway, Security Group, EC2 instances, site-to-site VPN, Route53 hybrid DNS, VPC peering, Transit Gateway\nWeek 3: AWS Backup deployment, creating backup plans, restore testing; S3 Bucket, Storage Gateway, static website deployment with S3 \u0026amp; CloudFront, versioning, replication\nWeek 4: S3 bucket creation, infrastructure deployment, backup plan \u0026amp; notifications, restore test; VM import/export, Storage Gateway, Multi-AZ file system, performance testing, advanced S3 website\nWeek 5: Security Hub, managing VPC, EC2 \u0026amp; Lambda with tagging; IAM Users, Policies, Roles, KMS; CloudTrail \u0026amp; Athena; permission management; resource cleanup\nWeek 6: VPC, EC2 \u0026amp; RDS Security Groups, RDS database deployment, application deployment, backup/restore; EC2 connection via RDP \u0026amp; Fleet Manager; SQL Server \u0026amp; Oracle configuration; migration tasks; troubleshooting\nWeek 7: Data management on S3, DynamoDB, Redshift; data pipelines with Kinesis, Glue, DataBrew, EMR; data analysis with Athena \u0026amp; Kinesis Data Analytics; visualization with QuickSight; serverless applications and interactive dashboards; CloudShell, SDK, Cloud9 usage\nWeek 8: Building AWS architecture for the project; collecting requirements, creating Network Architecture Diagram, designing VPC, subnets, routing, EC2, RDS, API Gateway, CloudFront, CI/CD, and finalizing the diagram based on mentor feedback\nWeek 9: Drafting the BDSS Proposal; writing Executive Summary, Problem Statement, Solution Overview; analyzing BDSS architecture; consolidating content from team proposals and standardizing according to the template\nWeek 10: Building a workshop based on the Proposal \u0026amp; Proposal Template; writing Introduction, Background, Objectives; creating Architecture, Data Flow, CI/CD, Security; consolidating Cost \u0026amp; Risk to complete the Workshop Draft\nWeek 11: Consolidating content from 2 proposals; standardizing Executive Summary, Problem, Solution Architecture; building slide outline; converting all content to English for final report preparation\nWeek 12: Presenting the project to mentors; collecting feedback on architecture, CI/CD, cost, security; revising slides and documents; compiling action items for final report submission\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/1-worklog/1.1-week1/",
	"title": "Worklog Week 1",
	"tags": [],
	"description": "",
	"content": "Week 1 Objectives: Set up and manage a basic AWS account. Get familiar with security mechanisms, user management, budgeting, and support on AWS. Practice operations on AWS Console and AWS CLI. Tasks to implement this week: Day Task Start Date End Date Reference Mon - Create AWS Free Tier account (Module 01-Lab01-01) - Set up Virtual MFA (Module 01-Lab01-02) 08/09/2025 08/09/2025 https://000001.awsstudygroup.com/ Tue - Create Admin Group and Admin User (Module 01-Lab01-03) - Configure Account Authentication Support (Module 01-Lab01-04) 09/09/2025 09/09/2025 https://000007.awsstudygroup.com/ Wed - Create Budget using template (Module 01-Lab07-01) - Create Cost Budget (Module 01-Lab07-02) 10/09/2025 10/09/2025 https://000009.awsstudygroup.com/ Thu - Create Usage Budget (Module 01-Lab07-03) - Create Reservation Instance (RI) Budget (Module 01-Lab07-04) 11/09/2025 11/09/2025 https://000009.awsstudygroup.com/ Fri - Create Savings Plans Budget (Module 01-Lab07-05) - Clean Up Budgets (Module 01-Lab07-06) 12/09/2025 12/09/2025 https://000009.awsstudygroup.com/ Sat - Explore AWS Support plans (Module 01-Lab09-01) - Types of support requests (Module 01-Lab09-02) - Change support plan (Module 01-Lab09-03) - Manage support requests (Module 01-Lab09-04) 13/09/2025 13/09/2025 https://000007.awsstudygroup.com/ Sun - Review, consolidate, and finalize configurations; clean up experimental resources 14/09/2025 14/09/2025 - Week 1 Results: AWS Account Initialization:\nSuccessfully created AWS Free Tier account. Set up MFA for root account for security. Created Admin Group and Admin User for management instead of using root. Completed Account Authentication Support configuration. Budget Management:\nCreated Budget using template, Cost Budget, Usage Budget, RI Budget, and Savings Plans Budget. Practiced cleaning up created budgets to avoid extra charges. Support and Troubleshooting:\nUnderstood and learned to use AWS Support plans. Practiced creating, managing, and changing support requests on AWS Console. Self-assessment:\nMastered the process of account setup, security, and user/group management. Practiced basic AWS budgeting and support plan management. Ready to proceed to the following weeks with more advanced AWS services. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/3-blogstranslated/3.1-blog1/",
	"title": "Blog 1",
	"tags": [],
	"description": "",
	"content": "Accelerate Your Cloud Strategy with Megaport‚Äôs 25 Gbps Hosted AWS Direct Connect As businesses move critical workloads to the cloud, network performance has become a fundamental business requirement. Amazon Web Services (AWS) Direct Connect provides a dedicated network connection between on-premises data centers and AWS. This bypasses the public internet to deliver more stable and reliable network performance with lower latency. The introduction of 25 Gbps hosted connections fills the gap between 10 Gbps options (often insufficient) and 100 Gbps options (often excessive), allowing organizations to right-size their connections without sacrificing performance. Megaport, a leading Network-as-a-Service (NaaS) provider and AWS Marketplace Partner, is among the first to offer this 25 Gbps connection across multiple Direct Connect Edge Locations through its Global Software-Defined Network, spanning hundreds of data centers worldwide. For the latest information, please refer to the Megaport public network footprint page.\nUsing Megaport‚Äôs self-service platform, organizations can provision, scale, and manage high-performance AWS connections in minutes rather than weeks or months. In this article, we describe how the powerful combination of AWS and Megaport services enables cloud architects and IT leaders to build next-generation hybrid networks that support data-intensive applications, enhance security, and optimize costs‚Äîwhile maintaining the flexibility to adapt to evolving business needs.\nPrerequisites We assume you are familiar with core networking structures on AWS, particularly Direct Connect. While we won‚Äôt dive deeply into definitions, we will highlight its role in supporting hybrid connection architectures involving hosted Direct Connect connections. If you are not familiar with these concepts, we recommend reviewing the Direct Connect documentation for more details on choosing between Direct Connect dedicated and hosted connections.\nFor foundational knowledge, the Getting Started with AWS Direct Connect guide is also a helpful resource.\nKey Use Cases for 25 Gbps Direct Connect The following sections outline key use cases for Direct Connect 25 Gbps.\n1. Cloud Migration Large-scale enterprise data migrations involve transferring massive datasets. A 25 Gbps hosted connection allows organizations to reduce migration time from days to hours while maintaining stable and secure performance. For example, migrating a 100 TB database, which would take over 22 hours with a 10 Gbps connection, can be completed in approximately 9 hours, significantly shortening time-to-production.\nConnection Speed Data Volume Estimated Migration Time Performance Gain 10 Gbps 100 TB ~22 hours Baseline 25 Gbps 100 TB ~9 hours ~59% faster Table 1: Bandwidth effects on large-scale data migration\n2. Data Transfer Organizations collecting data from edge locations or on-premises environments benefit from high-throughput, predictable connections for analytics, backup, and storage workloads. Media companies can efficiently transfer large video files between studios and AWS, while healthcare organizations can move imaging datasets to the cloud for AI analysis while maintaining compliance through private connectivity. The 25 Gbps tier is particularly useful for IoT deployments generating high volumes of sensor data, large-scale backups with strict Recovery Point Objective (RPO) requirements, and organizations training ML models with substantial on-premises datasets.\n3. Hybrid Cloud Support As hybrid architectures become more prevalent, reliable connectivity between on-premises systems and AWS is essential. Megaport‚Äôs 25 Gbps hosted connection provides the capacity needed for distributed databases, hybrid storage solutions, and microservices spanning multiple environments. Organizations can implement consistent security policies and seamless application experiences across their entire technology stack, while maintaining performance headroom for peak workloads and future growth.\n4. Latency-Sensitive Applications Applications such as financial trading platforms, automation systems, and real-time collaboration tools require minimal latency. The 25 Gbps dedicated connection maintains stable, low-latency performance by bypassing the public internet while providing sufficient bandwidth to prevent congestion during peak periods. For industries requiring millisecond-level speed‚Äîsuch as high-frequency trading, online gaming, or telehealth‚ÄîDirect Connect‚Äôs predictable performance offers competitive advantages while maintaining security through private connectivity.\nIndustries benefiting include: high-frequency trading, online gaming, telehealth.\n5. Cost Control The 25 Gbps package offers a cost-effective solution to expand network capacity without over-provisioning. Organizations that previously had to choose between insufficient 10 Gbps connections or excessive 100 Gbps connections can now select an optimal balance, often saving 50‚Äì60% compared to the 100 Gbps alternative. Megaport‚Äôs flexible platform also allows businesses to adjust bandwidth as demands change, supporting cost optimization across the application lifecycle while ensuring required performance for modern cloud workloads.\nBenefits of Deploying AWS Direct Connect 25 Gbps with Megaport The following sections highlight the benefits of deploying Direct Connect 25 Gbps with Megaport.\n1. Private, Secure Data Transfer Megaport‚Äôs hosted connections provide a private path to AWS, bypassing the public internet, enhancing data privacy, reducing exposure to common security threats, and ensuring compliance for sensitive workloads. Private connectivity is increasingly critical as regulations like GDPR, HIPAA, and industry-specific requirements impose stricter controls on data movement and protection. The 25 Gbps tier delivers this security without compromising the performance needed for modern data-intensive applications.\n2. Ease of Use Megaport‚Äôs self-service portal enables customers to provision, scale, and manage Direct Connect connections in minutes. This flexibility allows teams to quickly adapt to changing project demands without incurring manual management costs. Organizations can establish connections to AWS Regions almost in real-time, rather than waiting weeks or months for traditional telecom circuits, accelerating cloud initiatives and reducing time-to-value for new projects.\n3. Global Reach Megaport‚Äôs presence in over 975 data centers across 26+ countries provides near-ubiquitous access to Direct Connect locations. Organizations with distributed footprints can standardize a consistent connection approach across AWS Regions, simplifying architecture and operations while maintaining high performance. This global reach is particularly valuable for multinational businesses operating across time zones or organizations with strict data sovereignty requirements.\n4. Flexibility and Scalability As demand increases, customers can flexibly adjust bandwidth via the Megaport portal. This flexibility allows IT teams to scale cost-effectively while maintaining optimal performance for critical workloads. The 25 Gbps tier offers an ideal intermediate solution, deployable as a long-term option or as a stepping stone for a broader cloud network strategy.\nGetting Started with AWS and Megaport 25 Gbps The following sections guide you on how to use AWS and Megaport with a 25 Gbps hosted connection.\nPrerequisites An active Megaport account with billing enabled. An AWS account with Direct Connect access. Step 1: Create a Megaport Cloud Router (MCR) Log in to the Megaport Portal. Select +Add Service and choose MCR (Megaport Cloud Router) as shown in Figure 1. Ensure the MCR supports at least 25 Gbps capacity, as this determines the maximum speed available for your hosted connection. Follow the on-screen instructions to complete setup. More details can be found in the Creating MCR Documentation. Step 2: Create a Hosted Connection from Megaport to AWS In the Megaport Portal, select your MCR and click + Add Connection. Choose AWS Direct Connect from the Cloud options. Provide the necessary information and follow the instructions: Creating a Hosted Connection Connection Name: a descriptive name for your connection. Service Level Reference: provide a unique identifier for billing or tracking purposes. Rate Limit: set to 25,000 Mbps to provision a 25 Gbps connection. Submit and deploy the connection. You can also create hosted VIFs and other connection types (e.g., public VIF, transit VIF), depending on your use case.\nStep 3: Accept the Hosted Connection in AWS Log in to the AWS Console and navigate to AWS Direct Connect. In the navigation pane, select Connections. Select the hosted connection and choose View details. Select the confirmation checkbox and click Accept. Step 4: Create a Virtual Interface for the Hosted Connection After accepting the connection, select it and choose Create Virtual Interface as shown in Figure 3. Choose the interface type ‚Äì typically Private to access a VPC. Configure as follows: Virtual interface name VLAN ID (must match the VLAN used in Megaport configuration) BGP ASN (your default or AWS-provided) BGP peer IP address (AWS provides one side; you specify your side) Gateway association: select a Virtual Private Gateway or AWS Transit Gateway attached to your VPC. Click Create. Step 5: Configure BGP on the Megaport MCR Return to the Megaport Portal. Edit the Virtual Cross Connect (VXC) to match the BGP details provided by AWS. Enter the required information: BGP peer IP addresses (yours and AWS‚Äôs) Your ASN (or AWS-assigned ASN) Save and apply the configuration. Conclusion In this article, we explored how AWS Direct Connect 25 Gbps hosted connections via Megaport can transform your cloud connectivity strategy. We covered key use cases such as large-scale cloud migrations, data-intensive applications, hybrid cloud deployments, and latency-sensitive workloads. You learned how this solution provides private, secure data transfer with flexible scalability, while offering significant cost savings compared to 100 Gbps alternatives. We also provided step-by-step guidance for setting up a 25 Gbps hosted connection using Megaport‚Äôs self-service platform.\nCall to Action Assess your current and future network throughput requirements. Explore 25 Gbps hosted connection options on the AWS Direct Connect Partners page. Visit Megaport‚Äôs AWS solution page to learn more or start self-service provisioning. About the Authors Mokshith Kumar\nSenior GTM Solutions Architect ‚Äì Core Networking at AWS, supporting ISVs and FSI in North America.\nRole: Develop GTM strategy, lead strategic initiatives, drive AWS networking adoption. Interests: Swimming, music. Miranda Li\nSenior Solutions Architect at AWS, specializing in ISVs and cloud-native architecture.\n4 years of experience supporting ISV innovation and scaling on AWS. Expertise: IaaS, networking architecture, security, data analytics. Interests: Badminton, running, outdoor activities. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/5-workshop/5.2-prerequisite/",
	"title": "Prerequisites &amp; Preparation",
	"tags": [],
	"description": "",
	"content": "System Requirements 1. AWS Account Active AWS account Administrator access or the following permissions: CloudFormation: Full access EC2: Full access VPC: Full access RDS: Full access S3: Full access CloudFront: Full access IAM: Create roles and policies CloudWatch: Full access 2. AWS CLI Install and configure AWS CLI:\nWindows:\n# Download and install from: https://aws.amazon.com/cli/ # Or use chocolatey: choco install awscli # Verify installation aws --version Linux/Mac:\n# Using pip pip install awscli # Or use package manager # Ubuntu/Debian sudo apt-get install awscli # MacOS brew install awscli # Verify installation aws --version Configure AWS CLI:\naws configure # AWS Access Key ID: \u0026lt;your-access-key\u0026gt; # AWS Secret Access Key: \u0026lt;your-secret-key\u0026gt; # Default region name: ap-southeast-1 # Default output format: json 3. EC2 Key Pair Create an EC2 Key Pair for SSH access:\nVia AWS Console:\nOpen EC2 Console Select region ap-southeast-1 (Singapore) Go to Network \u0026amp; Security ‚Üí Key Pairs Click Create key pair Name: workshop-aws-key Key pair type: RSA Private key file format: .pem (Linux/Mac) or .ppk (Windows/PuTTY) Click Create key pair Save the .pem file securely Via AWS CLI:\n# Create key pair aws ec2 create-key-pair \\ --key-name workshop-aws-key \\ --query \u0026#39;KeyMaterial\u0026#39; \\ --output text \\ --region ap-southeast-1 \u0026gt; workshop-aws-key.pem # Set permissions (Linux/Mac only) chmod 400 workshop-aws-key.pem 4. Development Tools Java Development Kit (JDK) 17:\n# Windows (chocolatey) choco install openjdk17 # Linux (Ubuntu/Debian) sudo apt-get install openjdk-17-jdk # MacOS brew install openjdk@17 # Verify java -version Maven:\n# Windows choco install maven # Linux sudo apt-get install maven # MacOS brew install maven # Verify mvn -version Node.js and npm:\n# Windows choco install nodejs # Linux curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash - sudo apt-get install -y nodejs # MacOS brew install node # Verify node --version npm --version Prepare Project Files 1. Clone or Download Project # If you have Git repository git clone \u0026lt;your-repo-url\u0026gt; cd aws_project # Or download and extract ZIP file 2. Project Structure aws_project/\r‚îú‚îÄ‚îÄ aws/\r‚îÇ ‚îú‚îÄ‚îÄ infrastructure.yaml # Main CloudFormation template\r‚îÇ ‚îú‚îÄ‚îÄ cicd-pipeline.yaml # CI/CD pipeline (optional)\r‚îÇ ‚îú‚îÄ‚îÄ parameters.json # Stack parameters\r‚îÇ ‚îú‚îÄ‚îÄ deploy.bat # Deploy script (Windows)\r‚îÇ ‚îú‚îÄ‚îÄ deploy.sh # Deploy script (Linux/Mac)\r‚îÇ ‚îî‚îÄ‚îÄ README.md # Detailed instructions\r‚îú‚îÄ‚îÄ BE/\r‚îÇ ‚îî‚îÄ‚îÄ workshop_BE/\r‚îÇ ‚îú‚îÄ‚îÄ src/ # Backend source code\r‚îÇ ‚îú‚îÄ‚îÄ pom.xml # Maven configuration\r‚îÇ ‚îî‚îÄ‚îÄ README.md\r‚îî‚îÄ‚îÄ FE/\r‚îú‚îÄ‚îÄ src/ # Frontend source code\r‚îú‚îÄ‚îÄ package.json # npm dependencies\r‚îî‚îÄ‚îÄ README.md 3. Configure Parameters Open aws/parameters.json and update values:\n[ { \u0026#34;ParameterKey\u0026#34;: \u0026#34;ProjectName\u0026#34;, \u0026#34;ParameterValue\u0026#34;: \u0026#34;workshop-aws\u0026#34; }, { \u0026#34;ParameterKey\u0026#34;: \u0026#34;Environment\u0026#34;, \u0026#34;ParameterValue\u0026#34;: \u0026#34;dev\u0026#34; }, { \u0026#34;ParameterKey\u0026#34;: \u0026#34;KeyPairName\u0026#34;, \u0026#34;ParameterValue\u0026#34;: \u0026#34;workshop-aws-key\u0026#34; // ‚ö†Ô∏è Replace with your key pair name }, { \u0026#34;ParameterKey\u0026#34;: \u0026#34;DBPassword\u0026#34;, \u0026#34;ParameterValue\u0026#34;: \u0026#34;YourStrongPassword123!\u0026#34; // ‚ö†Ô∏è Use a strong password }, { \u0026#34;ParameterKey\u0026#34;: \u0026#34;InstanceType\u0026#34;, \u0026#34;ParameterValue\u0026#34;: \u0026#34;t3.micro\u0026#34; }, { \u0026#34;ParameterKey\u0026#34;: \u0026#34;DBInstanceClass\u0026#34;, \u0026#34;ParameterValue\u0026#34;: \u0026#34;db.t3.micro\u0026#34; } ] Important notes:\nKeyPairName: Must match your created key pair name DBPassword: Minimum 8 characters with uppercase, lowercase, numbers, and special characters Don\u0026rsquo;t commit this file with real passwords to Git 4. Update AMI ID The CloudFormation template uses a default AMI ID. Update it for your region:\nFind AMI ID:\n# Find Amazon Linux 2023 AMI for ap-southeast-1 aws ec2 describe-images \\ --owners amazon \\ --filters \u0026#34;Name=name,Values=al2023-ami-*-x86_64\u0026#34; \\ --query \u0026#39;Images | sort_by(@, \u0026amp;CreationDate) | [-1].[ImageId,Name,CreationDate]\u0026#39; \\ --region ap-southeast-1 \\ --output table Update in infrastructure.yaml:\nFind line ~530:\nLaunchTemplate: Properties: LaunchTemplateData: ImageId: ami-0c55b159cbfafe1f0 # ‚ö†Ô∏è Replace with your AMI ID Preparation Checklist Ensure you have completed all the following steps:\nAWS account configured AWS CLI installed and configured (aws configure) EC2 Key Pair created Java 17 installed Maven installed Node.js and npm installed Project files downloaded parameters.json file updated AMI ID updated in infrastructure.yaml Validate AWS Credentials # Check AWS credentials aws sts get-caller-identity # Expected output: # { # \u0026#34;UserId\u0026#34;: \u0026#34;AIDAXXXXXXXXXXXXXXXXX\u0026#34;, # \u0026#34;Account\u0026#34;: \u0026#34;123456789012\u0026#34;, # \u0026#34;Arn\u0026#34;: \u0026#34;arn:aws:iam::123456789012:user/your-username\u0026#34; # } Validate CloudFormation Template cd aws aws cloudformation validate-template \\ --template-body file://infrastructure.yaml \\ --region ap-southeast-1 If successful, you\u0026rsquo;ll see output with template parameters and outputs information.\nCost Estimation Before deployment, understand the costs:\nService Instance Type Cost/month (USD) EC2 t3.nano $3.50 RDS MySQL db.t3.micro $2.80 API Gateway - $0.50 S3 + CloudFront - $0.80 Route 53 - $0.50 Cognito - $0.10 CloudWatch - $0.30 CI/CD (CodePipeline) - $0.40 Total $8.90 For workshop (2-3 hours): ~$0.50-1.00\nNote:\nCosts apply to ap-southeast-1 region Use AWS Free Tier if account is eligible NAT Gateway (~$32/month) can be disabled to save costs Next Steps After completing all preparation steps, you\u0026rsquo;re ready to:\n‚û°Ô∏è Deploy Infrastructure with CloudFormation\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/4-eventparticipated/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": "Reflection Report ‚Äì ‚ÄúAWS Cloud Club ‚Äì First Cloud AI Journey Workshop‚Äù Purpose of the Event The ‚ÄúAWS Cloud Club ‚Äì First Cloud AI Journey‚Äù workshop was organized to:\nProvide orientation for students beginning their journey into cloud computing and AI. Introduce the AWS Cloud Clubs community and its role in fostering cloud knowledge. Equip participants with foundational knowledge to prepare for deeper cloud/AI learning tracks. Connect tech‚Äìdriven students with the AWS community in Vietnam. Create a collaborative environment where learners can exchange knowledge and gain insights from others in the same field. Speakers Le Vu Xuan An ‚Äì AWS Cloud Club Captain HCMUTE Tran Duc Anh ‚Äì AWS Cloud Club Captain SGU Tran Doan Cong Ly ‚Äì AWS Cloud Captain PTIT Danh Hoang Hieu Nghi ‚Äì AWS CLoud Captain HUFLIT Key Content Covered 1. Introduction to AWS Cloud Clubs AWS Cloud Clubs are student-led communities supported by AWS. Each university has a Cloud Club Captain responsible for leading academic and technical activities. The community aims to: Enable peer-to-peer learning. Provide guidance on preparing for AWS certifications. Organize workshops ranging from fundamentals to advanced topics. 2. First Cloud AI Journey ‚Äì Learning Roadmap The speakers introduced an overview of the First Cloud AI Journey program, including:\nCloud learning path: AWS Cloud fundamentals ‚Üí hands-on labs ‚Üí AI/ML basics ‚Üí real-world projects Foundations of: Cloud computing (EC2, S3, Lambda‚Ä¶) Basic AI concepts Key elements for GenAI (data, vector databases, prompt engineering‚Ä¶) Introduction to AWS services supporting AI learning (to be covered in later sessions). 3. Cloud Learning Experiences Shared by Captains The Cloud Club Captains emphasized:\nHow to start learning AWS from zero without feeling overwhelmed. Certification preparation strategies: Cloud Practitioner Solutions Architect ‚Äì Associate Importance of joining communities to accelerate learning. Common beginner mistakes: Not practicing hands-on labs Ignoring foundational principles (like the Well-Architected Framework) Lack of personal project building Tips for building a strong cloud career: Create personal projects Share notes/blogs Build a professional cloud portfolio 4. Q\u0026amp;A and Networking Activities The event included:\nOpen Q\u0026amp;A with the speakers. Discussion about effective study habits and resource selection. Networking among students from different universities. Sharing real experiences in preparing for certifications and participating in cloud projects. What I Learned 1. Cloud \u0026amp; AI Learning Mindset Cloud fundamentals are essential before diving into AI or GenAI. A clear, structured learning plan prevents burnout and wasted effort. Hands-on practice is more valuable than passive study. 2. Importance of Community in Learning AWS Cloud Clubs accelerate learning through: Study groups Peer mentoring Shared resources Networking exposes students to real opportunities in cloud engineering. 3. Certification Preparation Skills How to approach AWS exams efficiently. Useful learning tools: AWS Skill Builder Cloud Quest AWS free digital training Balancing study time and avoiding burnout. 4. AI Readiness Mindset AI is not just about models ‚Äî it starts with: Data readiness Infrastructure readiness Understanding real business use cases Cloud plays a foundational role in deploying AI applications. Application to My Work Build a study plan to earn the AWS Cloud Practitioner certification. Join Cloud Club activities to expand my community and learn collaboratively. Start hands-on mini-projects such as: Deploying static website on S3/CloudFront. Building serverless APIs using AWS Lambda. Explore introductory AI services on AWS in upcoming workshops. Document my learning journey and share insights to reinforce understanding. Event Experience Attending the ‚ÄúAWS Cloud Club ‚Äì First Cloud AI Journey‚Äù workshop was a valuable and motivating experience.\nLearning From Experienced Members Insightful stories on cloud learning paths. Practical advice on developing a discipline-based study habit. Event Atmosphere A professional yet friendly environment. Clear slides and explanations that were easy to follow. Networking Connected with peers interested in Cloud and AI. Gained exposure to multiple perspectives on cloud career development. Motivation \u0026amp; Direction The session helped me form a clearer vision of my cloud learning path. Renewed motivation to pursue cloud and AI seriously. Event Photos Overall, the event not only strengthened my technical understanding but also shaped my perspective on cloud learning, community engagement, and AI readiness. It has given me a clearer roadmap and strong motivation to move forward in my Cloud \u0026amp; AI journey.\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/1-worklog/1.2-week2/",
	"title": "Worklog Week 2",
	"tags": [],
	"description": "",
	"content": "Week 2 Objectives: Learn and practice AWS network setup using VPC, Subnet, Route Table, Internet Gateway, NAT Gateway, and security mechanisms. Configure EC2 instances in subnets and test connectivity. Set up Hybrid DNS with Route 53 Resolver. Explore and deploy VPC Peering and AWS Transit Gateway. Tasks to implement this week: Day Task Start Date End Date Reference Mon - Introduction to Amazon VPC and AWS Site-to-Site VPN (Module 02-Lab03-01) - Subnets (Module 02-Lab03-01.1) - Route Table (Module 02-Lab03-01.2) - Internet Gateway (IGW) (Module 02-Lab03-01.3) - NAT Gateway (Module 02-Lab03-01.4) 15/09/2025 15/09/2025 https://000003.awsstudygroup.com/ Tue - Configure Security Group (Module 02-Lab03-02.1) - Network ACLs (Module 02-Lab03-02.2) - VPC Resource Map (Module 02-Lab03-02.3) 16/09/2025 16/09/2025 https://000003.awsstudygroup.com/ Wed - Create VPC (Module 02-Lab03-03.1) - Create Subnet (Module 02-Lab03-03.2) - Create Internet Gateway (Module 02-Lab03-03.3) - Create Route Table for Outbound Internet Routing via IGW (Module 02-Lab03-03.4) - Create Security Groups (Module 02-Lab03-03.5) 17/09/2025 17/09/2025 https://000010.awsstudygroup.com/ Thu - Create EC2 Instances in Subnets (Module 02-Lab03-04.1) - Test connection (Module 02-Lab03-04.2) - Create NAT Gateway (Module 02-Lab03-04.3) - EC2 Instance Connect Endpoint (Module 02-Lab03-04.5) 18/09/2025 18/09/2025 https://000010.awsstudygroup.com/ Fri - Set up Hybrid DNS with Route 53 Resolver (Module 02-Lab10-01) - Generate Key Pair (Module 02-Lab10-02.1) - Initialize CloudFormation Template (Module 02-Lab10-02.2) - Configure Security Group (Module 02-Lab10-02.3) - Connect to RDGW (Module 02-Lab10-03) 19/09/2025 19/09/2025 https://000019.awsstudygroup.com/ Sat - DNS setup: Route 53 Outbound Endpoint (Module 02-Lab10-05.1) - Create Resolver Rules (Module 02-Lab10-05.2) - Create Inbound Endpoints (Module 02-Lab10-05.3) - Test results (Module 02-Lab10-05.4) - Clean up resources (Module 02-Lab10-06) 20/09/2025 20/09/2025 https://000019.awsstudygroup.com/ Sun - VPC Peering setup: Introduction (Module 02-Lab19-01) - Initialize CloudFormation Templates (Module 02-Lab19-02.1) - Create Security Group (Module 02-Lab19-02.2) - Create EC2 instance (Module 02-Lab19-02.3) - Update Network ACLs (Module 02-Lab19-03) - Create peering connection (Module 02-Lab19-04) - Configure Route Tables (Module 02-Lab19-05) - Enable Cross-Peer DNS (Module 02-Lab19-06) - Clean up resources (Module 02-Lab19-07) - AWS Transit Gateway setup: Introduction (Module 02-Lab20-01) - Preparation steps (Module 02-Lab20-02) - Create Transit Gateway (Module 02-Lab20-03) - Create TGW Attachments (Module 02-Lab20-04) - Create TGW Route Tables (Module 02-Lab20-05) - Add TGW Routes to VPC Route Tables (Module 02-Lab20-06) - Clean up resources (Module 02-Lab20-07) 21/09/2025 21/09/2025 https://000020.awsstudygroup.com/ Week 2 Results: AWS Networking:\nCreated and configured VPC, Subnet, Route Table, Internet Gateway, NAT Gateway, Security Groups. Deployed EC2 instances in subnets and verified connectivity. Configured EC2 Instance Connect Endpoint for easier access. Hybrid DNS:\nCreated Key Pairs and initialized CloudFormation Templates. Configured Security Groups and connected to RDGW. Created Route 53 Outbound/Inbound Endpoints, set up Resolver Rules, and verified results. Cleaned up DNS resources after testing. VPC Peering \u0026amp; Transit Gateway:\nEstablished VPC Peering, configured Route Tables, and enabled Cross-Peer DNS. Created AWS Transit Gateway, attachments, route tables, and added routes to VPC route tables. Cleaned up resources to avoid unexpected costs. Self-assessment:\nGained hands-on experience with AWS networking, Hybrid DNS, VPC Peering, and Transit Gateway. Successfully deployed, tested, and cleaned up resources. Ready for the following weeks with more advanced knowledge. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/2-proposal/",
	"title": "Project Proposal",
	"tags": [],
	"description": "",
	"content": "Blood Donation Support System (BDSS) üìÑ Download Full Proposal Document (Word)\n1. Executive Summary Blood Donation Support System (BDSS) is a web platform that supports blood donation management and connects blood donors with healthcare facilities. The project is developed by a student team in Ho Chi Minh City to optimize the blood donation process, reduce the burden of finding donors, and improve healthcare communication efficiency.\nThe system is built on AWS Cloud architecture, utilizing Amazon EC2, Amazon RDS, API Gateway, Cognito, and CI/CD Pipeline (GitLab + CodePipeline) for automated deployment. BDSS supports four user groups (Guest, Member, Staff, Admin), providing features for lookup, blood donation registration, blood bank management, donation process tracking, and visual reporting.\n2. Problem Statement Current Problem: Healthcare facilities are currently managing blood donation processes manually or through disparate tools. Finding suitable blood donors by blood type or location is challenging, especially in emergency situations. Additionally, the data storage system is not synchronized, making it difficult to analyze, report, and optimize blood donation campaigns.\nProposed Solution: Develop a comprehensive blood donation support platform on AWS Cloud, with features for blood donation management, finding donors and recipients by blood type or geographic location, integrating user authentication via Amazon Cognito, and data management on Amazon RDS.\nThe frontend is deployed via Route 53 + CloudFront, backend through API Gateway ‚Äì EC2, MySQL database on Amazon RDS, and automated CI/CD pipeline using GitLab ‚Äì CodePipeline.\nBenefits and ROI: Reduce 60‚Äì70% of time searching for suitable blood donors. Increase accuracy of blood type and location information. Optimize operational costs with flexible cloud architecture, pay-as-you-go pricing. Improve response capability in emergency blood situations. 3. Solution Architecture The platform employs a serverless AWS architecture to manage data from 5 Raspberry Pi-based stations, scalable to 15. Data is ingested via AWS IoT Core, stored in an S3 data lake, and processed by AWS Glue Crawlers and ETL jobs to transform and load it into another S3 bucket for analysis. Lambda and API Gateway handle additional processing, while Amplify with Next.js hosts the dashboard, secured by Cognito. The architecture is detailed below:\nThe system is designed with a 3-tier architecture on AWS Cloud with the following main components:\n1. Frontend \u0026amp; Content Delivery Layer: Users: Access the system via web browsers or mobile devices. Route 53: DNS service managing domain names and routing traffic to CloudFront. CloudFront: CDN distributing static content with low latency, cached at edge locations. Amazon S3: Stores static assets (HTML, CSS, JS, images) for frontend application. 2. Application \u0026amp; Compute Layer: API Gateway: REST API endpoint, handling requests/responses between frontend and backend. VPC (Virtual Private Cloud): Isolated virtual network with configuration: Internet Gateway: Allows public subnet to connect to the Internet. Public Subnet: Contains EC2 instances processing business logic. Private Subnet: Contains RDS database, no direct Internet access. NAT Gateway: Allows private subnet to access Internet outbound only. Amazon EC2: Compute instances running backend API (Node.js/Express). Amazon RDS (MySQL): Relational database storing blood donor data, blood types, donation history. 3. CI/CD \u0026amp; DevOps Pipeline: GitLab: Source code repository and version control. AWS CodePipeline: Orchestrates automated CI/CD workflow. AWS CodeBuild: Builds and tests code before deployment. Automated Deployment: Automatically deploys to EC2 on code changes. 4. Monitoring, Security \u0026amp; Management Layer: Amazon Cognito: User authentication and authorization (Guest, Member, Staff, Admin roles). AWS IAM: Manages access permissions for users and services. AWS Secrets Manager: Securely stores database credentials and API keys. Amazon CloudWatch: Monitors metrics, logs, and creates alarms. AWS CloudTrail: Audit logs for all API calls and user activities. Amazon Athena: Queries and analyzes logs from S3. Amazon SNS: Sends notifications (email/SMS) for critical events (emergency blood needs, matching donors). System Workflow: User Access: Users ‚Üí Route 53 ‚Üí CloudFront ‚Üí S3 (Frontend) API Requests: Frontend ‚Üí API Gateway ‚Üí EC2 (Backend) ‚Üí RDS (Database) Data Flow: EC2 instances in public subnet connect to RDS in private subnet Outbound Traffic: Private subnet ‚Üí NAT Gateway ‚Üí Internet Gateway CI/CD Flow: GitLab ‚Üí CodePipeline ‚Üí CodeBuild ‚Üí EC2 deployment Monitoring: CloudWatch collects metrics ‚Üí SNS sends alerts ‚Üí Athena analyzes logs 4. Technical Implementation Implementation Phases: 1. Analysis \u0026amp; Design (Month 1) Gather requirements, define use cases, design ERD and AWS architecture. 2. Infrastructure \u0026amp; Pipeline Setup (Month 2) Configure Route 53, CloudFront, EC2, RDS, and CI/CD on AWS. 3. Development \u0026amp; Testing (Month 3‚Äì4) Build main modules: blood donation registration, search, blood bank management. Integrate Cognito and SNS alert system. 4. Deployment \u0026amp; Operations (Month 5) Deploy production system and monitor with CloudWatch. Key Technical Requirements: Frontend: React/Next.js or Angular (deployed via S3/CloudFront). Backend: Node.js/Express on EC2, communicating via REST API Gateway. Database: Amazon RDS MySQL, optimized queries and periodic backups. CI/CD: GitLab ‚Üí CodeBuild ‚Üí CodePipeline ‚Üí EC2. Auth: Cognito (4 roles: Guest, Member, Staff, Admin). Alert \u0026amp; Logs: SNS + CloudWatch + CloudTrail. 5. Roadmap \u0026amp; Milestones Timeline Phase Key Deliverables Month 1 Requirements Analysis \u0026amp; Design AWS architecture + use case diagrams Month 2 Infrastructure \u0026amp; Pipeline Setup EC2, RDS, API Gateway operational Month 3‚Äì4 Development \u0026amp; Testing Complete main modules Month 5 Production Deployment System operational and stable with Dashboard reports 6. Budget Estimation Service Estimated Cost/Month (USD) Notes EC2 (t3.nano) 3.50 Backend REST API Amazon RDS (MySQL) 2.80 20 GB storage API Gateway 0.50 5,000 requests CloudFront + S3 0.80 Website + CDN Route 53 0.50 Domain \u0026amp; DNS Cognito 0.10 \u0026lt;100 users CloudWatch + Logs 0.30 Monitoring and alerts CI/CD (CodePipeline, CodeBuild) 0.40 Automated deployment Total 8.9 USD/month ~106.8 USD/year Total costs can be adjusted based on AWS Free Tier or using spot instances.\n7. Risk Assessment Risk Impact Probability Mitigation Measures Internet Connection Loss Medium Medium Backup on EC2 instances DDoS Attack High Low AWS WAF + CloudFront User Data Errors High Low RDS backup + IAM access restrictions Budget Overrun Medium Low AWS budget alerts CI/CD Pipeline Disruption Low Medium Test pipeline before merge 8. Expected Outcomes Technical: Cloud-native system, automated CI/CD, multi-user support with high security. Application: Helps healthcare facilities manage blood donations efficiently, minimizing manual processes. Scalability: Can be scaled to multiple hospitals, integrate AI for blood type demand analysis or predict upcoming donation drives. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/5-workshop/5.2-prerequiste/",
	"title": "Prerequiste",
	"tags": [],
	"description": "",
	"content": "IAM permissions Add the following IAM permission policy to your user account to deploy and cleanup this workshop.\n{\r\u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,\r\u0026#34;Statement\u0026#34;: [\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;cloudformation:*\u0026#34;,\r\u0026#34;cloudwatch:*\u0026#34;,\r\u0026#34;ec2:AcceptTransitGatewayPeeringAttachment\u0026#34;,\r\u0026#34;ec2:AcceptTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:AllocateAddress\u0026#34;,\r\u0026#34;ec2:AssociateAddress\u0026#34;,\r\u0026#34;ec2:AssociateIamInstanceProfile\u0026#34;,\r\u0026#34;ec2:AssociateRouteTable\u0026#34;,\r\u0026#34;ec2:AssociateSubnetCidrBlock\u0026#34;,\r\u0026#34;ec2:AssociateTransitGatewayRouteTable\u0026#34;,\r\u0026#34;ec2:AssociateVpcCidrBlock\u0026#34;,\r\u0026#34;ec2:AttachInternetGateway\u0026#34;,\r\u0026#34;ec2:AttachNetworkInterface\u0026#34;,\r\u0026#34;ec2:AttachVolume\u0026#34;,\r\u0026#34;ec2:AttachVpnGateway\u0026#34;,\r\u0026#34;ec2:AuthorizeSecurityGroupEgress\u0026#34;,\r\u0026#34;ec2:AuthorizeSecurityGroupIngress\u0026#34;,\r\u0026#34;ec2:CreateClientVpnEndpoint\u0026#34;,\r\u0026#34;ec2:CreateClientVpnRoute\u0026#34;,\r\u0026#34;ec2:CreateCustomerGateway\u0026#34;,\r\u0026#34;ec2:CreateDhcpOptions\u0026#34;,\r\u0026#34;ec2:CreateFlowLogs\u0026#34;,\r\u0026#34;ec2:CreateInternetGateway\u0026#34;,\r\u0026#34;ec2:CreateLaunchTemplate\u0026#34;,\r\u0026#34;ec2:CreateNetworkAcl\u0026#34;,\r\u0026#34;ec2:CreateNetworkInterface\u0026#34;,\r\u0026#34;ec2:CreateNetworkInterfacePermission\u0026#34;,\r\u0026#34;ec2:CreateRoute\u0026#34;,\r\u0026#34;ec2:CreateRouteTable\u0026#34;,\r\u0026#34;ec2:CreateSecurityGroup\u0026#34;,\r\u0026#34;ec2:CreateSubnet\u0026#34;,\r\u0026#34;ec2:CreateSubnetCidrReservation\u0026#34;,\r\u0026#34;ec2:CreateTags\u0026#34;,\r\u0026#34;ec2:CreateTransitGateway\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayPeeringAttachment\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayPrefixListReference\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayRoute\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayRouteTable\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:CreateVpc\u0026#34;,\r\u0026#34;ec2:CreateVpcEndpoint\u0026#34;,\r\u0026#34;ec2:CreateVpcEndpointConnectionNotification\u0026#34;,\r\u0026#34;ec2:CreateVpcEndpointServiceConfiguration\u0026#34;,\r\u0026#34;ec2:CreateVpnConnection\u0026#34;,\r\u0026#34;ec2:CreateVpnConnectionRoute\u0026#34;,\r\u0026#34;ec2:CreateVpnGateway\u0026#34;,\r\u0026#34;ec2:DeleteCustomerGateway\u0026#34;,\r\u0026#34;ec2:DeleteFlowLogs\u0026#34;,\r\u0026#34;ec2:DeleteInternetGateway\u0026#34;,\r\u0026#34;ec2:DeleteNetworkInterface\u0026#34;,\r\u0026#34;ec2:DeleteNetworkInterfacePermission\u0026#34;,\r\u0026#34;ec2:DeleteRoute\u0026#34;,\r\u0026#34;ec2:DeleteRouteTable\u0026#34;,\r\u0026#34;ec2:DeleteSecurityGroup\u0026#34;,\r\u0026#34;ec2:DeleteSubnet\u0026#34;,\r\u0026#34;ec2:DeleteSubnetCidrReservation\u0026#34;,\r\u0026#34;ec2:DeleteTags\u0026#34;,\r\u0026#34;ec2:DeleteTransitGateway\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayPeeringAttachment\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayPrefixListReference\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayRoute\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayRouteTable\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:DeleteVpc\u0026#34;,\r\u0026#34;ec2:DeleteVpcEndpoints\u0026#34;,\r\u0026#34;ec2:DeleteVpcEndpointServiceConfigurations\u0026#34;,\r\u0026#34;ec2:DeleteVpnConnection\u0026#34;,\r\u0026#34;ec2:DeleteVpnConnectionRoute\u0026#34;,\r\u0026#34;ec2:Describe*\u0026#34;,\r\u0026#34;ec2:DetachInternetGateway\u0026#34;,\r\u0026#34;ec2:DisassociateAddress\u0026#34;,\r\u0026#34;ec2:DisassociateRouteTable\u0026#34;,\r\u0026#34;ec2:GetLaunchTemplateData\u0026#34;,\r\u0026#34;ec2:GetTransitGatewayAttachmentPropagations\u0026#34;,\r\u0026#34;ec2:ModifyInstanceAttribute\u0026#34;,\r\u0026#34;ec2:ModifySecurityGroupRules\u0026#34;,\r\u0026#34;ec2:ModifyTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:ModifyVpcAttribute\u0026#34;,\r\u0026#34;ec2:ModifyVpcEndpoint\u0026#34;,\r\u0026#34;ec2:ReleaseAddress\u0026#34;,\r\u0026#34;ec2:ReplaceRoute\u0026#34;,\r\u0026#34;ec2:RevokeSecurityGroupEgress\u0026#34;,\r\u0026#34;ec2:RevokeSecurityGroupIngress\u0026#34;,\r\u0026#34;ec2:RunInstances\u0026#34;,\r\u0026#34;ec2:StartInstances\u0026#34;,\r\u0026#34;ec2:StopInstances\u0026#34;,\r\u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsEgress\u0026#34;,\r\u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsIngress\u0026#34;,\r\u0026#34;iam:AddRoleToInstanceProfile\u0026#34;,\r\u0026#34;iam:AttachRolePolicy\u0026#34;,\r\u0026#34;iam:CreateInstanceProfile\u0026#34;,\r\u0026#34;iam:CreatePolicy\u0026#34;,\r\u0026#34;iam:CreateRole\u0026#34;,\r\u0026#34;iam:DeleteInstanceProfile\u0026#34;,\r\u0026#34;iam:DeletePolicy\u0026#34;,\r\u0026#34;iam:DeleteRole\u0026#34;,\r\u0026#34;iam:DeleteRolePolicy\u0026#34;,\r\u0026#34;iam:DetachRolePolicy\u0026#34;,\r\u0026#34;iam:GetInstanceProfile\u0026#34;,\r\u0026#34;iam:GetPolicy\u0026#34;,\r\u0026#34;iam:GetRole\u0026#34;,\r\u0026#34;iam:GetRolePolicy\u0026#34;,\r\u0026#34;iam:ListPolicyVersions\u0026#34;,\r\u0026#34;iam:ListRoles\u0026#34;,\r\u0026#34;iam:PassRole\u0026#34;,\r\u0026#34;iam:PutRolePolicy\u0026#34;,\r\u0026#34;iam:RemoveRoleFromInstanceProfile\u0026#34;,\r\u0026#34;lambda:CreateFunction\u0026#34;,\r\u0026#34;lambda:DeleteFunction\u0026#34;,\r\u0026#34;lambda:DeleteLayerVersion\u0026#34;,\r\u0026#34;lambda:GetFunction\u0026#34;,\r\u0026#34;lambda:GetLayerVersion\u0026#34;,\r\u0026#34;lambda:InvokeFunction\u0026#34;,\r\u0026#34;lambda:PublishLayerVersion\u0026#34;,\r\u0026#34;logs:CreateLogGroup\u0026#34;,\r\u0026#34;logs:DeleteLogGroup\u0026#34;,\r\u0026#34;logs:DescribeLogGroups\u0026#34;,\r\u0026#34;logs:PutRetentionPolicy\u0026#34;,\r\u0026#34;route53:ChangeTagsForResource\u0026#34;,\r\u0026#34;route53:CreateHealthCheck\u0026#34;,\r\u0026#34;route53:CreateHostedZone\u0026#34;,\r\u0026#34;route53:CreateTrafficPolicy\u0026#34;,\r\u0026#34;route53:DeleteHostedZone\u0026#34;,\r\u0026#34;route53:DisassociateVPCFromHostedZone\u0026#34;,\r\u0026#34;route53:GetHostedZone\u0026#34;,\r\u0026#34;route53:ListHostedZones\u0026#34;,\r\u0026#34;route53domains:ListDomains\u0026#34;,\r\u0026#34;route53domains:ListOperations\u0026#34;,\r\u0026#34;route53domains:ListTagsForDomain\u0026#34;,\r\u0026#34;route53resolver:AssociateResolverEndpointIpAddress\u0026#34;,\r\u0026#34;route53resolver:AssociateResolverRule\u0026#34;,\r\u0026#34;route53resolver:CreateResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:CreateResolverRule\u0026#34;,\r\u0026#34;route53resolver:DeleteResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:DeleteResolverRule\u0026#34;,\r\u0026#34;route53resolver:DisassociateResolverEndpointIpAddress\u0026#34;,\r\u0026#34;route53resolver:DisassociateResolverRule\u0026#34;,\r\u0026#34;route53resolver:GetResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:GetResolverRule\u0026#34;,\r\u0026#34;route53resolver:ListResolverEndpointIpAddresses\u0026#34;,\r\u0026#34;route53resolver:ListResolverEndpoints\u0026#34;,\r\u0026#34;route53resolver:ListResolverRuleAssociations\u0026#34;,\r\u0026#34;route53resolver:ListResolverRules\u0026#34;,\r\u0026#34;route53resolver:ListTagsForResource\u0026#34;,\r\u0026#34;route53resolver:UpdateResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:UpdateResolverRule\u0026#34;,\r\u0026#34;s3:AbortMultipartUpload\u0026#34;,\r\u0026#34;s3:CreateBucket\u0026#34;,\r\u0026#34;s3:DeleteBucket\u0026#34;,\r\u0026#34;s3:DeleteObject\u0026#34;,\r\u0026#34;s3:GetAccountPublicAccessBlock\u0026#34;,\r\u0026#34;s3:GetBucketAcl\u0026#34;,\r\u0026#34;s3:GetBucketOwnershipControls\u0026#34;,\r\u0026#34;s3:GetBucketPolicy\u0026#34;,\r\u0026#34;s3:GetBucketPolicyStatus\u0026#34;,\r\u0026#34;s3:GetBucketPublicAccessBlock\u0026#34;,\r\u0026#34;s3:GetObject\u0026#34;,\r\u0026#34;s3:GetObjectVersion\u0026#34;,\r\u0026#34;s3:GetBucketVersioning\u0026#34;,\r\u0026#34;s3:ListAccessPoints\u0026#34;,\r\u0026#34;s3:ListAccessPointsForObjectLambda\u0026#34;,\r\u0026#34;s3:ListAllMyBuckets\u0026#34;,\r\u0026#34;s3:ListBucket\u0026#34;,\r\u0026#34;s3:ListBucketMultipartUploads\u0026#34;,\r\u0026#34;s3:ListBucketVersions\u0026#34;,\r\u0026#34;s3:ListJobs\u0026#34;,\r\u0026#34;s3:ListMultipartUploadParts\u0026#34;,\r\u0026#34;s3:ListMultiRegionAccessPoints\u0026#34;,\r\u0026#34;s3:ListStorageLensConfigurations\u0026#34;,\r\u0026#34;s3:PutAccountPublicAccessBlock\u0026#34;,\r\u0026#34;s3:PutBucketAcl\u0026#34;,\r\u0026#34;s3:PutBucketPolicy\u0026#34;,\r\u0026#34;s3:PutBucketPublicAccessBlock\u0026#34;,\r\u0026#34;s3:PutObject\u0026#34;,\r\u0026#34;secretsmanager:CreateSecret\u0026#34;,\r\u0026#34;secretsmanager:DeleteSecret\u0026#34;,\r\u0026#34;secretsmanager:DescribeSecret\u0026#34;,\r\u0026#34;secretsmanager:GetSecretValue\u0026#34;,\r\u0026#34;secretsmanager:ListSecrets\u0026#34;,\r\u0026#34;secretsmanager:ListSecretVersionIds\u0026#34;,\r\u0026#34;secretsmanager:PutResourcePolicy\u0026#34;,\r\u0026#34;secretsmanager:TagResource\u0026#34;,\r\u0026#34;secretsmanager:UpdateSecret\u0026#34;,\r\u0026#34;sns:ListTopics\u0026#34;,\r\u0026#34;ssm:DescribeInstanceProperties\u0026#34;,\r\u0026#34;ssm:DescribeSessions\u0026#34;,\r\u0026#34;ssm:GetConnectionStatus\u0026#34;,\r\u0026#34;ssm:GetParameters\u0026#34;,\r\u0026#34;ssm:ListAssociations\u0026#34;,\r\u0026#34;ssm:ResumeSession\u0026#34;,\r\u0026#34;ssm:StartSession\u0026#34;,\r\u0026#34;ssm:TerminateSession\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;\r}\r]\r} Provision resources using CloudFormation In this lab, we will use N.Virginia region (us-east-1).\nTo prepare the workshop environment, deploy this CloudFormation Template (click link): PrivateLinkWorkshop . Accept all of the defaults when deploying the template.\nTick 2 acknowledgement boxes Choose Create stack The ClouddFormation deployment requires about 15 minutes to complete.\n2 VPCs have been created 3 EC2s have been created "
},
{
	"uri": "https://phuong721.github.io/learning-aws/3-blogstranslated/3.2-blog2/",
	"title": "Blog 2",
	"tags": [],
	"description": "",
	"content": "Simplifying Multi-Tenant Encryption with a Cost-Efficient AWS KMS Key Strategy Introduction Organizations face diverse challenges when it comes to managing encryption keys. While some scenarios require strict separation, there are practical use cases where a centralized approach can streamline operations and reduce complexity. In this post, we focus on Software-as-a-Service (SaaS) providers, but the principles can apply to large enterprises facing similar key-management challenges.\nManaging encryption in a multi-tenant, multi-service architecture presents significant complexity. Many organizations struggle with the overhead and cost of provisioning separate AWS Key Management Service (AWS KMS) customer managed keys for each tenant and each service. While secure, this approach often increases operational overhead and KMS usage costs over time.\nBut what if there were a more efficient way?\nIn this article, we introduce a strategy for using a single customer-managed (symmetric) key per tenant across your services. After reading this post, you will learn:\nHow to implement a scalable, secure, and cost-efficient encryption model Techniques for sharing a single customer-managed key per tenant across multiple services and environments How to encrypt tenant data stored in Amazon DynamoDB and other storage types while maintaining strong tenant isolation Multi-Tenant Encryption Requirements in SaaS Data isolation is a foundational requirement in SaaS multi-tenant architectures, supporting compliance and customer trust. Many SaaS providers must encrypt sensitive information‚Äîsuch as API keys, credentials, and personal data‚Äîin storage solutions like DynamoDB and Amazon Simple Storage Service (Amazon S3).\nAlthough these services provide default encryption at rest, they often use a single shared key across many data records. Consider DynamoDB in a shared-pool model, where a single table stores data for multiple tenants. In this setup, tenant data is encrypted using the same AWS KMS key regardless of ownership.\nA KMS key represents a top-level key container uniquely identified in AWS KMS. For more details about the hierarchy of keys involved when encrypting or decrypting data, see the AWS KMS key hierarchy.\nThis shared-key approach is often insufficient for SaaS providers operating under strict security or compliance frameworks. Some customers require:\nBring Your Own Key (BYOK) Logical data isolation via dedicated encryption keys To meet these demands, a provider may create dedicated AWS KMS customer managed keys for each customer, ensuring their sensitive data remains isolated and inaccessible to other tenants.\nProviders may also consider a silo model‚Äîseparate tables per customer. However, that approach introduces challenges: as the customer base grows, managing numerous tables becomes increasingly complex, and AWS service quotas can become limiting.\nScaling Concerns: Managing KMS Keys at Large Scale As a SaaS platform grows, empowering service teams to develop independently is crucial. A common scaling pattern is enabling each team to build services in dedicated AWS accounts. This often leads to a decentralized model where each service manages its own KMS keys per customer.\nHowever, this autonomy introduces hidden costs as both your customer base and service catalog expand.\nThe Challenge of Key Proliferation As the organization grows, the number of keys increases with each new tenant and service. This results in several challenges:\nCost impact: Each AWS KMS key costs $1 per month, up to $3 per month with two or more key rotations. Operational complexity: Managing many KMS keys across environments and accounts becomes error-prone and hard to scale. Organizational inefficiency: Duplicate engineering efforts as teams build and maintain similar key-management logic. Governance cost: Enforcing consistent policies and tracking KMS usage across multiple AWS accounts becomes difficult. A Streamlined Approach The solution lies in adopting a centralized key-management strategy‚Äîone KMS key per tenant, stored in a central AWS account. This approach effectively addresses cost, operational, and governance challenges while maintaining strong security guarantees.\nIn the following sections, we\u0026rsquo;ll explore how to implement this centralized model and securely share KMS keys across services and AWS accounts.\nSolution Overview: Centralized Tenant Key Management At the core of the solution is a centralized Tenant Key Management Service (shown as Service A in the illustration). This service manages the entire life cycle of tenant KMS keys‚Äîfrom creation during tenant onboarding to alias management, access policies, and deletion.\nThe service enables safe, scalable cross-organization use of keys through cross-account AWS Identity and Access Management (IAM) access. It grants other services (such as a customer-facing service in Account B) permissions to perform specific encryption operations using the tenant\u0026rsquo;s KMS key via role delegation. The design follows AWS best practices for cross-account IAM access using AWS Security Token Service (AWS STS), as described in AWS documentation and related blog posts.\nCentralized Key Management in Practice: Encrypting Customer Data Let‚Äôs examine how this works in practice with a common scenario:\nService A: The centralized tenant key-management service in Account A Service B: A customer-facing workload running in Account B When a customer interacts with Service B, sensitive information‚Äîsuch as secrets, API keys, or license information‚Äîmust be stored securely in a DynamoDB table. Instead of relying on a shared KMS key or default encryption, Service B encrypts data using the customer\u0026rsquo;s dedicated KMS key managed by Service A.\nThis process uses cross-account IAM role delegation. Service B temporarily assumes a role (ServiceARole) in Account A, gaining scoped permissions for the specific tenant‚Äôs KMS key. Using these temporary credentials, Service B can perform client-side encryption using AWS SDK or AWS Encryption SDK.\nSolution Walkthrough Assumptions and definitions:\nIncoming requests include an authentication header with a JWT containing the tenant identifier (). Account A: Centralized key-management service Account B: Customer-facing service alias/customer-: The alias format in Account A, mapped to each tenant\u0026rsquo;s KMS key ServiceARole: A role in Account A allowed to encrypt and decrypt using tenant-key aliases ServiceBRole: A role in Account B that may assume ServiceARole Let‚Äôs walk through the flow:\nUsing the Service with JWT A tenant-associated customer logs into the SaaS application and receives a JWT containing their tenant ID. The customer performs an action in Service B and sends sensitive data.\nService B processes the request, verifies the JWT, and must:\nEncrypt the customer\u0026rsquo;s sensitive data Store the encrypted value along with other data in DynamoDB Assuming the Role The Lambda execution role in Service B assumes ServiceARole in Account A. An alternative cross-account access method is KMS grants.\nExample IAM policy for ServiceARole, allowing encryption/decryption based only on alias/customer-*:\n{ \u0026ldquo;Version\u0026rdquo;: \u0026ldquo;2012-10-17\u0026rdquo;, \u0026ldquo;Statement\u0026rdquo;: [ { \u0026ldquo;Sid\u0026rdquo;: \u0026ldquo;AllowKMSByAlias\u0026rdquo;, \u0026ldquo;Effect\u0026rdquo;: \u0026ldquo;Allow\u0026rdquo;, \u0026ldquo;Action\u0026rdquo;: [ \u0026ldquo;kms:Encrypt\u0026rdquo;, \u0026ldquo;kms:Decrypt\u0026rdquo;, \u0026ldquo;kms:GenerateDataKey*\u0026rdquo; ], \u0026ldquo;Resource\u0026rdquo;: \u0026ldquo;\u0026rdquo;, \u0026ldquo;Condition\u0026rdquo;: { \u0026ldquo;StringLike\u0026rdquo;: { \u0026ldquo;kms:RequestAlias\u0026rdquo;: \u0026ldquo;alias/customer-\u0026rdquo; } } } ] }\nTo securely encrypt tenant secrets at scale, we grant application roles cross-account access to the KMS key‚Äîbut only through their alias, which maps to the tenant identifier contained in their JWT authentication token, enforcing strong isolation.\nYou can control access to the KMS key based on the aliases associated with each KMS key. To do this, use the kms:RequestAlias ‚Äã‚Äãand kms:ResourceAliases conditional keys as specified in Use aliases to control access to KMS keys.\nAdditionally, the ServiceARole trust policy allows ServiceBRole in account B to assume: { \u0026ldquo;Version\u0026rdquo;: \u0026ldquo;2012-10-17\u0026rdquo;, \u0026ldquo;Statement\u0026rdquo;: [ { \u0026ldquo;Effect\u0026rdquo;: \u0026ldquo;Allow\u0026rdquo;, \u0026ldquo;Principal\u0026rdquo;: { \u0026ldquo;AWS\u0026rdquo;: \u0026ldquo;arn:aws:iam::\u0026lt;ACCOUNT_B_ID\u0026gt;:role/ServiceBRole\u0026rdquo; }, \u0026ldquo;Action\u0026rdquo;: \u0026ldquo;sts:AssumeRole\u0026rdquo; } ] }\nDepending on your environment, you can add additional conditions to this trust policy to further narrow the scope of who can assume this role. For more information, see IAM and AWS STS condition context keys.\nEach customer-managed KMS key will then have the following policy. For example, a KMS key for a customer with : 123 will have a policy that restricts access to the key using a specific customer alias and only through ServiceRoleA. { \u0026ldquo;Version\u0026rdquo;: \u0026ldquo;2012-10-17\u0026rdquo;, \u0026ldquo;Id\u0026rdquo;: \u0026ldquo;TenantKeyPolicy\u0026rdquo;, \u0026ldquo;Statement\u0026rdquo;: [ { \u0026ldquo;Sid\u0026rdquo;: \u0026ldquo;AllowServiceARoleViaAlias\u0026rdquo;, \u0026ldquo;Effect\u0026rdquo;: \u0026ldquo;Allow\u0026rdquo;, \u0026ldquo;Principal\u0026rdquo;: { \u0026ldquo;AWS\u0026rdquo;: \u0026ldquo;arn:aws:iam::\u0026lt;ACCOUNT_A_ID\u0026gt;:role/ServiceARole\u0026rdquo; }, \u0026ldquo;Action\u0026rdquo;: [ \u0026ldquo;kms:Encrypt\u0026rdquo;, \u0026ldquo;kms:Decrypt\u0026rdquo;, \u0026ldquo;kms:GenerateDataKey*\u0026rdquo; ], \u0026ldquo;Resource\u0026rdquo;: \u0026ldquo;*\u0026rdquo;, \u0026ldquo;Condition\u0026rdquo;: { \u0026ldquo;StringLike\u0026rdquo;: { \u0026ldquo;kms:RequestAlias\u0026rdquo;: \u0026ldquo;alias/customer-123\u0026rdquo; } } } ] }\nHere is a Python code example that illustrates how Service B automatically assumes a role in Account A to encrypt data for a specific tenant using a session-scoped IAM policy that only allows access to that tenant\u0026rsquo;s KMS key alias.\nThis pattern follows the same principles outlined in Isolating SaaS Tenants with Dynamically Generated IAM Policies. The idea is to create and attach a tenant-specific IAM policy at runtime that grants the minimum permissions required to operate on tenant-owned resources‚Äîin this case, a KMS key alias. The credentials will allow the Lambda function to only use the KMS key that belongs to the customer (identified by tenant_id).\nWe\u0026rsquo;ll call assume_role_for_tenant for every tenant.\nStatus of \u0026ldquo;StringEquals\u0026rdquo; - \u0026ldquo;kms:RequestAlias\u0026rdquo;: alias is the magic formula of AWS STS, it restricts ServiceB from using the current tenant\u0026rsquo;s alias in its encrypted SDK calls and relies on alias authorization\nimport boto3 def assume_role_for_tenant(tenant_id: str): alias = f\u0026quot;alias/customer-{tenant_id}\u0026quot; # Session policy scoped to only the specific alias session_policy = { \u0026ldquo;Version\u0026rdquo;: \u0026ldquo;2012-10-17\u0026rdquo;, \u0026ldquo;Statement\u0026rdquo;: [ { \u0026ldquo;Effect\u0026rdquo;: \u0026ldquo;Allow\u0026rdquo;, \u0026ldquo;Action\u0026rdquo;: [ \u0026ldquo;kms:Encrypt\u0026rdquo;, \u0026ldquo;kms:Decrypt\u0026rdquo;, \u0026ldquo;kms:GenerateDataKey*\u0026rdquo; ], \u0026ldquo;Resource\u0026rdquo;: \u0026ldquo;*\u0026rdquo;, \u0026ldquo;Condition\u0026rdquo;: { \u0026ldquo;StringEquals\u0026rdquo;: { \u0026ldquo;kms:RequestAlias\u0026rdquo;: alias } } } ] } # Assume ServiceARole in Account A with inline session policy sts = boto3.client(\u0026ldquo;sts\u0026rdquo;) assumed = sts.assume_role( RoleArn=\u0026ldquo;arn:aws:iam::\u0026lt;ACCOUNT_A_ID\u0026gt;:role/ServiceARole\u0026rdquo;, RoleSessionName=f\u0026quot;Tenant{tenant_id}Session\u0026quot;, Policy=json.dumps(session_policy) ) return assumed[\u0026ldquo;Credentials\u0026rdquo;]\nEncrypt data and store it in DynamoDB Now, all that\u0026rsquo;s left to do is use the assumed role credentials and use the AWS SDK to encrypt sensitive customer data and store it in a DynamoDB table.\nUse temporary credentials to create a KMS client creds = assume_role_for_tenant(tenant_id, plaintext)\rkms = boto3.client(\r\u0026quot;kms\u0026quot;,\rregion_name=\u0026quot;us-east-1\u0026quot;,\raws_access_key_id=creds[\u0026quot;AccessKeyId\u0026quot;],\raws_secret_access_key=creds[\u0026quot;SecretAccessKey\u0026quot;],\raws_session_token=creds[\u0026quot;SessionToken\u0026quot;]\r)\r# Encrypt using the alias\rresponse = kms.encrypt(\rKeyId= f\u0026quot;alias/customer-{tenant_id}\u0026quot;\rPlaintext=plaintext\r)\r# store response[\u0026quot;CiphertextBlob\u0026quot;] in DynamoDB table\rThis article is not about isolation between different services, only isolation between tenants. If you need such service isolation, you can use an encryption context, an optional set of non-secret key/value pairs that can contain additional contextual information about the data, such as a service identifier. This helps ensure that services can only encrypt or decrypt data using their respective service encryption context.\nBenefits of Centralized Key Management Let\u0026rsquo;s see how this solution addresses our previous challenges.\nTenant Isolation Design While reducing the total number of KMS keys, we still maintain strict tenant isolation. Each customer\u0026rsquo;s sensitive data is still encrypted with a dedicated key, identified by a unique alias (alias/customer-). Access control to the tenant key is tightly managed through IAM role delegation, following the principles of least privilege:\nService A has exclusive control over the tenant\u0026rsquo;s KMS key management.\nService B can only assume the role of granting restricted encryption, decryption, and GenerateDataKey access to the customer-managed key specified by the alias: alias/customer-.\nOptimized Cost Management Our approach significantly reduces costs by moving from multiple service-specific KMS keys per tenant to a single KMS key per tenant, securely shared across multiple services and environments. This approach introduces a new centralized account (Account A) that provides access to encryption keys in appropriate circumstances. It is important to understand AWS STS limits, specific to calls, and consider mechanisms for storing temporary IAM credentials if those limits become a bottleneck. Additionally, if KMS limits are a bottleneck, consider using data key caching using the AWS Encryption SDK.\nStreamlined Operations and Governance By centralizing key management in Service A, you can achieve:\nConsistent KMS key lifecycle management across the organization Improved auditability by using AWS CloudTrail to better understand key access patterns by service Reduced operational costs Simplified compliance monitoring The only additional complexity is setting up initial cross-account role delegation between Service A and other services. Once established, this framework can be extended to accommodate new subscribers and services.\nIt is best to encapsulate the logic for role assignment, policy generation, and AWS SDK client initialization in a common SDK for the entire organization. This abstraction reduces the cognitive load on developers and minimizes the risk of misconfiguration. You can go further by providing high-level utility functions like encrypt_tenant_data() and decrypt_tenant_data(), which hide the underlying complexity while promoting secure and consistent usage patterns across the team.\nConclusion In this article, we explored an effective approach to managing encryption keys in multi-tenant SaaS environments through centralization. We looked at common challenges faced by growing SaaS providers, including key proliferation, rising costs, and operational complexity across multiple AWS accounts and services. This centralized key management solution uses AWS best practices for IAM role delegation and cross-account access, allowing organizations to maintain security and compliance while minimizing operational costs. By implementing this approach, SaaS providers or large organizations facing similar challenges can effectively manage their encryption infrastructure as they scale, without compromising security or increasing complexity.\nAbout the Authors Itay Meller is a Security Specialist Solutions Architect at AWS, with a strong background in cybersecurity R\u0026amp;D and leadership roles at multiple security-focused companies. With extensive expertise in cloud security, Itay helps organizations securely adopt and scale AWS environments by solving complex security and compliance challenges.\nRan Isenberg is an AWS Serverless Hero, Principal Software Architect at CyberArk, blogger and speaker. He maintains the blog RanTheBuilder.cloud, where he shares his knowledge and experience in the Serverless world.\nYossi Lagstein is a Senior Solutions Architect at Amazon Web Services. Yossi has over 30 years of experience as an expert and manager developing infrastructure components for a variety of projects and products. Yossi helps AWS customers develop, design, and build well-architected solutions. Outside of work, Yossi enjoys running, swimming, and hiking.\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/5-workshop/5.3-deploy-infrastructure/",
	"title": "Deploy Infrastructure with CloudFormation",
	"tags": [],
	"description": "",
	"content": "Overview In this step, you will deploy the complete AWS infrastructure using CloudFormation template. The template will create VPC, subnets, EC2 instances, RDS database, Load Balancer, S3 buckets, CloudFront distribution, and all necessary resources.\nValidate Template Before deployment, validate the template to ensure no syntax errors:\ncd aws aws cloudformation validate-template \\ --template-body file://infrastructure.yaml \\ --region ap-southeast-1 Expected result: Information about parameters, outputs, and template description.\nDeploy Stack Method 1: Using Deploy Script (Recommended) Windows:\ncd aws deploy.bat create Linux/Mac:\ncd aws chmod +x deploy.sh ./deploy.sh create The script will automatically:\nValidate template Create CloudFormation stack Monitor deployment progress Display outputs when complete Method 2: Using AWS CLI aws cloudformation create-stack \\ --stack-name workshop-aws-dev \\ --template-body file://infrastructure.yaml \\ --parameters file://parameters.json \\ --capabilities CAPABILITY_NAMED_IAM \\ --region ap-southeast-1 Monitor Progress Via AWS Console Open CloudFormation Console Select stack workshop-aws-dev Events tab: View resources being created Resources tab: View resource list Outputs tab: View outputs (after completion) Via AWS CLI # Check status aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].StackStatus\u0026#39; # View events aws cloudformation describe-stack-events \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --max-items 10 Deployment Time Stack creation takes approximately 15-20 minutes:\nVPC and Networking: 2-3 minutes NAT Gateway: 2-3 minutes RDS Database: 5-7 minutes EC2 Auto Scaling Group: 3-5 minutes Load Balancer: 2-3 minutes CloudFront Distribution: 5-10 minutes VPC Endpoints: 2-3 minutes View Outputs After stack creation succeeds (Status: CREATE_COMPLETE), get outputs:\naws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs\u0026#39; \\ --output table Important Outputs:\nOutput Key Description Example VPCId VPC ID vpc-0123456789abcdef0 FrontendBucketName S3 bucket for frontend workshop-aws-dev-frontend-123456789012-ap-southeast-1 CloudFrontDomainName CloudFront URL d1234567890abc.cloudfront.net ALBDNSName Load Balancer DNS workshop-aws-dev-alb-123456789.ap-southeast-1.elb.amazonaws.com RDSEndpoint Database endpoint workshop-aws-dev-db.xxxxx.ap-southeast-1.rds.amazonaws.com APIGatewayURL API Gateway URL https://xxxxx.execute-api.ap-southeast-1.amazonaws.com/dev CognitoUserPoolId Cognito User Pool ID ap-southeast-1_xxxxxxxxx Save these values - you\u0026rsquo;ll need them for next steps!\nVerify Created Resources 1. VPC and Networking # Get VPC ID VPC_ID=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`VPCId`].OutputValue\u0026#39; \\ --output text) # View VPC details aws ec2 describe-vpcs --vpc-ids $VPC_ID --region ap-southeast-1 # View Subnets aws ec2 describe-subnets \\ --filters \u0026#34;Name=vpc-id,Values=$VPC_ID\u0026#34; \\ --region ap-southeast-1 \\ --query \u0026#39;Subnets[*].[SubnetId,CidrBlock,AvailabilityZone,Tags[?Key==`Name`].Value|[0]]\u0026#39; \\ --output table 2. EC2 Instances # View EC2 instances in Auto Scaling Group aws ec2 describe-instances \\ --filters \u0026#34;Name=tag:aws:cloudformation:stack-name,Values=workshop-aws-dev\u0026#34; \\ --region ap-southeast-1 \\ --query \u0026#39;Reservations[*].Instances[*].[InstanceId,State.Name,PrivateIpAddress,PublicIpAddress]\u0026#39; \\ --output table 3. RDS Database # View RDS instance aws rds describe-db-instances \\ --db-instance-identifier workshop-aws-dev-db \\ --region ap-southeast-1 \\ --query \u0026#39;DBInstances[0].[DBInstanceIdentifier,DBInstanceStatus,Endpoint.Address,Endpoint.Port]\u0026#39; \\ --output table Troubleshooting Stack Creation Failed If stack creation fails:\nView Events to find error: aws cloudformation describe-stack-events \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;StackEvents[?ResourceStatus==`CREATE_FAILED`].[LogicalResourceId,ResourceStatusReason]\u0026#39; \\ --output table Common errors: Error: \u0026ldquo;Key pair does not exist\u0026rdquo;\nCheck key pair name in parameters.json Ensure key pair exists in ap-southeast-1 region Error: \u0026ldquo;Invalid AMI ID\u0026rdquo;\nUpdate AMI ID in infrastructure.yaml Use AMI ID appropriate for your region Error: \u0026ldquo;Insufficient permissions\u0026rdquo;\nCheck IAM permissions of user Need CloudFormation, EC2, VPC, RDS, S3, IAM permissions Rollback and retry: # Delete failed stack aws cloudformation delete-stack \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 # Wait for stack deletion aws cloudformation wait stack-delete-complete \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 # Try creating again aws cloudformation create-stack \\ --stack-name workshop-aws-dev \\ --template-body file://infrastructure.yaml \\ --parameters file://parameters.json \\ --capabilities CAPABILITY_NAMED_IAM \\ --region ap-southeast-1 Confirm Successful Deployment Checklist to confirm infrastructure is ready:\nStack status is CREATE_COMPLETE VPC and subnets created EC2 instances running (State: running) RDS database status is available Load Balancer status is active S3 buckets created CloudFront distribution status is Deployed All outputs have values Next Steps After infrastructure is ready, you can:\n‚û°Ô∏è Configure and Deploy Backend Application\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/1-worklog/1.3-week3/",
	"title": "Worklog Week 3",
	"tags": [],
	"description": "",
	"content": "Week 3 Goals: Practice deploying AWS Backup and ensure data restore. Deploy S3, Storage Gateway, manage data and file shares. Set up and manage a static website on S3 with CloudFront. Learn advanced S3 features: versioning, replication, and access management. Clean up resources after testing to avoid unnecessary costs. Tasks for this week: Day Task Start Date End Date Resources Mon - Deploy AWS Backup to the system - Introduction (Module 03-Lab13-01) - Deploy infrastructure (Module 03-Lab13-02.2) - Create Backup Plan (Module 03-Lab13-03) 22/09/2025 22/09/2025 https://000013.awsstudygroup.com/ Tue - Test Restore (Module 03-Lab13-05) - Clean up Backup resources (Module 03-Lab13-06) 23/09/2025 23/09/2025 https://000013.awsstudygroup.com/ Wed - Create S3 Bucket \u0026amp; EC2 for Storage Gateway (Module 03-Lab24-01.1 \u0026amp; 01.2) - Create Storage Gateway and File Shares (Module 03-Lab24-02.1 \u0026amp; 02.2) 24/09/2025 24/09/2025 https://000024.awsstudygroup.com/ Thu - Create S3 Bucket, load data, enable static website (Module 03-Lab57-02.1, 02.2 \u0026amp; 03) - Configure public access and test website (Module 03-Lab57-04, 05, 06) 25/09/2025 25/09/2025 https://000057.awsstudygroup.com/ Fri - Block all public access, configure CloudFront \u0026amp; test (Module 03-Lab57-07.1 to 07.3) - Use bucket versioning, move objects, multi-region replication (Module 03-Lab57-08, 09, 10) 26/09/2025 26/09/2025 https://000057.awsstudygroup.com/ Sat - Clean up S3 \u0026amp; CloudFront resources (Module 03-Lab57-11) 27/09/2025 27/09/2025 https://000057.awsstudygroup.com/ Sun - Weekly summary, evaluate results, record lessons learned on Backup, Storage Gateway, and S3/CloudFront 28/09/2025 28/09/2025 N/A Week 3 Achievements: AWS Backup:\nSuccessfully deployed Backup Plan and tested data restore. Cleaned up backup resources after testing. Storage Gateway \u0026amp; S3:\nCreated S3 Bucket and EC2 for Storage Gateway. Configured Storage Gateway and file shares, loaded data successfully. Static Website \u0026amp; CloudFront:\nDeployed static website on S3, configured public access, and verified display. Configured CloudFront to distribute content, checked operation. Applied versioning, moved objects, and performed multi-region replication. Self-evaluation:\nMastered AWS Backup, Storage Gateway, S3, and CloudFront deployment steps. Practiced restore testing, versioning, replication, and resource cleanup. Ready for next week with advanced AWS exercises on security and cost optimization. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/3-blogstranslated/",
	"title": "Translated Blogs",
	"tags": [],
	"description": "",
	"content": "Blog 1 - Accelerate your Cloud Strategy with Megaport\u0026rsquo;s 25 Gbps Hosted AWS Direct Connect This blog introduces how to accelerate your cloud strategy with Megaport\u0026rsquo;s 25 Gbps Hosted AWS Direct Connect. You will learn the benefits of performance, scalability, and secure network connectivity between on-premises and the cloud, and how to deploy and manage this connectivity to optimize costs and operational efficiency.\nBlog 2 - Simplify multi-subscriber encryption with cost-effective AWS KMS key strategies This blog guides you through how to simplify multi-subscriber encryption with cost-effective AWS KMS key strategies. You will learn how to manage and distribute KMS keys efficiently, optimize costs, ensure data security on a per-tenant basis, and maintain performance and scalability in a multi-tenant environment.\nBlog 3 - Open Protocol for Agent Interoperability Part 4: A2A Agent Communication This blog introduces the Agent-to-Agent (A2A) protocol that enables AI agents to communicate directly with each other. You will learn how AWS supports A2A through the Strands Agents SDK, key features such as Agent Tags, structured task execution, multiple transport options, and A2A security. The article also illustrates example deployments of HR agents and Employee Information agents using A2A, and customer feedback on multi-agent interoperability.\nBlog 4 - \u0026hellip; This blog introduces how to start building a data lake in the healthcare sector by applying a microservices architecture. You will learn why data lakes are important for storing and analyzing diverse healthcare data (electronic medical records, lab test data, medical IoT devices‚Ä¶), how microservices help make the system more flexible, scalable, and easier to maintain. The article also guides you through the steps to set up the environment, organize the data processing pipeline, and ensure compliance with security \u0026amp; privacy standards such as HIPAA.\nBlog 5 - \u0026hellip; This blog introduces how to start building a data lake in the healthcare sector by applying a microservices architecture. You will learn why data lakes are important for storing and analyzing diverse healthcare data (electronic medical records, lab test data, medical IoT devices‚Ä¶), how microservices help make the system more flexible, scalable, and easier to maintain. The article also guides you through the steps to set up the environment, organize the data processing pipeline, and ensure compliance with security \u0026amp; privacy standards such as HIPAA.\nBlog 6 - \u0026hellip; This blog introduces how to start building a data lake in the healthcare sector by applying a microservices architecture. You will learn why data lakes are important for storing and analyzing diverse healthcare data (electronic medical records, lab test data, medical IoT devices‚Ä¶), how microservices help make the system more flexible, scalable, and easier to maintain. The article also guides you through the steps to set up the environment, organize the data processing pipeline, and ensure compliance with security \u0026amp; privacy standards such as HIPAA.\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/3-blogstranslated/3.3-blog3/",
	"title": "Blog 3",
	"tags": [],
	"description": "",
	"content": "Open Protocol for Agent Interoperability Part 4: A2A Agent Communication Introduction: Welcome to Part 4 of our Open Protocols for Agent Interoperability blog series where we will cover the Agent-to-Agent (A2A) protocol, AWS\u0026rsquo;s involvement with the Linux Foundation-based open standard, and our support for A2A in the Strands Agents SDK. Here\u0026rsquo;s what we\u0026rsquo;ve covered so far:\nPart 1: How the Model Context Protocol (MCP) facilitates communication between agents and how AWS has worked to improve the MCP specification to better support agent-to-agent communication.\nPart 2: Details on recent MCP specification updates related to Authentication.\nPart 3: How to build inter-agent systems with the new Strands Agents SDK and MCP\nStandard protocols are the primary way to connect network services. Typically, there are different protocols to address different types of network connectivity. At the network layer, there are two main protocols: TCP and UDP. Each protocol is suited to specific needs, and neither protocol is universal. This is also true when connecting AI agents. In part 4 of our agent-to-agent communication series, we will introduce A2A, how it can be used for agent-to-agent communication, and how AWS helps customers build systems with A2A.\nMCP was originally created to connect agents to tools, but can also be used to connect agents to each other. A2A was created to connect agents to each other, and can also be used in conjunction with MCP for agents to communicate with tools. Which protocol to use for agent-to-agent communication depends on your needs. AWS supports both protocols, allowing customers to deploy their code on AWS using MCP, A2A, or a combination of both.\nAs inter-agent protocols and the frameworks around them evolve, they will likely become more like TCP \u0026amp; UDP, where most developers focus more on building their agents rather than the underlying protocols. The first step towards that is for agent frameworks to support the protocols and build ecosystems around them. At AWS, we have taken this first step by joining the A2A standards community and adding support for A2A in our open-source Strands Agents SDK. Swami Sivasubramanian, Vice President of AWS Agentic AI, summarizes this effort:\nAt AWS, we believe agentic AI will be critical to nearly every customer experience. We welcome A2A to the Linux Foundation and expect this to create more opportunities for anyone building AI applications. We plan to support the community with project contributions and access to the broadest and deepest set of agentic frameworks, protocols, and services.\nSimilar to how we are supporting the development of MCP, we are supporting the development of A2A to meet customer needs. We plan to focus on several areas to make A2A work well on AWS, including support for Amazon Bedrock AgentCore, extending the A2A protocol for temporary task storage and SigV4, improving multi-task management, and improving the Java A2A SDK.\nOverview of A2A The A2A protocol addresses a key challenge in the AI ‚Äã‚Äãlandscape. It enables AI agents built on diverse platforms, operated by different companies on separate servers, to communicate and collaborate effectively‚Äîas agents, not just tools. A2A represents a significant step forward in creating interoperable AI systems that work together across organizational boundaries. The protocol is supported by a growing partner ecosystem, including more than 50 technology companies such as Google, Atlassian, Confluent, Salesforce, SAP, and MongoDB.\nBefore A2A, organizations faced significant challenges in deploying multi-agent AI systems at scale. Without a standardized protocol, each pair of agents required custom integration code, leading to excessive development costs and maintenance complexity. This creates siloed AI systems where specialized agents cannot easily share capabilities or coordinate on complex tasks. The protocol provides agents with a common language, allowing them to maintain their autonomy and specialized skills while collaborating‚Äîagents communicate with each other as peers, not just tools. This distinction is important because it allows agents to engage in complex back-and-forth interactions, negotiate task requirements, and maintain independent decision-making while working toward common goals.\nFor AWS customers, A2A offers a number of compelling features that align with enterprise requirements. The protocol enables enterprise capabilities including secure agent discovery through standardized agent tags, authentication and authorization mechanisms for controlled access, support for multiple communication methods (text, forms, media), and the ability to allow agents to collaborate on long-running tasks without revealing their internal state or implementation details.\nA2A addresses the unique challenges of multi-agent collaboration through features that enable complex workflows, handling complex real-world business processes with the observability and control required by production environments. Specifically, it supports agent tags, structured tasks, multiple transport options, and authentication/authorization primitives.\nAgent Tags Effective multi-agent communication requires agents to discover and understand each other‚Äôs capabilities. A2A supports this through Agent Tags ‚Äî metadata documents that capture semantic meaning about what each agent can do, how it prefers to operate, and what types of tasks it is good at. Agent Tags enable other agents to make intelligent decisions about when and how to cooperate. Agent Tags also describe an agent‚Äôs authentication/authorization requirements and support incrementally expanded capabilities after authentication, using Authenticated Extended Agent Tags.\nStructured Task Execution Agents work together to solve problems by leveraging tasks to structure their communication; they organize their messages into intelligent units of work, carry context, track progress, and store output artifacts. Through tasks, agents can reference previously created artifacts, understand dependencies between tasks in a workflow, and make informed decisions based on the entire conversation history. Tasks support both sequential and parallel execution for complex workflows. Agents can create multiple subsequent tasks simultaneously and create dependent activity chains. This gives application developers the flexibility to model real-world business processes.\nBy leveraging task IDs and context, applications can trace task origins, tracing task chains back to their roots to recover information about how outputs are produced. This improves observability by providing agents with the ability to generate rich activity logs for debugging and auditing.\nMultiple Transport Options A2A empowers application developers by supporting three core protocols with equivalent capabilities: JSON-RPC 2.0, gRPC, and REST. This allows developers to choose the transport that best fits their team‚Äôs expertise, existing infrastructure, and performance requirements. For long-running operations, A2A enhances each transport with Server-Sent Events (SSE) for streaming and sending webhook-based push notifications. Developers have intuitive options for handling asynchronous task updates and real-time progress monitoring without complex polling logic.\nA2A Security Enterprise-grade security is a non-negotiable requirement for agent systems. A2A enables a robust security architecture by supporting a number of authentication protocols; including OAuth 2.0, OpenID Connect, and mTLS, allowing organizations to integrate agents with their existing identity infrastructure, while skill-specific authorization metadata and secondary authentication support allow for fine-grained access control policies that can be enforced at the application level.\nA2A‚Äôs decision to keep agents opaque to each other supports a zero-trust architecture by treating each agent as an independent security boundary, and the protocol‚Äôs support for task auditing provides the foundation for comprehensive security monitoring and compliance reporting.\nInter-Agent with Strands Agents \u0026amp; A2A The unique features of A2A make it perfect for interoperability between agent platforms. Several open source agent platforms already support it. The open source Strands Agents SDK recently added support for A2A so agents can easily communicate with other agents.\nStrands Agents takes a model-driven approach to building and operating AI agents in just a few lines of code. Strands scales from simple to complex agent use cases, and from local development to production deployment. Many teams at AWS have used Strands for AI agents in production, including Amazon Q Developer, AWS Glue, and VPC Reachability Analyzer.\nWith built-in A2A support in Strands Agents, you can easily use an agent as an A2A server and communicate from one Strands Agent to other A2A agents. To illustrate this, consider the example of a Human Resources (HR) agent that can answer questions about employees. To do this, you can imagine the HR agent communicating with several other agents such as an employee data agent, an Enterprise Resource Planning (ERP) agent, a performance agent, a goals agent, etc. For this example, let\u0026rsquo;s start with a basic architecture, where a REST API provides access to an HR agent that connects to an Employee Info agent: The architecture of the inter-agent system consists of two agents (HR \u0026amp; Employee Info), connected using A2A.\nNote: The complete, working version of the following example is available in our Agentic AI samples repo.\nOur employee information tool uses Amazon Bedrock and the MCP tool to retrieve employee data (see full code for those aspects): employee_agent = Agent( model=bedrock_model, name=\u0026ldquo;Employee Agent\u0026rdquo;, description=\u0026ldquo;Answers questions about employees\u0026rdquo;, tools=tools, system_prompt=\u0026ldquo;you must abbreviate employee first names and list all their skills\u0026rdquo; )\nTo expose this agent via A2A, we just need to create an A2A server and start it when the program runs: a2a_server = A2AServer(agent=employee_agent, host=urlparse(EMPLOYEE_AGENT_URL).hostname, port=urlparse(EMPLOYEE_AGENT_URL).port)\nif name == \u0026ldquo;main\u0026rdquo;: a2a_server.serve(host=\u0026ldquo;0.0.0.0\u0026rdquo;, port=8001)\nNote that we pass EMPLOYEE_AGENT_URL via an environment variable. This helps our infrastructure definition know the endpoint URL that can set the host and port used in the A2A agent tag (used by the A2A client to discover the agent).\nNow we can access the Employee Info agent via A2A and we can create the HR agent: provider = A2AClientToolProvider(known_agent_urls=[EMPLOYEE_AGENT_URL]) agent = Agent(model=bedrock_model, tools=provider.tools)\nThis agent can now be invoked in a variety of ways. In this example, we invoke it from a REST request. See the full code for the REST aspects. Here\u0026rsquo;s what happens when a REST request is made:\nThe user (possibly via a web or mobile app) sends a query like \u0026ldquo;list employees with AI-related skills\u0026rdquo;\nThe HR agent uses the Amazon Nova model to understand the user\u0026rsquo;s query and decides that it should be sent to the employee information agent.\nUsing A2A, the query is sent to the Employee Information agent.\nThe Employee Information agent uses the Amazon Nova model to understand the query and decides that it should call the Employee Data MCP server.\nThe Employee Information agent calls the Employee Data MCP server to query the employee database and return the data to the Nova model.\nGiven a system requirement to abbreviate employee names, the model takes a list of employees, formats the list nicely, abbreviates the names, and returns the text to the Employee Info agent.\nThe Employee Info agent returns the text to the HR agent, which returns the text in a REST response.\nOf course, all of this can run on AWS using a variety of runtime environments (Amazon Elastic Kubernetes Service (Amazon EKS), Amazon Elastic Container Service (Amazon ECS), Amazon Bedrock AgentCore, AWS Lambda, etc.). This example contains an AWS CloudFormation deployment template that deploys the agents and MCP servers on Amazon ECS (all in a VPC) and an Application Load Balancer to expose the REST service.\nWe can experiment with curl: curl -X POST \u0026ndash;location \u0026ldquo;http://something.us-east-1.elb.amazonaws.com/inquire\" -H \u0026ldquo;Content-Type: application/json\u0026rdquo; -d \u0026lsquo;{\u0026ldquo;question\u0026rdquo;: \u0026ldquo;list employees that have skills related to AI programming\u0026rdquo;}\u0026rsquo; And we are back: Here are the employees with skills related to AI programming:\nA. Rosalez - Machine Learning, REST API E. Owusu - DevOps, Machine Learning, Python J. Doe- Machine Learning, JavaScript K. Mensah - REST API, Kubernetes, Machine Learning, Node.js M. Rivera - AWS, Kubernetes, GraphQL, Machine Learning M. Major - MongoDB, Angular, Kotlin, Machine Learning, REST API C. Salazar - React, Machine Learning, SQL, Kotlin N. Wolf - SQL, Machine Learning, Docker, DevOps, Git If you need more If you need detailed information about any of these employees or require further assistance, please let me know!\nGet the complete source for this example.\nWith Strands Agents, it takes just a few lines of code to expose agents as A2A servers and communicate between agents using A2A. In future posts, we will cover more advanced agent types such as Swarms, Graphs, and Workflows.\nCustomer Perspectives We‚Äôve heard from a number of customers and partners who are excited about our A2A support. Here are some of their thoughts:\n‚ÄúAt Autodesk, we are committed to driving open standards for agent AI and interoperability as we shape the future of design and engineering. Through our collaboration with AWS and the A2A community, we are excited to help build an ecosystem where intelligent agents can communicate seamlessly across Autodesk platforms. As we continue to enhance Autodesk Platform Services with generative AI capabilities, we see tremendous potential in how interoperable AI agents can transform workflows across architecture, engineering, construction, and manufacturing. Working with AWS, we are committed to creating solutions that enable secure and efficient agent collaboration while maintaining enterprise-grade standards.‚Äù ‚Äì Ritesh Bansal, Vice President of Data Analytics, Insights and AI/ML Platform, Autodesk\n‚ÄúOur commitment to developing Agentic AI, open protocols, and interoperability is at the core of our vision for secure and intelligent networks. By collaborating with AWS and the A2A community, we are driving innovation to set new standards for AI-based security, enabling organizations to operate with greater resilience and confidence in the rapidly evolving AI era.‚Äù ‚Äì Raj Chopra, Senior Vice President and Chief Product Officer, Security, Cisco\n‚ÄúAs organizations design increasingly sophisticated agentic AI systems, coordination between agents and tools is becoming essential. We are excited to see AWS accelerate efforts like A2A, supporting better interoperability architectures that help organizations and Datadog customers build more observable, reliable, and secure agent-based applications.‚Äù ‚Äî Yrieix Garnier, Vice President of Product, Datadog\n‚ÄúMongoDB and AWS are committed to building an open, interoperable ecosystem that gives developers greater freedom to innovate. Adopting open standards like A2A is an important step toward this vision, simplifying how agents interact with MongoDB\u0026rsquo;s rich document model, built-in vector search, and Voyage AI models.‚Äù ‚Äì Abhinav Mehla, Vice President of Global Partner Programs \u0026amp; Ecosystem, MongoDB\n‚ÄúInteroperability is critical for AI agents to work seamlessly and efficiently across enterprise systems and tools, which is why we collaborated with the industry to develop the A2A standard, and why we will support open standards like A2A and MCP in Agentforce. AWS‚Äôs support for A2A will continue to help break down barriers between vendors, drive innovation, and deliver significant value to our mutual customers by enabling agents to work across the company‚Äôs entire infrastructure and ecosystem of tools and agents.‚Äù ‚Äî Gary Lerhaupt, Vice President of Product Architecture, Salesforce\n‚ÄúIt‚Äôs exciting to see industry leaders like AWS back the Agent2Agent protocol. What started as a bold idea is now quickly becoming an industry standard ‚Äì one based on openness, security, and cross-platform interoperability. With support from AWS and other partners, the A2A ecosystem is truly thriving, and ServiceNow is proud to lead this trend by making enterprise-grade, interoperable AI agents a reality.‚Äù ‚Äì Joe Davis, Executive Vice President of Platform Engineering \u0026amp; AI Technologies at ServiceNow.\nSnowflake firmly believes that some of the industry‚Äôs biggest innovations come from open protocols and the communities that support them. Maximizing the potential of agentic AI depends on open protocols like A2A, as well as the shared knowledge and best practices they provide. We are excited to see AWS demonstrate their commitment to open protocols for agent interoperability by adding A2A support to Strands Agents. Together with the support of the broader technology community, the industry will be able to automate knowledge work with secure agentic systems like Strands Agents and Snowflake Cortex Agents. ‚Äì Dwarak Rajagopal, Vice President of AI Engineering \u0026amp; Research, Snowflake\n‚ÄúIn the future, a fragmented workforce of humans and AI agents will inevitably hinder growth. We believe that open protocols, particularly Agent-to-Agent (A2A) Protocols, play a critical role in the evolution of this hybrid workforce. They enable secure, collaborative communication, ensuring interoperability across diverse agent ecosystems. Workday‚Äôs Agent System of Record (ASOR) uniquely extends our trusted platform to manage people, finances, and agents together. Working with AWS and the A2A community, we are committed to enabling secure, interoperable agent communication. This isn‚Äôt just about new technology; it‚Äôs about securely unlocking new levels of productivity and innovation across the enterprise, while maintaining complete control.‚Äù ‚ÄîDean Arnold, Vice President of System of Record, Workday\nGetting Started and Providing Feedback To get started building interactive AI agents using A2A, check out the Strands Agents A2A docs. We\u0026rsquo;d love to hear your feedback on using A2A with Strands Agents! Join the discussions on the open source Strands Agents Python SDK repo to let us know what else you need to know when building an inter-agent system.\nNick Aldridge is a Principal Engineer at AWS. Over the past 6 years, Nick has been involved in multiple AI/ML initiatives, including Amazon Lex and Amazon Bedrock. Most recently, he led the launch of Amazon Bedrock Knowledge Bases. Currently, he works on generative AI and AI infrastructure, focusing on agent collaboration and function invocation. Before joining AWS, Nick earned his Master\u0026rsquo;s degree from the University of Chicago.\nJames Ward is a Principal Developer Advocate at AWS. James travels the world helping enterprise developers learn how to build reliable systems. His current focus is on helping developers build systems of AI agents using Spring AI, Embabel, Strands Agents, Amazon Bedrock, MCP, and A2A.\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/5-workshop/5.4-deploy-backend/",
	"title": "Deploy Backend Application",
	"tags": [],
	"description": "",
	"content": "Overview In this step, you will build and deploy the Spring Boot backend application to EC2 instances. The backend provides RESTful API for DNA analysis, user authentication, and data management.\nStep 1: Configure Database Connection Get RDS endpoint from CloudFormation outputs:\nRDS_ENDPOINT=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`RDSEndpoint`].OutputValue\u0026#39; \\ --output text) echo \u0026#34;RDS Endpoint: $RDS_ENDPOINT\u0026#34; Update file BE/workshop_BE/src/main/resources/application.properties:\n# Database Configuration spring.datasource.url=jdbc:mysql://${RDS_ENDPOINT}:3306/workshop_aws?useSSL=true\u0026amp;requireSSL=false\u0026amp;allowPublicKeyRetrieval=true\u0026amp;serverTimezone=Asia/Ho_Chi_Minh spring.datasource.username=admin spring.datasource.password=YourStrongPassword123! spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver # Connection Pool spring.datasource.hikari.maximum-pool-size=10 spring.datasource.hikari.minimum-idle=5 spring.datasource.hikari.connection-timeout=20000 # JPA Configuration spring.jpa.hibernate.ddl-auto=update spring.jpa.show-sql=false spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MySQL8Dialect # Server Configuration server.port=8080 server.servlet.context-path=/dna_service # JWT Configuration jwt.signerKey=2VJ50pdhYm96e4VECp/vsZGVmkSl9xp1rSYAZKsZL7n9Ti1pZYle3k9mheQEKt6+ jwt.expiration=86400000 # CORS Configuration cors.allowed.origins=* # Logging logging.level.root=INFO logging.level.aws_project.workshop=DEBUG logging.file.name=/opt/workshop/application.log Step 2: Build Backend JAR cd BE/workshop_BE # Clean and build mvn clean package -DskipTests # Or use Maven Wrapper ./mvnw clean package -DskipTests # Verify JAR file ls -lh target/workshop-0.0.1-SNAPSHOT.jar Expected result: JAR file approximately 50-80MB in target/ directory\nStep 3: Upload JAR to S3 Create S3 bucket for backend artifacts (if not exists):\nACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text) BACKEND_BUCKET=\u0026#34;workshop-aws-dev-backend-${ACCOUNT_ID}-ap-southeast-1\u0026#34; # Create bucket aws s3 mb s3://${BACKEND_BUCKET} --region ap-southeast-1 # Upload JAR aws s3 cp target/workshop-0.0.1-SNAPSHOT.jar \\ s3://${BACKEND_BUCKET}/jars/ \\ --region ap-southeast-1 # Verify upload aws s3 ls s3://${BACKEND_BUCKET}/jars/ Step 4: Deploy to EC2 Get EC2 Instance ID INSTANCE_ID=$(aws ec2 describe-instances \\ --filters \u0026#34;Name=tag:aws:cloudformation:stack-name,Values=workshop-aws-dev\u0026#34; \\ \u0026#34;Name=instance-state-name,Values=running\u0026#34; \\ --region ap-southeast-1 \\ --query \u0026#39;Reservations[0].Instances[0].InstanceId\u0026#39; \\ --output text) echo \u0026#34;Instance ID: $INSTANCE_ID\u0026#34; Connect to EC2 via Session Manager aws ssm start-session --target $INSTANCE_ID --region ap-southeast-1 On EC2 Instance, run the following commands: # Switch to ec2-user sudo su - ec2-user # Navigate to application directory cd /opt/workshop # Download JAR from S3 ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text) BACKEND_BUCKET=\u0026#34;workshop-aws-dev-backend-${ACCOUNT_ID}-ap-southeast-1\u0026#34; aws s3 cp s3://${BACKEND_BUCKET}/jars/workshop-0.0.1-SNAPSHOT.jar . \\ --region ap-southeast-1 # Verify file ls -lh workshop-0.0.1-SNAPSHOT.jar Create Application Properties cat \u0026gt; application.properties \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; spring.application.name=workshop-aws # Database Configuration spring.datasource.url=jdbc:mysql://REPLACE_WITH_RDS_ENDPOINT:3306/workshop_aws?useSSL=true\u0026amp;requireSSL=false\u0026amp;allowPublicKeyRetrieval=true\u0026amp;serverTimezone=Asia/Ho_Chi_Minh spring.datasource.username=admin spring.datasource.password=YourStrongPassword123! spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver # Connection Pool spring.datasource.hikari.maximum-pool-size=10 spring.datasource.hikari.minimum-idle=5 # JPA Configuration spring.jpa.hibernate.ddl-auto=update spring.jpa.show-sql=false # Server Configuration server.port=8080 server.servlet.context-path=/dna_service # JWT Configuration jwt.signerKey=2VJ50pdhYm96e4VECp/vsZGVmkSl9xp1rSYAZKsZL7n9Ti1pZYle3k9mheQEKt6+ # Logging logging.level.root=INFO logging.level.aws_project.workshop=DEBUG logging.file.name=/opt/workshop/application.log EOF # Replace RDS endpoint RDS_ENDPOINT=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`RDSEndpoint`].OutputValue\u0026#39; \\ --output text) sed -i \u0026#34;s/REPLACE_WITH_RDS_ENDPOINT/${RDS_ENDPOINT}/g\u0026#34; application.properties Start Application # Stop old application (if any) sudo systemctl stop workshop.service 2\u0026gt;/dev/null || true pkill -f workshop-0.0.1-SNAPSHOT.jar 2\u0026gt;/dev/null || true # Start application nohup java -jar workshop-0.0.1-SNAPSHOT.jar \\ --spring.config.location=file:/opt/workshop/application.properties \\ \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp; # Save PID echo $! \u0026gt; application.pid # Wait for application to start sleep 10 # Check process ps aux | grep java Step 5: Verify Application Test Health Endpoint # On EC2 curl http://localhost:8080/dna_service/actuator/health # Expected result: # {\u0026#34;status\u0026#34;:\u0026#34;UP\u0026#34;} Test via Load Balancer # On local machine ALB_DNS=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`ALBDNSName`].OutputValue\u0026#39; \\ --output text) curl http://${ALB_DNS}/dna_service/actuator/health Test via API Gateway API_URL=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`APIGatewayURL`].OutputValue\u0026#39; \\ --output text) curl ${API_URL}/dna_service/actuator/health Step 6: Configure Systemd Service To automatically start application when EC2 restarts:\n# On EC2 sudo tee /etc/systemd/system/workshop.service \u0026gt; /dev/null \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; [Unit] Description=Workshop DNA Analysis Backend After=network.target [Service] Type=simple User=ec2-user Group=ec2-user WorkingDirectory=/opt/workshop ExecStart=/usr/bin/java -jar /opt/workshop/workshop-0.0.1-SNAPSHOT.jar --spring.config.location=file:/opt/workshop/application.properties Restart=always RestartSec=10 StandardOutput=append:/opt/workshop/application.log StandardError=append:/opt/workshop/application.log [Install] WantedBy=multi-user.target EOF # Reload systemd sudo systemctl daemon-reload # Enable service sudo systemctl enable workshop.service # Start service sudo systemctl start workshop.service # Check status sudo systemctl status workshop.service Step 7: View Logs # View application logs tail -f /opt/workshop/application.log # View systemd logs sudo journalctl -u workshop.service -f # View CloudWatch Logs (on local machine) aws logs tail /aws/workshop-aws/dev/application \\ --follow \\ --region ap-southeast-1 Troubleshooting Application Won\u0026rsquo;t Start Check logs:\ntail -100 /opt/workshop/application.log Common errors:\nDatabase connection failed\nCheck RDS endpoint in application.properties Verify Security Group allows EC2 to connect to RDS Verify database credentials Port 8080 already in use\n# Kill process using port 8080 sudo lsof -ti:8080 | xargs kill -9 Out of memory\n# Increase heap size java -Xmx512m -jar workshop-0.0.1-SNAPSHOT.jar Health Check Failed # Check application is running ps aux | grep java # Check port listening sudo netstat -tulpn | grep 8080 # Test locally curl -v http://localhost:8080/dna_service/actuator/health Load Balancer Health Check Failed # Check Target Group health aws elbv2 describe-target-health \\ --target-group-arn \u0026lt;target-group-arn\u0026gt; \\ --region ap-southeast-1 # Check Security Group # EC2 SG must allow traffic from ALB SG on port 8080 Confirm Successful Deployment Checklist:\nJAR file built successfully JAR uploaded to S3 Application running on EC2 Health endpoint returns {\u0026quot;status\u0026quot;:\u0026quot;UP\u0026quot;} Accessible via Load Balancer Accessible via API Gateway Systemd service enabled Logs being written to CloudWatch Next Steps After backend is ready:\n‚û°Ô∏è Deploy Frontend to S3 and CloudFront\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/1-worklog/1.4-week4/",
	"title": "Worklog Week 4",
	"tags": [],
	"description": "",
	"content": "Objectives for Week 4: Advanced AWS Backup deployment and notification setup. Deploy and manage virtual machines from On-Premises to AWS using AMI. Advanced S3, Storage Gateway, and File Shares management. Deploy Multi-AZ File System with SSD \u0026amp; HDD, monitor performance, manage users. Manage static S3 websites, CloudFront, versioning, replication, and resource cleanup. Tasks to accomplish this week: Day Task Start Date End Date Resources Mon - Create S3 Bucket (Module 04-Lab13-02.1) - Deploy Backup infrastructure (Module 04-Lab13-02.2) - Create Backup Plan (Module 04-Lab13-03) - Set up notifications (Module 04-Lab13-04) 29/09/2025 29/09/2025 https://000013.awsstudygroup.com/, https://000014.awsstudygroup.com/ Tue - Test Restore (Module 04-Lab13-05) - Clean up Backup resources (Module 04-Lab13-06) 30/09/2025 30/09/2025 https://000013.awsstudygroup.com/, https://000014.awsstudygroup.com/ Wed - Work with VMWare Workstation (Module 04-Lab14-01) - Export VM from On-Premises (Module 04-Lab14-02.1) - Upload VM to AWS (Module 04-Lab14-02.2) - Import VM to AWS (Module 04-Lab14-02.3) - Deploy Instance from AMI (Module 04-Lab14-02.4) 01/10/2025 01/10/2025 https://000024.awsstudygroup.com/, https://000025.awsstudygroup.com/ Thu - Manage S3 Bucket ACL (Module 04-Lab14-03.1) - Export VM from Instance (Module 04-Lab14-03.2) - Clean up VM \u0026amp; AWS resources (Module 04-Lab14-05) 02/10/2025 02/10/2025 https://000024.awsstudygroup.com/, https://000025.awsstudygroup.com/ Fri - Create Storage Gateway (Module 04-Lab24-2.1) - Create File Shares (Module 04-Lab24-2.2) - Mount File Shares on On-Premises machine (Module 04-Lab24-2.3) - Clean up resources (Module 04-Lab24-3) 03/10/2025 03/10/2025 https://000024.awsstudygroup.com/ Sat - Create SSD \u0026amp; HDD Multi-AZ File System (Module 04-Lab25-2.2 \u0026amp; 2.3) - Create file shares, test \u0026amp; monitor performance (Module 04-Lab25-3, 4, 5) - Enable deduplication, shadow copies, manage user sessions \u0026amp; quotas, scale throughput \u0026amp; storage (Module 04-Lab25-6 to 12) 04/10/2025 04/10/2025 https://000024.awsstudygroup.com/ Sun - Clean up Multi-AZ environment (Module 04-Lab25-13) - Create S3 Bucket, load data, static website, CloudFront, versioning \u0026amp; replication, test \u0026amp; cleanup (Module 04-Lab57-2.1 to 11) 05/10/2025 05/10/2025 https://000057.awsstudygroup.com/ Achievements for Week 4: Advanced AWS Backup:\nSuccessfully deployed Backup Plan, configured notifications, and tested restore. Cleaned up backup resources. Virtual Machines \u0026amp; AMI:\nExported VM from On-Premises, uploaded \u0026amp; imported to AWS. Deployed Instance from AMI and managed S3 Bucket ACL. Cleaned up VM \u0026amp; resources after testing. Storage Gateway \u0026amp; Multi-AZ File System:\nCreated Storage Gateway, File Shares, and mounted on On-Premises machine. Deployed SSD \u0026amp; HDD Multi-AZ File System, created file shares, tested \u0026amp; monitored performance. Managed users, enabled deduplication, shadow copies, quotas, scaled throughput \u0026amp; storage. S3 \u0026amp; CloudFront:\nCreated S3 Bucket, loaded data, deployed static website, configured CloudFront. Used versioning, replication multi-region, tested \u0026amp; cleaned up resources. Self-evaluation:\nConfident in deploying advanced Backup, Storage Gateway, Multi-AZ File System, VM management \u0026amp; static website. Practiced proper resource cleanup to avoid costs. Ready for next week‚Äôs lessons on security, IAM \u0026amp; cost optimization. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/3-blogstranslated/3.4-blog4/",
	"title": "Blog 4",
	"tags": [],
	"description": "",
	"content": "\r‚ö†Ô∏è Note: The information below is for reference purposes only. Please do not copy verbatim for your report, including this warning.\nGetting Started with Healthcare Data Lakes: Using Microservices Data lakes can help hospitals and healthcare facilities turn data into business insights, maintain business continuity, and protect patient privacy. A data lake is a centralized, managed, and secure repository to store all your data, both in its raw and processed forms for analysis. Data lakes allow you to break down data silos and combine different types of analytics to gain insights and make better business decisions.\nThis blog post is part of a larger series on getting started with setting up a healthcare data lake. In my final post of the series, ‚ÄúGetting Started with Healthcare Data Lakes: Diving into Amazon Cognito‚Äù, I focused on the specifics of using Amazon Cognito and Attribute Based Access Control (ABAC) to authenticate and authorize users in the healthcare data lake solution. In this blog, I detail how the solution evolved at a foundational level, including the design decisions I made and the additional features used. You can access the code samples for the solution in this Git repo for reference.\nArchitecture Guidance The main change since the last presentation of the overall architecture is the decomposition of a single service into a set of smaller services to improve maintainability and flexibility. Integrating a large volume of diverse healthcare data often requires specialized connectors for each format; by keeping them encapsulated separately as microservices, we can add, remove, and modify each connector without affecting the others. The microservices are loosely coupled via publish/subscribe messaging centered in what I call the ‚Äúpub/sub hub.‚Äù\nThis solution represents what I would consider another reasonable sprint iteration from my last post. The scope is still limited to the ingestion and basic parsing of HL7v2 messages formatted in Encoding Rules 7 (ER7) through a REST interface.\nThe solution architecture is now as follows:\nFigure 1. Overall architecture; colored boxes represent distinct services.\nWhile the term microservices has some inherent ambiguity, certain traits are common:\nSmall, autonomous, loosely coupled Reusable, communicating through well-defined interfaces Specialized to do one thing well Often implemented in an event-driven architecture When determining where to draw boundaries between microservices, consider:\nIntrinsic: technology used, performance, reliability, scalability Extrinsic: dependent functionality, rate of change, reusability Human: team ownership, managing cognitive load Technology Choices and Communication Scope Communication scope Technologies / patterns to consider Within a single microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Between microservices in a single service AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Between services Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The Pub/Sub Hub Using a hub-and-spoke architecture (or message broker) works well with a small number of tightly related microservices.\nEach microservice depends only on the hub Inter-microservice connections are limited to the contents of the published message Reduces the number of synchronous calls since pub/sub is a one-way asynchronous push Drawback: coordination and monitoring are needed to avoid microservices processing the wrong message.\nCore Microservice Provides foundational data and communication layer, including:\nAmazon S3 bucket for data Amazon DynamoDB for data catalog AWS Lambda to write messages into the data lake and catalog Amazon SNS topic as the hub Amazon S3 bucket for artifacts such as Lambda code Only allow indirect write access to the data lake through a Lambda function ‚Üí ensures consistency.\nFront Door Microservice Provides an API Gateway for external REST interaction Authentication \u0026amp; authorization based on OIDC via Amazon Cognito Self-managed deduplication mechanism using DynamoDB instead of SNS FIFO because: SNS deduplication TTL is only 5 minutes SNS FIFO requires SQS FIFO Ability to proactively notify the sender that the message is a duplicate Staging ER7 Microservice Lambda ‚Äútrigger‚Äù subscribed to the pub/sub hub, filtering messages by attribute Step Functions Express Workflow to convert ER7 ‚Üí JSON Two Lambdas: Fix ER7 formatting (newline, carriage return) Parsing logic Result or error is pushed back into the pub/sub hub New Features in the Solution 1. AWS CloudFormation Cross-Stack References Example outputs in the core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://phuong721.github.io/learning-aws/4-eventparticipated/",
	"title": "Events Participated",
	"tags": [],
	"description": "",
	"content": " In this section, you should list and describe in detail the events you participated in during your internship or work experience.\nEach event should follow the format Event 1, Event 2, Event 3‚Ä¶ and include:\nEvent name Time of the event Location (if any) Your role in the event A brief description of the content and key activities Outcomes or value gained (lessons learned, new skills, contribution to the team/project) This helps demonstrate your actual involvement as well as the soft skills and experience you gained from each event.\nDuring my internship, I participated in two events. Each event brought valuable knowledge, practical insights, and memorable experiences.\nEvent 1 Event Name: AWS Mastery #2 ‚Äì CloudFormation \u0026amp; CDK Workshop\nTime: November 17, 2025\nLocation: Online event (AWS Community Vietnam)\nRole: Participant\nEvent Description:\nThe workshop focused on Infrastructure as Code (IaC) using CloudFormation and AWS CDK. Speakers introduced IaC concepts, explained the structure of CloudFormation templates, demonstrated commands such as cdk deploy and cdk diff, and guided participants on deploying infrastructure through code. Additional topics included Docker fundamentals, containerization, and services like ECS, EKS, and App Runner.\nValue Gained:\n- A solid understanding of IaC workflows, drift detection, and CloudFormation best practices.\n- Knowledge of CDK constructs (L1‚ÄìL3) and automated infrastructure deployment.\n- Practical insights into container orchestration on AWS.\n- Improved ability to analyze and deploy DevOps pipelines using IaC.\nEvent 2 Event Name: AWS Cloud Club ‚Äì First Cloud AI Journey Workshop\nTime: November 29, 2025\nLocation: Offline event for Cloud Clubs (Ho Chi Minh City)\nRole: Participant\nEvent Description:\nThe workshop introduced the AWS Cloud Club community and provided a learning roadmap for Cloud + AI for students. Cloud Club Captains shared their AWS learning journeys, covering cloud fundamentals, AI/ML basics, GenAI concepts, study resources, certification paths, and practical career-development guidance.\nValue Gained:\n- A clearer understanding of why cloud fundamentals are essential before diving into AI/GenAI.\n- A structured AWS learning roadmap (Cloud Practitioner ‚Üí Solutions Architect Associate).\n- Effective self-study strategies and common mistakes beginners should avoid.\n- Expanded professional network through connections with Cloud Club members and peers interested in cloud and AI.\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/5-workshop/5.5-deploy-frontend/",
	"title": "Deploy Frontend",
	"tags": [],
	"description": "",
	"content": "Overview In this step, you will build the React frontend and deploy it to S3, then distribute it via CloudFront CDN to ensure high performance and low latency for global users.\nStep 1: Configure API Endpoint Get API Gateway URL from CloudFormation outputs:\nAPI_URL=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`APIGatewayURL`].OutputValue\u0026#39; \\ --output text) echo \u0026#34;API URL: $API_URL\u0026#34; Update file FE/.env:\ncd FE cat \u0026gt; .env \u0026lt;\u0026lt;EOF VITE_API_URL=${API_URL}/dna_service VITE_APP_NAME=DNA Analysis Workshop VITE_APP_VERSION=1.0.0 EOF Or update config file directly FE/src/config/api.ts:\nexport const API_BASE_URL = process.env.VITE_API_URL || \u0026#39;http://localhost:8080/dna_service\u0026#39;; export const API_TIMEOUT = 30000; export const API_ENDPOINTS = { AUTH: { LOGIN: \u0026#39;/auth/login\u0026#39;, REGISTER: \u0026#39;/auth/register\u0026#39;, LOGOUT: \u0026#39;/auth/logout\u0026#39;, REFRESH: \u0026#39;/auth/refresh\u0026#39;, }, DNA: { ANALYZE: \u0026#39;/dna/analyze\u0026#39;, HISTORY: \u0026#39;/dna/history\u0026#39;, RESULT: \u0026#39;/dna/result\u0026#39;, }, USER: { PROFILE: \u0026#39;/user/profile\u0026#39;, UPDATE: \u0026#39;/user/update\u0026#39;, }, }; Step 2: Install Dependencies cd FE # Install npm packages npm install # Verify installation npm list --depth=0 Step 3: Build Frontend # Build production bundle npm run build # Check build output ls -lh dist/ # View file structure tree dist/ -L 2 Expected result:\ndist/\r‚îú‚îÄ‚îÄ index.html\r‚îú‚îÄ‚îÄ assets/\r‚îÇ ‚îú‚îÄ‚îÄ index-[hash].js\r‚îÇ ‚îú‚îÄ‚îÄ index-[hash].css\r‚îÇ ‚îî‚îÄ‚îÄ [other assets]\r‚îî‚îÄ‚îÄ vite.svg Step 4: Upload to S3 Get S3 bucket name from outputs:\nFRONTEND_BUCKET=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`FrontendBucketName`].OutputValue\u0026#39; \\ --output text) echo \u0026#34;Frontend Bucket: $FRONTEND_BUCKET\u0026#34; Upload files to S3:\n# Sync all files aws s3 sync dist/ s3://${FRONTEND_BUCKET}/ \\ --delete \\ --region ap-southeast-1 # Set cache control for static assets aws s3 cp dist/assets/ s3://${FRONTEND_BUCKET}/assets/ \\ --recursive \\ --cache-control \u0026#34;max-age=31536000\u0026#34; \\ --region ap-southeast-1 # Set no-cache for index.html aws s3 cp dist/index.html s3://${FRONTEND_BUCKET}/ \\ --cache-control \u0026#34;no-cache,no-store,must-revalidate\u0026#34; \\ --region ap-southeast-1 # Verify upload aws s3 ls s3://${FRONTEND_BUCKET}/ --recursive Step 5: Invalidate CloudFront Cache After upload, need to invalidate CloudFront cache so users receive the new version:\n# Get CloudFront Distribution ID DIST_ID=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`CloudFrontDistributionId`].OutputValue\u0026#39; \\ --output text) echo \u0026#34;Distribution ID: $DIST_ID\u0026#34; # Create invalidation aws cloudfront create-invalidation \\ --distribution-id $DIST_ID \\ --paths \u0026#34;/*\u0026#34; \\ --region ap-southeast-1 # Monitor invalidation status aws cloudfront get-invalidation \\ --distribution-id $DIST_ID \\ --id \u0026lt;invalidation-id\u0026gt; Note: Invalidation takes 5-10 minutes to complete.\nStep 6: Access Frontend Get CloudFront domain name:\nCLOUDFRONT_URL=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`CloudFrontDomainName`].OutputValue\u0026#39; \\ --output text) echo \u0026#34;Frontend URL: https://${CLOUDFRONT_URL}\u0026#34; Open browser and access the URL above.\nStep 7: Verify Frontend Test Basic Functionality Home Page: Check page loads correctly Navigation: Test menus and routing API Connection: Open Developer Tools ‚Üí Network tab Console Errors: Check for no JavaScript errors Test Authentication # Test login endpoint curl -X POST https://${CLOUDFRONT_URL}/api/auth/login \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;username\u0026#34;:\u0026#34;test\u0026#34;,\u0026#34;password\u0026#34;:\u0026#34;test123\u0026#34;}\u0026#39; Test CORS Open Developer Tools ‚Üí Console and run:\nfetch(\u0026#39;${API_URL}/dna_service/actuator/health\u0026#39;) .then(res =\u0026gt; res.json()) .then(data =\u0026gt; console.log(\u0026#39;API Response:\u0026#39;, data)) .catch(err =\u0026gt; console.error(\u0026#39;CORS Error:\u0026#39;, err)); Step 8: Configure Custom Domain (Optional) If you have a domain name:\n1. Create SSL Certificate in ACM # Certificate must be created in us-east-1 for CloudFront aws acm request-certificate \\ --domain-name yourdomain.com \\ --subject-alternative-names www.yourdomain.com \\ --validation-method DNS \\ --region us-east-1 2. Validate Certificate Add CNAME records to DNS as instructed by ACM.\n3. Update CloudFront Distribution aws cloudfront update-distribution \\ --id $DIST_ID \\ --distribution-config file://cloudfront-config.json 4. Update Route 53 # Create A record alias to CloudFront aws route53 change-resource-record-sets \\ --hosted-zone-id \u0026lt;zone-id\u0026gt; \\ --change-batch file://route53-changes.json Deployment Script Create script to automate deployment:\ncat \u0026gt; deploy-frontend.sh \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; #!/bin/bash set -e echo \u0026#34;Building frontend...\u0026#34; cd FE npm run build echo \u0026#34;Getting S3 bucket name...\u0026#34; FRONTEND_BUCKET=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`FrontendBucketName`].OutputValue\u0026#39; \\ --output text) echo \u0026#34;Uploading to S3...\u0026#34; aws s3 sync dist/ s3://${FRONTEND_BUCKET}/ --delete --region ap-southeast-1 echo \u0026#34;Invalidating CloudFront cache...\u0026#34; DIST_ID=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`CloudFrontDistributionId`].OutputValue\u0026#39; \\ --output text) aws cloudfront create-invalidation \\ --distribution-id $DIST_ID \\ --paths \u0026#34;/*\u0026#34; \\ --region ap-southeast-1 echo \u0026#34;Deployment complete!\u0026#34; echo \u0026#34;Frontend URL: https://$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`CloudFrontDomainName`].OutputValue\u0026#39; \\ --output text)\u0026#34; EOF chmod +x deploy-frontend.sh Use script:\n./deploy-frontend.sh Troubleshooting Build Failed Error: \u0026ldquo;Module not found\u0026rdquo;\n# Delete node_modules and reinstall rm -rf node_modules package-lock.json npm install Error: \u0026ldquo;Out of memory\u0026rdquo;\n# Increase memory for Node.js export NODE_OPTIONS=\u0026#34;--max-old-space-size=4096\u0026#34; npm run build Upload Failed Error: \u0026ldquo;Access Denied\u0026rdquo;\nCheck AWS credentials Verify IAM permissions for S3 Error: \u0026ldquo;Bucket does not exist\u0026rdquo;\nCheck bucket name Verify CloudFormation stack created bucket CloudFront Issues Page won\u0026rsquo;t load:\nWait for CloudFront distribution to deploy (5-10 minutes) Check distribution status: Deployed Receiving old version:\nCreate new invalidation Clear browser cache (Ctrl+Shift+R) CORS errors:\nCheck API Gateway CORS configuration Verify backend CORS settings API Connection Failed # Test API from browser console fetch(\u0026#39;${API_URL}/dna_service/actuator/health\u0026#39;) .then(res =\u0026gt; res.text()) .then(data =\u0026gt; console.log(data)) If error:\nCheck API Gateway URL is correct Verify backend is running Check Security Groups Confirm Successful Deployment Checklist:\nFrontend built successfully Files uploaded to S3 CloudFront invalidation completed Website loads correctly via CloudFront URL No errors in browser console API calls working (check Network tab) Authentication flow working Routing between pages working Next Steps After frontend is ready:\n‚û°Ô∏è Testing and Validation\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "Deploy DNA Analysis Application on AWS Overview In this workshop, you will learn how to deploy a production-ready full-stack DNA Analysis application on AWS using Infrastructure as Code (IaC) with CloudFormation. The application consists of a React frontend, Spring Boot backend, and MySQL database, all deployed with AWS best practices for security, scalability, and cost optimization.\nAWS Services Used:\nVPC \u0026amp; Networking: VPC, Subnets, Internet Gateway, NAT Gateway, VPC Endpoints Compute: EC2 Auto Scaling Group, Application Load Balancer Storage \u0026amp; CDN: S3 for frontend hosting, CloudFront for global content delivery Database: RDS MySQL for data persistence with automated backups Security: Security Groups, IAM Roles, AWS Cognito for user authentication Monitoring: CloudWatch Logs, Alarms, and SNS notifications API Management: API Gateway for secure backend API exposure What You Will Learn Infrastructure as Code: Deploy complete AWS infrastructure using CloudFormation templates VPC Design: Create a secure VPC with public and private subnets across multiple availability zones Cost Optimization: Use VPC Endpoints to reduce NAT Gateway costs (~$20-25/month savings) Auto Scaling: Configure EC2 Auto Scaling based on CPU metrics for high availability Database Management: Deploy and configure RDS MySQL with security best practices Frontend Deployment: Host static React website on S3 with CloudFront CDN Backend Deployment: Deploy Spring Boot application on EC2 with systemd service Security Best Practices: Implement security groups, IAM roles, and Cognito authentication Monitoring \u0026amp; Logging: Set up CloudWatch for application monitoring and alerting Architecture Diagram Internet\r‚îÇ\r‚îú‚îÄ‚îÄ‚îÄ CloudFront (CDN) ‚îÄ‚îÄ\u0026gt; S3 (Frontend)\r‚îÇ\r‚îî‚îÄ‚îÄ‚îÄ API Gateway ‚îÄ‚îÄ\u0026gt; ALB ‚îÄ‚îÄ\u0026gt; EC2 (Backend) ‚îÄ‚îÄ\u0026gt; RDS MySQL\r‚îÇ\r‚îî‚îÄ‚îÄ‚îÄ VPC Endpoints (S3, CloudWatch, SSM) Prerequisites AWS Account with appropriate permissions (Administrator or equivalent) AWS CLI installed and configured (aws configure) EC2 Key Pair created in your AWS region (ap-southeast-1) Basic understanding of AWS services and command line interface Familiarity with CloudFormation concepts Estimated Cost Running this workshop infrastructure will cost approximately $8.90/month (if running 24/7):\nService Instance Type Cost/month (USD) EC2 t3.nano $3.50 RDS MySQL db.t3.micro $2.80 API Gateway - $0.50 S3 + CloudFront - $0.80 Route 53 - $0.50 Cognito - $0.10 CloudWatch - $0.30 CI/CD (CodePipeline) - $0.40 Total $8.90 For workshop (2-3 hours): ~$0.50-1.00\nüí° Cost Saving Tips:\nDelete the stack immediately after workshop completion Use AWS Free Tier for eligible services Disable NAT Gateway when not in use (saves ~$32/month) Use VPC Endpoints instead of NAT Gateway for production Workshop Duration Total Time: 2-3 hours Infrastructure Deployment: 15-20 minutes Application Configuration: 30-45 minutes Testing \u0026amp; Validation: 15-30 minutes Cleanup: 5-10 minutes Content Workshop Overview Prerequisites \u0026amp; Preparation Deploy Infrastructure with CloudFormation Configure and Deploy Backend Application Deploy Frontend to S3 and CloudFront Testing and Validation Monitoring and Troubleshooting CI/CD Pipeline Setup Clean Up Resources "
},
{
	"uri": "https://phuong721.github.io/learning-aws/1-worklog/1.5-week5/",
	"title": "Worklog Week 5",
	"tags": [],
	"description": "",
	"content": "Week 5 Objectives: Practice AWS Security Hub and security assessment. Manage VPC, EC2, and Lambda with Web-hooks and Tagging. Manage IAM Users, Policies, Roles, and advanced Switch Roles. Practice controlling IAM user permissions and access restrictions. Manage CloudTrail, Athena, and encrypted S3 data. Deploy and manage EC2, S3, and IAM Role/Key. Tasks to be completed this week: Day Task Start Date End Date Reference Mon - Enable AWS Security Hub (Module 05-Lab18-02) - Score for each criteria set (Module 05-Lab18-03) - Clean up Security Hub resources (Module 05-Lab18-04) 06/10/2025 06/10/2025 https://000018.awsstudygroup.com/ Tue - Create VPC, Security Group, EC2 (Module 05-Lab22-2.1 to 2.3) - Configure Incoming Web-hooks Slack (Module 05-Lab22-2.4) - Create Tag for Instance (Module 05-Lab22-3) - Create Role for Lambda (Module 05-Lab22-4) - Stop/Start functions \u0026amp; check result (Module 05-Lab22-5.1 to 6) - Clean up resources (Module 05-Lab22-7) 07/10/2025 07/10/2025 https://000022.awsstudygroup.com/ Wed - Manage Tags on EC2 \u0026amp; AWS Resources (Module 05-Lab27-2.1.1 to 2.2) - Create Resource Group (Module 05-Lab27-3) - Clean up resources (Module 05-Lab27-4) 08/10/2025 08/10/2025 https://000027.awsstudygroup.com/ Thu - Create IAM Users, Policies, Roles (Module 05-Lab28-2.1 to 4) - Switch Roles \u0026amp; access EC2 in multiple Regions (Module 05-Lab28-5.1 to 5.2.5) - Clean up resources (Module 05-Lab28-6) 09/10/2025 09/10/2025 https://000028.awsstudygroup.com/ Fri - Create IAM Limited User \u0026amp; Restriction Policy, test limits (Module 05-Lab30-3 to 5) - Clean up resources (Module 05-Lab30-6) 10/10/2025 10/10/2025 https://000030.awsstudygroup.com/ Sat - Create Policy, Role, Group, User, KMS, S3 Bucket, upload data, CloudTrail, Athena, test encrypted data (Module 05-Lab33-2.1 to 6) - Clean up resources (Module 05-Lab33-7) 11/10/2025 11/10/2025 https://000033.awsstudygroup.com/ Sun - Manage IAM Group, User, Admin Role, Switch Role, restrict by IP \u0026amp; Time (Module 05-Lab44) - Create EC2, S3, IAM Role, Access Key and clean up resources (Module 05-Lab48) 12/10/2025 12/10/2025 https://000044.awsstudygroup.com/ https://000048.awsstudygroup.com/ Week 5 Results: AWS Security Hub:\nEnabled Security Hub, scored based on criteria, cleaned up resources. VPC, EC2 \u0026amp; Lambda:\nCreated VPC, Security Group, EC2, Lambda functions with stop/start, configured Incoming Web-hooks Slack. Used Tags to manage resources, created Resource Group, verified results. IAM Management:\nCreated Users, Policies, Roles, advanced Switch Roles. Deployed IAM Limited User with access restrictions and IP/Time limits. Managed multiple Regions via EC2 console, verified Tag \u0026amp; Policy. CloudTrail, Athena \u0026amp; S3:\nCreated Bucket, uploaded data, enabled CloudTrail, queried data with Athena, tested encrypted data. Resource Management:\nCleaned up all deployed resources after practice to avoid costs. Self-evaluation:\nMastered Security Hub, VPC, EC2, Lambda, Tag, IAM, CloudTrail \u0026amp; Athena operations. Understood and implemented advanced access restrictions for IAM Users. Ready for next week with security and cost optimization topics. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/3-blogstranslated/3.5-blog5/",
	"title": "Blog 5",
	"tags": [],
	"description": "",
	"content": "\r‚ö†Ô∏è Note: The information below is for reference purposes only. Please do not copy verbatim for your report, including this warning.\nGetting Started with Healthcare Data Lakes: Using Microservices Data lakes can help hospitals and healthcare facilities turn data into business insights, maintain business continuity, and protect patient privacy. A data lake is a centralized, managed, and secure repository to store all your data, both in its raw and processed forms for analysis. Data lakes allow you to break down data silos and combine different types of analytics to gain insights and make better business decisions.\nThis blog post is part of a larger series on getting started with setting up a healthcare data lake. In my final post of the series, ‚ÄúGetting Started with Healthcare Data Lakes: Diving into Amazon Cognito‚Äù, I focused on the specifics of using Amazon Cognito and Attribute Based Access Control (ABAC) to authenticate and authorize users in the healthcare data lake solution. In this blog, I detail how the solution evolved at a foundational level, including the design decisions I made and the additional features used. You can access the code samples for the solution in this Git repo for reference.\nArchitecture Guidance The main change since the last presentation of the overall architecture is the decomposition of a single service into a set of smaller services to improve maintainability and flexibility. Integrating a large volume of diverse healthcare data often requires specialized connectors for each format; by keeping them encapsulated separately as microservices, we can add, remove, and modify each connector without affecting the others. The microservices are loosely coupled via publish/subscribe messaging centered in what I call the ‚Äúpub/sub hub.‚Äù\nThis solution represents what I would consider another reasonable sprint iteration from my last post. The scope is still limited to the ingestion and basic parsing of HL7v2 messages formatted in Encoding Rules 7 (ER7) through a REST interface.\nThe solution architecture is now as follows:\nFigure 1. Overall architecture; colored boxes represent distinct services.\nWhile the term microservices has some inherent ambiguity, certain traits are common:\nSmall, autonomous, loosely coupled Reusable, communicating through well-defined interfaces Specialized to do one thing well Often implemented in an event-driven architecture When determining where to draw boundaries between microservices, consider:\nIntrinsic: technology used, performance, reliability, scalability Extrinsic: dependent functionality, rate of change, reusability Human: team ownership, managing cognitive load Technology Choices and Communication Scope Communication scope Technologies / patterns to consider Within a single microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Between microservices in a single service AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Between services Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The Pub/Sub Hub Using a hub-and-spoke architecture (or message broker) works well with a small number of tightly related microservices.\nEach microservice depends only on the hub Inter-microservice connections are limited to the contents of the published message Reduces the number of synchronous calls since pub/sub is a one-way asynchronous push Drawback: coordination and monitoring are needed to avoid microservices processing the wrong message.\nCore Microservice Provides foundational data and communication layer, including:\nAmazon S3 bucket for data Amazon DynamoDB for data catalog AWS Lambda to write messages into the data lake and catalog Amazon SNS topic as the hub Amazon S3 bucket for artifacts such as Lambda code Only allow indirect write access to the data lake through a Lambda function ‚Üí ensures consistency.\nFront Door Microservice Provides an API Gateway for external REST interaction Authentication \u0026amp; authorization based on OIDC via Amazon Cognito Self-managed deduplication mechanism using DynamoDB instead of SNS FIFO because: SNS deduplication TTL is only 5 minutes SNS FIFO requires SQS FIFO Ability to proactively notify the sender that the message is a duplicate Staging ER7 Microservice Lambda ‚Äútrigger‚Äù subscribed to the pub/sub hub, filtering messages by attribute Step Functions Express Workflow to convert ER7 ‚Üí JSON Two Lambdas: Fix ER7 formatting (newline, carriage return) Parsing logic Result or error is pushed back into the pub/sub hub New Features in the Solution 1. AWS CloudFormation Cross-Stack References Example outputs in the core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://phuong721.github.io/learning-aws/5-workshop/5.6-testing/",
	"title": "Testing and Validation",
	"tags": [],
	"description": "",
	"content": "Overview In this step, you will perform test cases to verify the application works correctly end-to-end, from frontend through API Gateway, Load Balancer, to backend and database.\nStep 1: Verify Infrastructure Verify All Services Running # Check CloudFormation stack status aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].StackStatus\u0026#39; # Expected: CREATE_COMPLETE # Check EC2 instances aws ec2 describe-instances \\ --filters \u0026#34;Name=tag:aws:cloudformation:stack-name,Values=workshop-aws-dev\u0026#34; \\ \u0026#34;Name=instance-state-name,Values=running\u0026#34; \\ --region ap-southeast-1 \\ --query \u0026#39;Reservations[*].Instances[*].[InstanceId,State.Name,PrivateIpAddress]\u0026#39; \\ --output table # Check RDS status aws rds describe-db-instances \\ --db-instance-identifier workshop-aws-dev-db \\ --region ap-southeast-1 \\ --query \u0026#39;DBInstances[0].[DBInstanceIdentifier,DBInstanceStatus]\u0026#39; \\ --output table # Expected: available # Check Load Balancer aws elbv2 describe-load-balancers \\ --names workshop-aws-dev-alb \\ --region ap-southeast-1 \\ --query \u0026#39;LoadBalancers[0].[LoadBalancerName,State.Code]\u0026#39; \\ --output table # Expected: active Step 2: Test Backend API Get API URLs ALB_DNS=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`ALBDNSName`].OutputValue\u0026#39; \\ --output text) API_URL=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`APIGatewayURL`].OutputValue\u0026#39; \\ --output text) echo \u0026#34;ALB DNS: $ALB_DNS\u0026#34; echo \u0026#34;API Gateway URL: $API_URL\u0026#34; Test Health Endpoint # Test via ALB curl -v http://${ALB_DNS}/dna_service/actuator/health # Test via API Gateway curl -v ${API_URL}/dna_service/actuator/health # Expected response: # {\u0026#34;status\u0026#34;:\u0026#34;UP\u0026#34;} Test User Registration # Register new user curl -X POST ${API_URL}/dna_service/auth/register \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;username\u0026#34;: \u0026#34;testuser\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;test@example.com\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;Test123!@#\u0026#34;, \u0026#34;fullName\u0026#34;: \u0026#34;Test User\u0026#34; }\u0026#39; # Expected: 200 OK with user data Test User Login # Login curl -X POST ${API_URL}/dna_service/auth/login \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;username\u0026#34;: \u0026#34;testuser\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;Test123!@#\u0026#34; }\u0026#39; # Expected: 200 OK with JWT token # Save token for next requests TOKEN=\u0026#34;\u0026lt;jwt-token-from-response\u0026gt;\u0026#34; Test Protected Endpoints # Get user profile curl -X GET ${API_URL}/dna_service/user/profile \\ -H \u0026#34;Authorization: Bearer ${TOKEN}\u0026#34; # Expected: 200 OK with user profile data Step 3: Test Frontend Access Frontend CLOUDFRONT_URL=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`CloudFrontDomainName`].OutputValue\u0026#39; \\ --output text) echo \u0026#34;Frontend URL: https://${CLOUDFRONT_URL}\u0026#34; Open browser and access the URL above.\nManual Testing Checklist 1. Home Page\nPage loads successfully Logo and branding display correctly Navigation menu works No errors in Console 2. User Registration\nForm validation works Can register new user Success message displays Redirects to login page 3. User Login\nCan login with created credentials JWT token saved in localStorage Redirects to dashboard after login User menu displays username 4. DNA Analysis\nCan upload DNA sequence file File validation works Analysis progress displays Analysis results display correctly Can view history 5. User Profile\nDisplays user information Can update profile Avatar upload works (if available) Logout works correctly 6. Responsive Design\nMobile view works well Tablet view works well Desktop view works well Step 4: Test Database Connection Connect to RDS # Get RDS endpoint RDS_ENDPOINT=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`RDSEndpoint`].OutputValue\u0026#39; \\ --output text) # Connect via MySQL client (from EC2 or local if public access) mysql -h ${RDS_ENDPOINT} -u admin -p workshop_aws Verify Tables Created -- Show all tables SHOW TABLES; -- Expected tables: -- users, dna_sequences, analysis_results, etc. -- Check user data SELECT id, username, email, created_at FROM users; -- Check DNA analysis data SELECT id, user_id, sequence_name, status, created_at FROM dna_sequences; -- Exit EXIT; Step 5: Load Testing (Optional) Install Apache Bench # Ubuntu/Debian sudo apt-get install apache2-utils # MacOS brew install httpd # Windows # Download from Apache website Run Load Test # Test health endpoint ab -n 1000 -c 10 http://${ALB_DNS}/dna_service/actuator/health # Test login endpoint ab -n 100 -c 5 -p login-data.json -T application/json \\ ${API_URL}/dna_service/auth/login Monitor During Load Test # Watch CloudWatch metrics aws cloudwatch get-metric-statistics \\ --namespace AWS/EC2 \\ --metric-name CPUUtilization \\ --dimensions Name=AutoScalingGroupName,Value=workshop-aws-dev-asg \\ --start-time $(date -u -d \u0026#39;5 minutes ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 60 \\ --statistics Average \\ --region ap-southeast-1 Step 6: Security Testing Test HTTPS Enforcement # CloudFront should redirect HTTP to HTTPS curl -I http://${CLOUDFRONT_URL} # Expected: 301 redirect to https:// Test CORS # Test preflight request curl -X OPTIONS ${API_URL}/dna_service/auth/login \\ -H \u0026#34;Origin: https://${CLOUDFRONT_URL}\u0026#34; \\ -H \u0026#34;Access-Control-Request-Method: POST\u0026#34; \\ -H \u0026#34;Access-Control-Request-Headers: Content-Type\u0026#34; \\ -v # Expected: CORS headers in response Test SQL Injection Protection # Try SQL injection in login curl -X POST ${API_URL}/dna_service/auth/login \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;username\u0026#34;: \u0026#34;admin\u0026#39;\\\u0026#39;\u0026#39; OR \u0026#39;\\\u0026#39;\u0026#39;1\u0026#39;\\\u0026#39;\u0026#39;=\u0026#39;\\\u0026#39;\u0026#39;1\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;anything\u0026#34; }\u0026#39; # Expected: 401 Unauthorized (not SQL error) Test XSS Protection In browser console:\n// Try XSS in input fields document.querySelector(\u0026#39;input[name=\u0026#34;username\u0026#34;]\u0026#39;).value = \u0026#39;\u0026lt;script\u0026gt;alert(\u0026#34;XSS\u0026#34;)\u0026lt;/script\u0026gt;\u0026#39;; Expected: Script not executed, escaped or sanitized.\nStep 7: Performance Testing Measure Page Load Time Open Chrome DevTools ‚Üí Network tab:\nFirst Contentful Paint (FCP): \u0026lt; 1.5s Largest Contentful Paint (LCP): \u0026lt; 2.5s Time to Interactive (TTI): \u0026lt; 3.5s Total Page Size: \u0026lt; 2MB Test API Response Time # Measure API response time time curl -s ${API_URL}/dna_service/actuator/health \u0026gt; /dev/null # Expected: \u0026lt; 200ms Test CloudFront Caching # First request (MISS) curl -I https://${CLOUDFRONT_URL}/assets/index.js # Second request (HIT) curl -I https://${CLOUDFRONT_URL}/assets/index.js # Check X-Cache header: Hit from cloudfront Troubleshooting Common Issues API Returns 502 Bad Gateway # Check backend health curl http://${ALB_DNS}/dna_service/actuator/health # Check target group health aws elbv2 describe-target-health \\ --target-group-arn \u0026lt;arn\u0026gt; \\ --region ap-southeast-1 # Check EC2 logs aws ssm start-session --target \u0026lt;instance-id\u0026gt; tail -f /opt/workshop/application.log Frontend Shows CORS Error Verify API Gateway CORS configuration Check backend CORS settings in application.properties Ensure CloudFront origin is whitelisted Database Connection Timeout Check RDS Security Group allows EC2 traffic Verify RDS endpoint in application.properties Test connection from EC2: telnet ${RDS_ENDPOINT} 3306 Slow Page Load Check CloudFront cache hit ratio Optimize images and assets Enable gzip compression Review CloudWatch metrics Test Results Documentation Create test-results.md file:\n# Workshop Test Results ## Date: 2025-12-08 ## Tester: [Your Name] ### Infrastructure Tests - [x] CloudFormation stack: CREATE_COMPLETE - [x] EC2 instances: Running - [x] RDS database: Available - [x] Load Balancer: Active ### Backend API Tests - [x] Health endpoint: OK - [x] User registration: OK - [x] User login: OK - [x] Protected endpoints: OK ### Frontend Tests - [x] Page load: OK - [x] User registration: OK - [x] User login: OK - [x] DNA analysis: OK - [x] Responsive design: OK ### Performance Tests - [x] Page load time: 1.2s - [x] API response time: 150ms - [x] CloudFront cache: Working ### Security Tests - [x] HTTPS enforcement: OK - [x] CORS: OK - [x] SQL injection protection: OK - [x] XSS protection: OK ## Issues Found None ## Recommendations - Enable CloudFront compression - Add more CloudWatch alarms - Implement rate limiting Confirm Testing Complete Checklist:\nAll infrastructure services running Backend API endpoints working Frontend loads and works correctly Database connection working User authentication flow working DNA analysis features working Performance meets requirements Security tests pass Test results documented Next Steps After testing is complete:\n‚û°Ô∏è Monitoring and Troubleshooting\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/6-self-evaluation/",
	"title": "Self-Assessment",
	"tags": [],
	"description": "",
	"content": "During my internship at [First Cloud AI Journey Office] from [08/09/2025] to [30/12/2025], I had the opportunity to participate in [description of main project or tasks]. This experience helped me improve my abilities in [list of skills: data analysis, programming, planning, presenting, teamwork, etc.].\nI consistently maintained a learning mindset, stayed proactive in my work, and collaborated effectively with colleagues to achieve the team‚Äôs shared goals. Below is my detailed self-evaluation based on the given criteria:\nNo. Criteria Description Good Fair Average 1 Professional knowledge and skills Understanding the work, applying knowledge to practice, using appropriate tools ‚úÖ ‚òê ‚òê 2 Ability to learn Quickly absorbing new knowledge, being proactive in learning from real-life situations ‚òê ‚úÖ ‚òê 3 Proactiveness Taking initiative, seeking new tasks without reminders ‚úÖ ‚òê ‚òê 4 Sense of responsibility Completing tasks on time, ensuring work quality ‚úÖ ‚òê ‚òê 5 Discipline Following schedules, workflows, and organizational rules ‚òê ‚úÖ ‚òê 6 Motivation for improvement Willingness to receive feedback and improve oneself ‚úÖ ‚òê ‚òê 7 Communication Presenting ideas clearly and understandably, providing effective feedback ‚òê ‚úÖ ‚òê 8 Teamwork Collaborating well with colleagues, contributing to the team ‚úÖ ‚òê ‚òê 9 Professional conduct Maintaining respectful behavior toward colleagues and the work environment ‚úÖ ‚òê ‚òê 10 Problem-solving skills Analyzing issues and proposing feasible, creative solutions ‚òê ‚úÖ ‚òê 11 Contribution to the project/organization Level of task completion and positive contributions to overall progress ‚òê ‚úÖ ‚òê 12 Overall performance General assessment of effort, adaptability, and improvement during the internship ‚úÖ ‚òê ‚òê Areas for Improvement Strengthen time-management skills to work more efficiently Improve analytical skills and the ability to solve complex problems Be more proactive in internal communication to enhance team collaboration "
},
{
	"uri": "https://phuong721.github.io/learning-aws/1-worklog/1.6-week6/",
	"title": "Worklog Week 6",
	"tags": [],
	"description": "",
	"content": "Week 6 Objectives: Practice deploying VPC, EC2, RDS, and security configurations. Deploy applications and perform backup/restore. Manage EC2 connections via RDP and Fleet Manager. Configure SQL Server and Oracle databases. Perform schema conversion from MSSQL/Oracle to Aurora MySQL. Practice Serverless Migration, checking logs, and troubleshooting test scenarios. Tasks to be performed this week: Day Task Start Date End Date Resources Mon - Create VPC (Module 06-Lab05-2.1) - Create EC2 Security Group (Module 06-Lab05-2.2) - Create RDS Security Group (Module 06-Lab05-2.3) - Create DB Subnet Group (Module 06-Lab05-2.4) - Deploy EC2 instance (Module 06-Lab05-3) - Deploy RDS database instance (Module 06-Lab05-4) - Application Deployment (Module 06-Lab05-5) - Backup \u0026amp; Restore (Module 06-Lab05-6) - Clean up resources (Module 06-Lab05-7) 13/10/2025 13/10/2025 https://000006.awsstudygroup.com/ Tue - Connect EC2 via RDP Client (Module 06-Lab43-01) - Connect EC2 via Fleet Manager (Module 06-Lab43-02) - Configure SQL Server Source DB (Module 06-Lab43-03) 14/10/2025 14/10/2025 https://000043.awsstudygroup.com/ Wed - Connect \u0026amp; configure Oracle Source DB (Module 06-Lab43-04 \u0026amp; 05) - Drop Constraint (Module 06-Lab43-06) - MSSQL ‚Üí Aurora MySQL target config (Module 06-Lab43-07) - Create migration project (Module 06-Lab43-08) 15/10/2025 15/10/2025 https://000043.awsstudygroup.com/ Thu - Schema conversion MSSQL/Oracle ‚Üí Aurora MySQL (Module 06-Lab43-09 \u0026amp; 10) - Create Migration Task \u0026amp; Endpoints (Module 06-Lab43-11) - Inspect S3 data (Module 06-Lab43-12) 16/10/2025 16/10/2025 https://000043.awsstudygroup.com/ Fri - Create Serverless Migration (Module 06-Lab43-13) - Create Event Notification (Module 06-Lab43-14) - Check logs (Module 06-Lab43-15) - Troubleshoot Mem Pressure \u0026amp; Table Errors (Module 06-Lab43-16 \u0026amp; 17) 17/10/2025 17/10/2025 https://000043.awsstudygroup.com/ Sat - Consolidate results, review and clean up all resources 18/10/2025 18/10/2025 N/A Sun - Weekly self-assessment and preparation for next week 19/10/2025 19/10/2025 N/A Week 6 Outcomes: Network \u0026amp; Database Deployment:\nCreated and configured VPC, EC2 Security Group, RDS Security Group, DB Subnet Group. Successfully deployed EC2 \u0026amp; RDS instances, application deployment, and performed backup/restore. EC2 Connection Management:\nConnected EC2 via RDP Client and Fleet Manager, managed SQL Server \u0026amp; Oracle Source DB. Data Migration \u0026amp; Conversion:\nPerformed schema conversion from MSSQL/Oracle to Aurora MySQL. Created Migration Task, Endpoints, inspected data on S3. Serverless Migration \u0026amp; Troubleshooting:\nCreated Serverless Migration, configured Event Notification, checked logs. Successfully handled Mem Pressure \u0026amp; Table Errors test scenarios. Resource Management:\nCleaned up all deployed resources to avoid unexpected costs. Self-Assessment:\nMastered deploying VPC, EC2, RDS, backup/restore, database connection, and Serverless Migration. Understood data conversion process and log monitoring. Prepared well for the next week with advanced security and infrastructure optimization topics. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/3-blogstranslated/3.6-blog6/",
	"title": "Blog 6",
	"tags": [],
	"description": "",
	"content": "\r‚ö†Ô∏è Note: The information below is for reference purposes only. Please do not copy verbatim for your report, including this warning.\nGetting Started with Healthcare Data Lakes: Using Microservices Data lakes can help hospitals and healthcare facilities turn data into business insights, maintain business continuity, and protect patient privacy. A data lake is a centralized, managed, and secure repository to store all your data, both in its raw and processed forms for analysis. Data lakes allow you to break down data silos and combine different types of analytics to gain insights and make better business decisions.\nThis blog post is part of a larger series on getting started with setting up a healthcare data lake. In my final post of the series, ‚ÄúGetting Started with Healthcare Data Lakes: Diving into Amazon Cognito‚Äù, I focused on the specifics of using Amazon Cognito and Attribute Based Access Control (ABAC) to authenticate and authorize users in the healthcare data lake solution. In this blog, I detail how the solution evolved at a foundational level, including the design decisions I made and the additional features used. You can access the code samples for the solution in this Git repo for reference.\nArchitecture Guidance The main change since the last presentation of the overall architecture is the decomposition of a single service into a set of smaller services to improve maintainability and flexibility. Integrating a large volume of diverse healthcare data often requires specialized connectors for each format; by keeping them encapsulated separately as microservices, we can add, remove, and modify each connector without affecting the others. The microservices are loosely coupled via publish/subscribe messaging centered in what I call the ‚Äúpub/sub hub.‚Äù\nThis solution represents what I would consider another reasonable sprint iteration from my last post. The scope is still limited to the ingestion and basic parsing of HL7v2 messages formatted in Encoding Rules 7 (ER7) through a REST interface.\nThe solution architecture is now as follows:\nFigure 1. Overall architecture; colored boxes represent distinct services.\nWhile the term microservices has some inherent ambiguity, certain traits are common:\nSmall, autonomous, loosely coupled Reusable, communicating through well-defined interfaces Specialized to do one thing well Often implemented in an event-driven architecture When determining where to draw boundaries between microservices, consider:\nIntrinsic: technology used, performance, reliability, scalability Extrinsic: dependent functionality, rate of change, reusability Human: team ownership, managing cognitive load Technology Choices and Communication Scope Communication scope Technologies / patterns to consider Within a single microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Between microservices in a single service AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Between services Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The Pub/Sub Hub Using a hub-and-spoke architecture (or message broker) works well with a small number of tightly related microservices.\nEach microservice depends only on the hub Inter-microservice connections are limited to the contents of the published message Reduces the number of synchronous calls since pub/sub is a one-way asynchronous push Drawback: coordination and monitoring are needed to avoid microservices processing the wrong message.\nCore Microservice Provides foundational data and communication layer, including:\nAmazon S3 bucket for data Amazon DynamoDB for data catalog AWS Lambda to write messages into the data lake and catalog Amazon SNS topic as the hub Amazon S3 bucket for artifacts such as Lambda code Only allow indirect write access to the data lake through a Lambda function ‚Üí ensures consistency.\nFront Door Microservice Provides an API Gateway for external REST interaction Authentication \u0026amp; authorization based on OIDC via Amazon Cognito Self-managed deduplication mechanism using DynamoDB instead of SNS FIFO because: SNS deduplication TTL is only 5 minutes SNS FIFO requires SQS FIFO Ability to proactively notify the sender that the message is a duplicate Staging ER7 Microservice Lambda ‚Äútrigger‚Äù subscribed to the pub/sub hub, filtering messages by attribute Step Functions Express Workflow to convert ER7 ‚Üí JSON Two Lambdas: Fix ER7 formatting (newline, carriage return) Parsing logic Result or error is pushed back into the pub/sub hub New Features in the Solution 1. AWS CloudFormation Cross-Stack References Example outputs in the core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://phuong721.github.io/learning-aws/5-workshop/5.7-monitoring/",
	"title": "Monitoring and Troubleshooting",
	"tags": [],
	"description": "",
	"content": "Overview In this step, you will learn how to monitor the application, view logs, and troubleshoot common issues using CloudWatch, CloudWatch Logs, and other AWS tools.\nCloudWatch Metrics EC2 Metrics # CPU Utilization aws cloudwatch get-metric-statistics \\ --namespace AWS/EC2 \\ --metric-name CPUUtilization \\ --dimensions Name=AutoScalingGroupName,Value=workshop-aws-dev-asg \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 300 \\ --statistics Average,Maximum \\ --region ap-southeast-1 # Memory Utilization (if CloudWatch Agent installed) aws cloudwatch get-metric-statistics \\ --namespace CWAgent \\ --metric-name mem_used_percent \\ --dimensions Name=AutoScalingGroupName,Value=workshop-aws-dev-asg \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 300 \\ --statistics Average \\ --region ap-southeast-1 RDS Metrics # Database Connections aws cloudwatch get-metric-statistics \\ --namespace AWS/RDS \\ --metric-name DatabaseConnections \\ --dimensions Name=DBInstanceIdentifier,Value=workshop-aws-dev-db \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 300 \\ --statistics Average,Maximum \\ --region ap-southeast-1 # CPU Utilization aws cloudwatch get-metric-statistics \\ --namespace AWS/RDS \\ --metric-name CPUUtilization \\ --dimensions Name=DBInstanceIdentifier,Value=workshop-aws-dev-db \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 300 \\ --statistics Average \\ --region ap-southeast-1 Application Load Balancer Metrics # Request Count aws cloudwatch get-metric-statistics \\ --namespace AWS/ApplicationELB \\ --metric-name RequestCount \\ --dimensions Name=LoadBalancer,Value=app/workshop-aws-dev-alb/xxxxx \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 300 \\ --statistics Sum \\ --region ap-southeast-1 # Target Response Time aws cloudwatch get-metric-statistics \\ --namespace AWS/ApplicationELB \\ --metric-name TargetResponseTime \\ --dimensions Name=LoadBalancer,Value=app/workshop-aws-dev-alb/xxxxx \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 300 \\ --statistics Average \\ --region ap-southeast-1 CloudWatch Logs View Application Logs # List log streams aws logs describe-log-streams \\ --log-group-name /aws/workshop-aws/dev/application \\ --order-by LastEventTime \\ --descending \\ --max-items 5 \\ --region ap-southeast-1 # Tail logs (real-time) aws logs tail /aws/workshop-aws/dev/application \\ --follow \\ --region ap-southeast-1 # Filter logs by pattern aws logs filter-log-events \\ --log-group-name /aws/workshop-aws/dev/application \\ --filter-pattern \u0026#34;ERROR\u0026#34; \\ --start-time $(date -d \u0026#39;1 hour ago\u0026#39; +%s)000 \\ --region ap-southeast-1 # Search for specific errors aws logs filter-log-events \\ --log-group-name /aws/workshop-aws/dev/application \\ --filter-pattern \u0026#34;NullPointerException\u0026#34; \\ --start-time $(date -d \u0026#39;1 hour ago\u0026#39; +%s)000 \\ --region ap-southeast-1 View EC2 System Logs # Get instance ID INSTANCE_ID=$(aws ec2 describe-instances \\ --filters \u0026#34;Name=tag:aws:cloudformation:stack-name,Values=workshop-aws-dev\u0026#34; \\ \u0026#34;Name=instance-state-name,Values=running\u0026#34; \\ --region ap-southeast-1 \\ --query \u0026#39;Reservations[0].Instances[0].InstanceId\u0026#39; \\ --output text) # Get console output aws ec2 get-console-output \\ --instance-id $INSTANCE_ID \\ --region ap-southeast-1 \\ --output text CloudWatch Alarms View Existing Alarms # List all alarms aws cloudwatch describe-alarms \\ --alarm-name-prefix workshop-aws-dev \\ --region ap-southeast-1 # Get alarm history aws cloudwatch describe-alarm-history \\ --alarm-name workshop-aws-dev-cpu-high \\ --max-records 10 \\ --region ap-southeast-1 Create Custom Alarms # Alarm for High Error Rate aws cloudwatch put-metric-alarm \\ --alarm-name workshop-aws-dev-high-error-rate \\ --alarm-description \u0026#34;Alert when error rate exceeds 5%\u0026#34; \\ --metric-name 5XXError \\ --namespace AWS/ApplicationELB \\ --statistic Sum \\ --period 300 \\ --evaluation-periods 2 \\ --threshold 10 \\ --comparison-operator GreaterThanThreshold \\ --dimensions Name=LoadBalancer,Value=app/workshop-aws-dev-alb/xxxxx \\ --alarm-actions arn:aws:sns:ap-southeast-1:123456789012:workshop-aws-dev-alarms \\ --region ap-southeast-1 # Alarm for Database Connections aws cloudwatch put-metric-alarm \\ --alarm-name workshop-aws-dev-high-db-connections \\ --alarm-description \u0026#34;Alert when DB connections exceed 80\u0026#34; \\ --metric-name DatabaseConnections \\ --namespace AWS/RDS \\ --statistic Average \\ --period 300 \\ --evaluation-periods 2 \\ --threshold 80 \\ --comparison-operator GreaterThanThreshold \\ --dimensions Name=DBInstanceIdentifier,Value=workshop-aws-dev-db \\ --alarm-actions arn:aws:sns:ap-southeast-1:123456789012:workshop-aws-dev-alarms \\ --region ap-southeast-1 CloudWatch Dashboards Create Dashboard # Create dashboard JSON cat \u0026gt; dashboard.json \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; { \u0026#34;widgets\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;metric\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;metrics\u0026#34;: [ [\u0026#34;AWS/EC2\u0026#34;, \u0026#34;CPUUtilization\u0026#34;, {\u0026#34;stat\u0026#34;: \u0026#34;Average\u0026#34;}] ], \u0026#34;period\u0026#34;: 300, \u0026#34;stat\u0026#34;: \u0026#34;Average\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;ap-southeast-1\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;EC2 CPU Utilization\u0026#34; } }, { \u0026#34;type\u0026#34;: \u0026#34;metric\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;metrics\u0026#34;: [ [\u0026#34;AWS/RDS\u0026#34;, \u0026#34;DatabaseConnections\u0026#34;, {\u0026#34;stat\u0026#34;: \u0026#34;Average\u0026#34;}] ], \u0026#34;period\u0026#34;: 300, \u0026#34;stat\u0026#34;: \u0026#34;Average\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;ap-southeast-1\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;RDS Connections\u0026#34; } }, { \u0026#34;type\u0026#34;: \u0026#34;metric\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;metrics\u0026#34;: [ [\u0026#34;AWS/ApplicationELB\u0026#34;, \u0026#34;RequestCount\u0026#34;, {\u0026#34;stat\u0026#34;: \u0026#34;Sum\u0026#34;}] ], \u0026#34;period\u0026#34;: 300, \u0026#34;stat\u0026#34;: \u0026#34;Sum\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;ap-southeast-1\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;ALB Request Count\u0026#34; } } ] } EOF # Create dashboard aws cloudwatch put-dashboard \\ --dashboard-name workshop-aws-dev-dashboard \\ --dashboard-body file://dashboard.json \\ --region ap-southeast-1 View Dashboard Open CloudWatch Console ‚Üí Dashboards ‚Üí workshop-aws-dev-dashboard\nTroubleshooting Common Issues Issue 1: High CPU Usage Symptoms:\nEC2 CPU \u0026gt; 80% Slow response times CloudWatch alarm triggered Diagnosis:\n# Check CPU metrics aws cloudwatch get-metric-statistics \\ --namespace AWS/EC2 \\ --metric-name CPUUtilization \\ --dimensions Name=AutoScalingGroupName,Value=workshop-aws-dev-asg \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 60 \\ --statistics Average,Maximum \\ --region ap-southeast-1 # SSH to EC2 and check processes aws ssm start-session --target $INSTANCE_ID top -bn1 | head -20 Solutions:\nScale up: Increase instance type Scale out: Increase number of instances Optimize code: Profile and optimize application Add caching: Implement Redis/ElastiCache Issue 2: Database Connection Pool Exhausted Symptoms:\n\u0026ldquo;Too many connections\u0026rdquo; errors Slow database queries Application timeouts Diagnosis:\n# Check DB connections aws cloudwatch get-metric-statistics \\ --namespace AWS/RDS \\ --metric-name DatabaseConnections \\ --dimensions Name=DBInstanceIdentifier,Value=workshop-aws-dev-db \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 60 \\ --statistics Average,Maximum \\ --region ap-southeast-1 # Connect to DB and check mysql -h $RDS_ENDPOINT -u admin -p SHOW PROCESSLIST; SHOW STATUS LIKE \u0026#39;Threads_connected\u0026#39;; Solutions:\nIncrease connection pool size in application.properties Fix connection leaks in code Scale up RDS instance Implement connection pooling best practices Issue 3: 502 Bad Gateway Symptoms:\nUsers receive 502 errors ALB cannot reach backend Health checks failing Diagnosis:\n# Check target health aws elbv2 describe-target-health \\ --target-group-arn \u0026lt;arn\u0026gt; \\ --region ap-southeast-1 # Check backend logs aws logs tail /aws/workshop-aws/dev/application --follow # Check Security Groups aws ec2 describe-security-groups \\ --group-ids \u0026lt;ec2-sg-id\u0026gt; \\ --region ap-southeast-1 Solutions:\nVerify backend is running: systemctl status workshop Check Security Group allows ALB traffic Verify health check path is correct Check application logs for errors Best Practices 1. Set Up Alerts CPU \u0026gt; 80% for 5 minutes Memory \u0026gt; 85% for 5 minutes Disk \u0026gt; 90% 5XX errors \u0026gt; 10 in 5 minutes Database connections \u0026gt; 80% of max 2. Regular Health Checks # Daily health check script #!/bin/bash echo \u0026#34;=== Daily Health Check ===\u0026#34; echo \u0026#34;Date: $(date)\u0026#34; # Check stack status echo \u0026#34;CloudFormation Stack:\u0026#34; aws cloudformation describe-stacks --stack-name workshop-aws-dev --query \u0026#39;Stacks[0].StackStatus\u0026#39; # Check EC2 echo \u0026#34;EC2 Instances:\u0026#34; aws ec2 describe-instances --filters \u0026#34;Name=tag:aws:cloudformation:stack-name,Values=workshop-aws-dev\u0026#34; --query \u0026#39;Reservations[*].Instances[*].[InstanceId,State.Name]\u0026#39; # Check RDS echo \u0026#34;RDS Database:\u0026#34; aws rds describe-db-instances --db-instance-identifier workshop-aws-dev-db --query \u0026#39;DBInstances[0].DBInstanceStatus\u0026#39; # Check API echo \u0026#34;API Health:\u0026#34; curl -s $API_URL/dna_service/actuator/health | jq . Monitoring Checklist CloudWatch metrics being collected CloudWatch Logs configured Alarms set up SNS notifications working Dashboard created Log retention configured Custom metrics published Health checks working Performance baseline established Next Steps After setting up monitoring:\n‚û°Ô∏è Clean Up Resources\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/7-feedback/",
	"title": "Share, contribute ideas",
	"tags": [],
	"description": "",
	"content": "General Feedback 1. Working Environment\nDuring my training at AWS, I found the working environment to be highly professional and dynamic. Everyone communicates clearly and directly, making discussions comfortable and efficient. What I appreciated the most is the ‚Äúlearning by doing‚Äù culture ‚Äì encouraging hands-on practice rather than relying solely on theory. However, I think AWS could consider organizing more internal sharing sessions so interns can better understand the responsibilities of different teams.\n2. Support from Mentor / Admin Team\nMy mentor was extremely supportive, providing clear guidance before each task. Whenever I encountered difficulties, the mentor didn‚Äôt solve the problem for me but instead helped me think in the right direction ‚Äì which significantly improved my problem-solving skills. The admin team also responded quickly, assisting with accounts, permissions, and documentation whenever needed.\n3. Relevance Between Tasks and My Major\nThe training topics were closely related to my major in Information Security, especially IAM, cloud security architecture, and AWS resource management. I also had the opportunity to work with technologies and tools that are not covered in my university curriculum, which helped broaden my knowledge considerably.\n4. Learning Opportunities \u0026amp; Skill Development\nThroughout the internship, I gained various new skills such as log analysis, applying AWS best practices, handling simulated incidents, and managing cloud resources. Besides technical skills, I also improved my communication, planning, and time-management abilities thanks to working with sprints and clear deadlines.\n5. Culture \u0026amp; Team Spirit\nThe team spirit was excellent. Everyone was willing to help each other and openly share their experiences. The working environment was professional yet friendly, making it easy to interact and collaborate. This helped me integrate quickly and become more confident during technical discussions.\n6. Policies / Benefits for Interns\nThe policies for interns were clear and flexible. The working schedule was well-adjusted to accommodate my academic commitments. Moreover, being allowed to participate in internal workshops and technical training sessions was a big advantage.\nAdditional Questions What were you most satisfied with during the internship?\n‚Üí Having the chance to work directly with real AWS services and receiving timely, constructive support from my mentor.\nWould you recommend this internship to your friends? Why?\n‚Üí Yes. Because the training environment is professional, well-structured, and provides hands-on experience that few other places offer.\nSuggestions \u0026amp; Expectations It would be great to have more group-based mini projects for additional practical experience. If possible, I would like to continue in a more advanced program such as the AWS Internship or Cloud Engineer Trainee track. I hope to see more deep-dive content related to cloud security and AI applications in system monitoring. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/1-worklog/1.7-week7/",
	"title": "Worklog Week 7",
	"tags": [],
	"description": "",
	"content": "Week 7 Objectives: Deploy and manage data on S3, DynamoDB, and Redshift. Create data pipelines using Kinesis, Glue, DataBrew, and EMR. Analyze data with Athena and Kinesis Data Analytics, and visualize with QuickSight. Build serverless applications and interactive dashboards. Familiarize with CloudShell, AWS SDK, and Cloud9 for programming and data handling tasks. Tasks to be carried out this week: Day Tasks Start Date End Date Resources Mon - Create S3 Bucket, Delivery Stream, sample data, Glue Crawler, data validation, session setup, analysis with Athena, visualization with QuickSight, resource cleanup (Module 07-Lab35-3.1 to 7) 20/10/2025 20/10/2025 https://000035.awsstudygroup.com/ Tue - Explore DynamoDB, console exploration, data backup, cleanup, apply Advanced Design Patterns, deploy global serverless app, event-driven architecture (Module 07-Lab39-1 to 8) 21/10/2025 21/10/2025 https://000039.awsstudygroup.com/ Wed - Prepare and build database, manage table data, cost, tagging, usage, queries, resource cleanup (Module 07-Lab40-2.1 to 4) 22/10/2025 22/10/2025 https://000040.awsstudygroup.com/ Thu - Familiarize with CloudShell, console, SDK; create Cloud9 instance, download \u0026amp; upload dataset to S3; setup DataBrew, data profiling, clean \u0026amp; transform data (Module 07-Lab60 \u0026amp; 07-Lab70) 23/10/2025 23/10/2025 https://000060.awsstudygroup.com/ Fri - Prepare pipeline, ingest \u0026amp; store data, catalog data, transform with Glue (interactive \u0026amp; GUI), DataBrew, EMR; analyze with Athena \u0026amp; Kinesis Data Analytics; visualize with QuickSight; serve with Lambda; warehouse on Redshift (Module 07-Lab72-2 to 13) 24/10/2025 24/10/2025 https://000070.awsstudygroup.com/ Sat - Build dashboard, improve dashboard, create interactive dashboard (Module 07-Lab73-3 to 5) 25/10/2025 25/10/2025 https://000072.awsstudygroup.com/ Sun - Summarize, review results, cleanup resources, self-assess week, and prepare for next week 26/10/2025 26/10/2025 https://000073.awsstudygroup.com/ Achievements in Week 7: Data management \u0026amp; processing:\nDeployed data on S3, DynamoDB, and Redshift. Built data pipelines using Kinesis, Glue, DataBrew, and EMR. Analysis \u0026amp; visualization:\nAnalyzed data using Athena and Kinesis Data Analytics. Visualized data and built interactive dashboards using QuickSight. Serverless applications:\nDeployed serverless applications on DynamoDB and Lambda. Built event-driven architecture for global serverless apps. Programming \u0026amp; data handling tools:\nUtilized CloudShell, AWS SDK, and Cloud9 for data handling and programming tasks. Resource management:\nCleaned up all deployed resources to avoid unexpected costs. Self-assessment:\nGained proficiency in data management, pipeline creation, analysis \u0026amp; visualization, and serverless applications. Prepared for the next week with advanced content on security, tagging, and cost management. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/5-workshop/5.8-cicd-pipeline/",
	"title": "CI/CD Pipeline Setup",
	"tags": [],
	"description": "",
	"content": "Overview In this section, you will set up a complete CI/CD pipeline using AWS CodePipeline, CodeBuild, and GitLab CI/CD to automate the build and deployment process for both backend and frontend applications.\nArchitecture GitLab ‚Üí S3 (Artifacts) ‚Üí CodePipeline ‚Üí CodeBuild (Backend) ‚Üí EC2\r‚Üì\rCodeBuild (Frontend) ‚Üí S3/CloudFront CI/CD Components 1. GitLab CI/CD Automatically builds and packages source code Uploads artifacts to S3 Triggers AWS CodePipeline 2. AWS CodePipeline Orchestrates the entire deployment workflow Monitors S3 for new artifacts Triggers CodeBuild projects 3. AWS CodeBuild Backend Build: Compiles Spring Boot application to JAR Frontend Build: Builds React application with Vite Deploys to respective AWS services Step 1: Configure GitLab CI/CD 1.1. Set GitLab CI/CD Variables In your GitLab project, go to Settings ‚Üí CI/CD ‚Üí Variables and add:\nVariable Value Protected Masked AWS_ACCESS_KEY_ID Your AWS Access Key ‚úÖ ‚úÖ AWS_SECRET_ACCESS_KEY Your AWS Secret Key ‚úÖ ‚úÖ 1.2. Review GitLab CI Configuration The .gitlab-ci.yml file in your project root:\nstages: - deploy deploy-to-aws: stage: deploy image: amazon/aws-cli:latest before_script: - | aws configure set aws_access_key_id $AWS_ACCESS_KEY_ID aws configure set aws_secret_access_key $AWS_SECRET_ACCESS_KEY aws configure set region ap-southeast-1 script: - echo \u0026#34;üì¶ Creating source.zip...\u0026#34; - | apk add zip zip -r source.zip . \\ -x \u0026#34;*.git*\u0026#34; \\ -x \u0026#34;node_modules/*\u0026#34; \\ -x \u0026#34;.idea/*\u0026#34; \\ -x \u0026#34;target/*\u0026#34; \\ -x \u0026#34;*.zip\u0026#34; - echo \u0026#34;üì§ Uploading to S3...\u0026#34; - | aws s3 cp source.zip \\ s3://workshop-aws-dev-artifacts-502310717700-ap-southeast-1/source.zip - echo \u0026#34;‚úÖ Upload completed! CodePipeline will trigger automatically.\u0026#34; only: - main when: on_success What it does:\nPackages entire project into source.zip Uploads to S3 artifacts bucket Triggers CodePipeline automatically Step 2: Deploy CodePipeline with CloudFormation 2.1. Review Pipeline Template The cicd-pipeline.yaml CloudFormation template creates:\nCodePipeline with S3 source CodeBuild project for backend CodeBuild project for frontend IAM roles and permissions 2.2. Deploy Pipeline Stack aws cloudformation create-stack \\ --stack-name workshop-aws-dev-cicd \\ --template-body file://aws/cicd-pipeline.yaml \\ --parameters \\ ParameterKey=ProjectName,ParameterValue=workshop-aws \\ ParameterKey=Environment,ParameterValue=dev \\ ParameterKey=SourceProvider,ParameterValue=S3 \\ ParameterKey=ArtifactBucketName,ParameterValue=workshop-aws-dev-artifacts-502310717700-ap-southeast-1 \\ --capabilities CAPABILITY_NAMED_IAM \\ --region ap-southeast-1 2.3. Wait for Stack Creation aws cloudformation wait stack-create-complete \\ --stack-name workshop-aws-dev-cicd \\ --region ap-southeast-1 Expected time: 3-5 minutes\nStep 3: Configure CodeBuild Projects 3.1. Backend BuildSpec CodeBuild uses buildspec-backend.yml:\nversion: 0.2 phases: pre_build: commands: - echo \u0026#34;Installing Maven...\u0026#34; - yum install -y maven build: commands: - echo \u0026#34;Building Backend JAR...\u0026#34; - cd BE/workshop_BE - mvn clean package -DskipTests post_build: commands: - echo \u0026#34;Uploading JAR to S3...\u0026#34; - aws s3 cp target/workshop-0.0.1-SNAPSHOT.jar \\ s3://workshop-aws-dev-backend-502310717700-ap-southeast-1/jars/ - echo \u0026#34;Deploying to EC2...\u0026#34; - aws ssm send-command \\ --instance-ids i-09fdbf7739ee37b32 \\ --document-name \u0026#34;AWS-RunShellScript\u0026#34; \\ --parameters commands=[ \u0026#34;cd /opt/workshop\u0026#34;, \u0026#34;aws s3 cp s3://workshop-aws-dev-backend-502310717700-ap-southeast-1/jars/workshop-0.0.1-SNAPSHOT.jar .\u0026#34;, \u0026#34;sudo systemctl restart workshop.service\u0026#34; ] artifacts: files: - \u0026#39;**/*\u0026#39; 3.2. Frontend BuildSpec CodeBuild uses buildspec-frontend.yml:\nversion: 0.2 phases: pre_build: commands: - echo \u0026#34;Installing Node.js...\u0026#34; - curl -sL https://rpm.nodesource.com/setup_18.x | bash - - yum install -y nodejs build: commands: - echo \u0026#34;Building Frontend...\u0026#34; - cd FE - npm install - npm run build post_build: commands: - echo \u0026#34;Deploying to S3...\u0026#34; - aws s3 sync dist/ \\ s3://workshop-aws-dev-frontend-502310717700-ap-southeast-1/ \\ --delete - echo \u0026#34;Invalidating CloudFront...\u0026#34; - aws cloudfront create-invalidation \\ --distribution-id E3K48K7CPOOLHZ \\ --paths \u0026#34;/*\u0026#34; artifacts: files: - \u0026#39;FE/dist/**/*\u0026#39; Step 4: Test CI/CD Pipeline 4.1. Trigger Pipeline from GitLab Make a code change and push to main branch:\ngit add . git commit -m \u0026#34;Test CI/CD pipeline\u0026#34; git push origin main 4.2. Monitor GitLab Pipeline Go to GitLab ‚Üí CI/CD ‚Üí Pipelines Watch the deploy-to-aws job Verify successful upload to S3 4.3. Monitor AWS CodePipeline Go to AWS Console ‚Üí CodePipeline Select workshop-aws-dev-pipeline Watch the pipeline stages: Source: Detects new source.zip in S3 Build-Backend: Builds JAR and deploys to EC2 Build-Frontend: Builds React app and deploys to S3/CloudFront 4.4. Check Build Logs For detailed logs:\nClick on Details in any stage View Build logs in CodeBuild Check for errors or warnings Step 5: Verify Deployment 5.1. Test Backend API curl https://98385v3jef.execute-api.ap-southeast-1.amazonaws.com/dev/dna_service/actuator/health Expected response:\n{\u0026#34;status\u0026#34;:\u0026#34;UP\u0026#34;} 5.2. Test Frontend Open browser and navigate to:\nhttps://d3gmmg22uirq0t.cloudfront.net Verify the application loads with latest changes.\nPipeline Flow Step-by-step flow:\nGitLab Commit ‚Üí Developer pushes code to main branch GitLab CI ‚Üí Builds and creates source.zip S3 Bucket ‚Üí Stores source.zip artifact CodePipeline ‚Üí Detects new artifact and triggers builds CodeBuild Backend ‚Üí Builds JAR and deploys to EC2 CodeBuild Frontend ‚Üí Builds React app and deploys to S3/CloudFront CloudWatch Logs ‚Üí Monitors all build and deployment activities Troubleshooting Pipeline Not Triggering Issue: CodePipeline doesn\u0026rsquo;t start after GitLab push\nSolutions:\nCheck S3 bucket for source.zip Verify CodePipeline source configuration Check IAM permissions for CodePipeline Backend Build Fails Issue: CodeBuild backend fails with Maven errors\nSolutions:\nCheck buildspec-backend.yml syntax Verify Maven dependencies in pom.xml Check CodeBuild logs for specific errors Ensure EC2 instance has SSM Agent running Frontend Build Fails Issue: CodeBuild frontend fails with npm errors\nSolutions:\nCheck buildspec-frontend.yml syntax Verify package.json dependencies Check Node.js version compatibility Ensure S3 bucket permissions are correct Deployment Fails Issue: Build succeeds but deployment fails\nSolutions:\nCheck EC2 Security Groups allow SSM Verify S3 bucket names are correct Check CloudFront distribution ID Review IAM role permissions Best Practices 1. Environment Variables Store sensitive data in GitLab CI/CD variables Use AWS Systems Manager Parameter Store for application configs Never commit credentials to Git 2. Build Optimization Cache dependencies (Maven .m2, npm node_modules) Use smaller Docker images for faster builds Parallelize independent build stages 3. Deployment Strategy Use blue-green deployment for zero downtime Implement health checks before routing traffic Keep rollback capability ready 4. Monitoring Enable CloudWatch Logs for all CodeBuild projects Set up SNS notifications for pipeline failures Monitor build times and optimize bottlenecks Cost Optimization CodeBuild Pricing Build minutes: $0.005 per minute (general1.small) Typical build: 5-10 minutes Cost per build: ~$0.025-0.05 CodePipeline Pricing Active pipeline: $1.00 per month Free tier: 1 active pipeline per month Estimated Monthly Cost 10 deployments/day: ~$15-20/month Includes: CodePipeline + CodeBuild + S3 storage Summary You have successfully set up a complete CI/CD pipeline that:\n‚úÖ Automatically builds and packages code from GitLab\n‚úÖ Uploads artifacts to S3\n‚úÖ Triggers AWS CodePipeline on changes\n‚úÖ Builds backend JAR with Maven\n‚úÖ Builds frontend with Vite\n‚úÖ Deploys backend to EC2\n‚úÖ Deploys frontend to S3/CloudFront\n‚úÖ Provides monitoring and logging\nNext: Clean Up Resources\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/1-worklog/1.8-week8/",
	"title": "Worklog Week 8",
	"tags": [],
	"description": "",
	"content": "Week 8 Objectives: Understand the architectural requirements for the project. Become proficient with draw.io to design system diagrams. Understand the relationships between AWS services in the architecture: Networking, Compute, Database, CI/CD, Monitoring. Complete the Network Architecture Diagram and submit it for mentor review. Tasks for this week: Day Task Start Date Completion Date Reference 2 - Gather architectural requirements from mentors - Define the scope of the diagram (VPC, subnets, routing, frontend, backend, database, CI/CD‚Ä¶) 2025-10-27 2025-10-27 FCJ Internal 3 - Start designing the network architecture diagram in draw.io - Create VPC, public/private subnets, Internet Gateway - Add Route 53, CloudFront, S3 FE bucket 2025-10-28 2025-10-28 AWS Docs 4 - Add API Gateway, EC2, Security Groups - Design RDS in private subnet - Draw the data flow: FE ‚Üí CloudFront ‚Üí API ‚Üí EC2 ‚Üí RDS 2025-10-29 2025-10-29 AWS Architecture Icons 5 - Integrate CI/CD pipeline (CodePipeline, CodeBuild, CloudFormation) - Add Cognito/Auth and complete the Security Layer 2025-10-30 2025-10-30 aws.amazon.com 6 - Optimize diagram layout, adjust colors and borders - Add numbering for request flows - Export the diagram and send it to mentors for review 2025-10-31 2025-10-31 FCJ Internal 7 - Receive mentor feedback: update subnets, API flow, security layers - Revise the diagram according to suggestions 2025-11-01 2025-11-01 Direct discussion Sun - Summarize lessons learned during the architecture design process - Finalize weekly Worklog 2025-11-02 2025-11-02 Week 8 Achievements: Completed a full AWS Network Architecture Diagram including:\nRoute 53, CloudFront, S3 frontend bucket. API Gateway ‚Üí EC2 backend. NAT Gateway + Internet Gateway. RDS in private subnet. CI/CD: CodePipeline, CodeBuild, CloudFormation. Monitoring \u0026amp; Security: CloudWatch, CloudTrail, IAM, Secrets Manager, SNS. Clearly understood how the components interact:\nUser request flow for FE/BE. Separation of public and private subnets. NAT mechanism for EC2 to access the internet securely. API Gateway ‚Üí EC2 ‚Üí RDS data flow. Learned how to standardize technical diagrams following AWS best practices:\nUse of correct AWS icons and proper service grouping. Layered architecture and numbered processing flows. Finalized the architecture diagram for reporting and mentor evaluation.\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/5-workshop/5.9-cleanup/",
	"title": "Clean Up Resources",
	"tags": [],
	"description": "",
	"content": "Overview After completing the workshop, you need to delete all resources to avoid unexpected charges. CloudFormation will automatically delete most resources, but some require manual deletion.\nStep 1: Delete S3 Bucket Contents CloudFormation cannot delete S3 buckets containing objects. Delete contents first:\n# Get bucket names from outputs FRONTEND_BUCKET=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`FrontendBucketName`].OutputValue\u0026#39; \\ --output text) # Delete all objects in frontend bucket aws s3 rm s3://$FRONTEND_BUCKET --recursive --region ap-southeast-1 # If backend bucket exists BACKEND_BUCKET=\u0026#34;workshop-aws-dev-backend-$(aws sts get-caller-identity --query Account --output text)-ap-southeast-1\u0026#34; aws s3 rm s3://$BACKEND_BUCKET --recursive --region ap-southeast-1 2\u0026gt;/dev/null || true Step 2: Delete CloudFormation Stack Method 1: Using Deploy Script Windows:\ncd aws deploy.bat delete Linux/Mac:\ncd aws ./deploy.sh delete Method 2: Using AWS CLI aws cloudformation delete-stack \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 Step 3: Monitor Deletion Progress # Check status aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].StackStatus\u0026#39; # Wait for stack deletion (may take 10-15 minutes) aws cloudformation wait stack-delete-complete \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 Via AWS Console:\nOpen CloudFormation Console Select stack workshop-aws-dev Events tab: View resources being deleted Stack will disappear from list when deletion completes Step 4: Verify Resources Deleted Check VPC # Should not see workshop VPC aws ec2 describe-vpcs \\ --filters \u0026#34;Name=tag:aws:cloudformation:stack-name,Values=workshop-aws-dev\u0026#34; \\ --region ap-southeast-1 Check EC2 Instances # Should not see workshop instances aws ec2 describe-instances \\ --filters \u0026#34;Name=tag:aws:cloudformation:stack-name,Values=workshop-aws-dev\u0026#34; \\ --region ap-southeast-1 \\ --query \u0026#39;Reservations[*].Instances[*].[InstanceId,State.Name]\u0026#39; Check RDS # Should not see RDS instance (may have snapshot) aws rds describe-db-instances \\ --region ap-southeast-1 \\ --query \u0026#39;DBInstances[?DBInstanceIdentifier==`workshop-aws-dev-db`]\u0026#39; Check S3 Buckets # Buckets should be deleted aws s3 ls | grep workshop-aws-dev Step 5: Delete RDS Snapshots (Optional) CloudFormation creates snapshot before deleting RDS. Delete if not needed:\n# List snapshots aws rds describe-db-snapshots \\ --region ap-southeast-1 \\ --query \u0026#39;DBSnapshots[?contains(DBSnapshotIdentifier,`workshop-aws-dev`)].DBSnapshotIdentifier\u0026#39; # Delete snapshot aws rds delete-db-snapshot \\ --db-snapshot-identifier \u0026lt;snapshot-id\u0026gt; \\ --region ap-southeast-1 Step 6: Delete CloudWatch Logs (Optional) Log groups are not automatically deleted:\n# List log groups aws logs describe-log-groups \\ --log-group-name-prefix \u0026#34;/aws/workshop-aws\u0026#34; \\ --region ap-southeast-1 # Delete log groups aws logs delete-log-group \\ --log-group-name \u0026#34;/aws/workshop-aws/dev/application\u0026#34; \\ --region ap-southeast-1 Step 7: Delete EC2 Key Pair (Optional) If key pair is no longer needed:\naws ec2 delete-key-pair \\ --key-name workshop-aws-key \\ --region ap-southeast-1 # Delete local .pem file rm workshop-aws-key.pem Troubleshooting Stack Deletion Failed If stack deletion fails:\nView error: aws cloudformation describe-stack-events \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;StackEvents[?ResourceStatus==`DELETE_FAILED`].[LogicalResourceId,ResourceStatusReason]\u0026#39; \\ --output table Common errors: Error: \u0026ldquo;S3 bucket is not empty\u0026rdquo;\nDelete all objects in bucket Retry stack deletion Error: \u0026ldquo;Network interface is in use\u0026rdquo;\nWait a few minutes for ENIs to be released Retry stack deletion Error: \u0026ldquo;Resource being used by another resource\u0026rdquo;\nIdentify resource dependencies Delete dependent resources first Force delete: # Retain problematic resources and delete stack aws cloudformation delete-stack \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --retain-resources \u0026lt;ResourceLogicalId\u0026gt; # Then delete resources manually Cleanup Checklist Ensure all resources are deleted:\nCloudFormation stack deleted S3 buckets deleted EC2 instances terminated RDS database deleted Load Balancer deleted VPC and subnets deleted CloudFront distribution disabled and deleted NAT Gateway deleted Elastic IPs released RDS snapshots deleted (optional) CloudWatch log groups deleted (optional) EC2 Key Pair deleted (optional) Confirm No Ongoing Charges After 24-48 hours, check AWS Cost Explorer to ensure no charges from workshop.\nConclusion You have successfully completed the workshop and cleaned up all resources!\nWhat you learned: ‚úÖ Deploy full-stack application on AWS ‚úÖ Infrastructure as Code with CloudFormation ‚úÖ AWS networking and security best practices ‚úÖ Cost optimization strategies ‚úÖ Monitoring and troubleshooting\nNext resources:\nAWS Well-Architected Framework AWS Solutions Library AWS Workshops Thank you for participating in this workshop! üéâ\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/1-worklog/1.9-week9/",
	"title": "Worklog Week 9",
	"tags": [],
	"description": "",
	"content": "Week 9 Objectives: Collect requirements and start developing content for the Proposal and Proposal Template of the BDSS project. Write introductory sections: Executive Summary, Problem Statement, Solution Overview. Identify the AWS architecture to include in both documents. Complete the first draft of the Proposal and the skeleton structure of the Proposal Template. Tasks to be carried out this week: Day Task Start Date End Date Reference Materials Mon - Receive mentor‚Äôs requirements for content to include in the Proposal \u0026amp; Proposal Template - Define the common outline for both documents 03/11/2025 03/11/2025 proposal.docx Proposal Template.docx Tue - Write Executive Summary for the Proposal - Prepare the corresponding introductory section in the Proposal Template 04/11/2025 04/11/2025 proposal.docx Wed - Write Problem Statement: describe issues at healthcare facilities \u0026amp; the need to connect blood donors - Adjust content for inclusion in the Proposal Template 05/11/2025 05/11/2025 Team documents Thu - Write Proposed Solution for the Proposal - Simultaneously complete the Solution Overview section in the Proposal Template 06/11/2025 06/11/2025 proposal.docx Fri - Describe Solution Architecture based on 4 layers - Review the presentation of the architecture in the Proposal Template to match the standard layout 07/11/2025 07/11/2025 AWS Docs Sat - Write Technical Implementation and deployment roadmap - Fill in corresponding sections in the Proposal Template (Activities, Deliverables, Scope‚Ä¶) 08/11/2025 08/11/2025 Proposal Template.docx Sun - Finalize the first draft for both Proposal and Proposal Template - Send to mentor for review and collect feedback - Update Week 9 Worklog 09/11/2025 09/11/2025 Slack/Meeting Week 9 Achievements: Completed the first draft of the Proposal and the skeleton of the Proposal Template, including sections:\nExecutive Summary Problem Statement Proposed Cloud Solution Solution Architecture (4 layers) Technical Implementation (draft) Built a complete structure for the Proposal Template, ready to fill in detailed content next week.\nGained a clearer understanding of mentor requirements and content presentation in two different formats:\nProposal: detailed description Proposal Template: standard AWS model Defined the AWS architecture used in both documents:\nRoute 53, CloudFront API Gateway ‚Äì EC2 RDS MySQL Cognito Authorization CI/CD Pipeline Monitoring \u0026amp; Security Layer Established a solid content foundation for next week to complete: Technical Plan, Budget Estimate, Risk Assessment, and finalize the Proposal Template.\n"
},
{
	"uri": "https://phuong721.github.io/learning-aws/1-worklog/1.10-week10/",
	"title": "Worklog Week 10",
	"tags": [],
	"description": "",
	"content": "Week 10 Objectives: Build the workshop based on the content from the Proposal and Proposal Template. Identify key sections to be included in the workshop: Overview, Architecture, CI/CD, Cost, Security, etc. Standardize the workshop structure following AWS formatting. Prepare materials so the team can present effectively during the workshop. Tasks to be carried out this week: Day Tasks Start Date Completion Date Resources Used 2 - Review the BDSS team proposal - Study the Proposal Template - Define the scope of the workshop to be built 10/11/2025 10/11/2025 proposal.docx Proposal Template.docx 3 - Analyze the workshop structure based on the template - Select relevant content from both proposals to include in the workshop 11/11/2025 11/11/2025 Proposal Template.docx 4 - Draft content for the workshop sections: Introduction, Background, Objectives - Standardize flow and wording according to AWS style 12/11/2025 12/11/2025 proposal.docx 5 - Build the main workshop content: + System Architecture + Data Flow + CI/CD Pipeline + Security Model 13/11/2025 14/11/2025 proposal.docx 6 - Consolidate AWS Cost Estimate and Risk Assessment for workshop usage - Adjust content according to the workshop layout 14/11/2025 15/11/2025 Proposal Template.docx 7 - Finalize the Workshop Draft - Clean up formatting, headings, and presentation flow - Send the completed workshop document for team review 16/11/2025 16/11/2025 ‚Äî Week 10 Achievements: Completed the Workshop Draft based on both the Proposal and Proposal Template. Standardized workshop content including: Introduction, Background, Architecture, CI/CD, Cost, Security, Roadmap. Presented BDSS architecture in a clear, workshop-friendly structure. Fully consolidated cost estimates, risks, and implementation planning for workshop usage. Workshop materials are ready for team review and preparation for the upcoming presentation. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/1-worklog/1.11-week11/",
	"title": "Worklog Week 11",
	"tags": [],
	"description": "",
	"content": "Week 11 Objectives: Consolidate content from the team‚Äôs two proposal documents. Prepare materials for the final presentation slide deck. Standardize all information and identify the main sections to be presented. Ensure consistency between system architecture and the implementation plan. Tasks to be carried out this week: Day Tasks Start Date Completion Date Resources Used 2 - Review the entire Proposal.docx - Identify key sections to include in the presentation slides 17/11/2025 17/11/2025 Proposal.docx 3 - Consolidate Executive Summary, Problem Statement, and Solution Overview - Rewrite content in a concise, presentation-friendly format 18/11/2025 18/11/2025 Proposal.docx 4 - Extract and standardize the Solution Architecture section: + Networking layer + Application layer + CI/CD + Security \u0026amp; Monitoring 19/11/2025 19/11/2025 Proposal Template.docx 5 - Consolidate AWS Cost Estimate - Review Risk Assessment and Timeline - Convert information into short bullet points for slides 20/11/2025 20/11/2025 Proposal.docx 6 - Build the outline for the presentation slides: + Summary + Problem + Architecture + Cost + Risk + Roadmap 21/11/2025 21/11/2025 Consolidated content 7 - Standardize all content in English - Validate logical flow between sections - Prepare materials for the slide design team 22/11/2025 23/11/2025 Proposal.docx, Proposal Template Week 11 Achievements: Completed consolidation of content from both proposal documents (Executive Summary, Problem, Solution, Architecture, Risk, Cost, etc.). Built a structured outline for the presentation slide deck, clearly separating core and supplementary sections. Standardized all content in English for the final presentation. Ensured consistency between the system architecture, implementation plan, and presentation materials. Ready to move on to the slide design phase and prepare for the final presentation. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/1-worklog/1.12-week12/",
	"title": "Worklog Week 12",
	"tags": [],
	"description": "",
	"content": "Week 12 Objectives: Present the team‚Äôs project to mentors and supervisors. Collect feedback for improvement on architecture, implementation, and presentation quality. Identify areas that need adjustment before the final submission. Document all comments and action items for the next sprint. Tasks to be carried out this week: Day Tasks Start Date Completion Date Resources Used 2 - Prepare final slide deck - Review speaking roles for each member 24/11/2025 24/11/2025 Slide deck 3 - Conduct internal rehearsal session - Adjust timing and transitions between presenters 25/11/2025 25/11/2025 Internal notes 4 - Official project presentation in front of mentors - Present system architecture, CI/CD pipeline, cost estimation, and demo 26/11/2025 26/11/2025 Presentation materials 5 - Receive mentor feedback on technical design, security considerations, and deployment approach - Record all comments for follow-up 27/11/2025 27/11/2025 Mentor feedback 6 - Analyze received feedback - Identify improvements required for architecture, diagrams, and slide clarity 28/11/2025 28/11/2025 Consolidated feedback 7 - Update documents and adjust the slide deck according to mentor comments - Prepare follow-up action plan for next week 29‚Äì30/11/2025 30/11/2025 Proposal, Slide deck Week 12 Achievements: Successfully presented the project to mentors and received detailed feedback on architecture, implementation, and presentation quality. Documented all comments related to: System architecture improvements Clarification of data flow and networking layers CI/CD pipeline explanation Cost optimization suggestions Security considerations Improved the slide deck and project documentation based on mentor recommendations. Identified key action items to refine before the final submission. Completed rehearsal and delivery of the mid-stage presentation as planned. "
},
{
	"uri": "https://phuong721.github.io/learning-aws/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://phuong721.github.io/learning-aws/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]